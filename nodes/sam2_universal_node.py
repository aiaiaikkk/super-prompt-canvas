"""
SAM2é€šç”¨èŠ‚ç‚¹
æ”¯æŒäº‘ç«¯/æœ¬åœ°éƒ¨ç½²çš„é€šç”¨ComfyUIèŠ‚ç‚¹
"""

import json
import numpy as np
import torch
import requests
import time
import base64
import io
from typing import Dict, List, Any, Optional, Tuple
from PIL import Image
import os
import sys

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.append(parent_dir)

try:
    from sam2_universal_service import get_universal_service
    UNIVERSAL_SERVICE_AVAILABLE = True
except ImportError as e:
    print(f"SAM2é€šç”¨æœåŠ¡å¯¼å…¥å¤±è´¥: {e}")
    UNIVERSAL_SERVICE_AVAILABLE = False

try:
    import comfy.model_management as model_management
    from nodes import MAX_RESOLUTION
    COMFY_AVAILABLE = True
except ImportError:
    COMFY_AVAILABLE = False
    MAX_RESOLUTION = 8192

class SAM2UniversalNode:
    """SAM2é€šç”¨èŠ‚ç‚¹ - æ”¯æŒäº‘ç«¯/æœ¬åœ°è‡ªåŠ¨åˆ‡æ¢"""
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image": ("IMAGE",),
            },
            "optional": {
                "mode": (["auto", "fast", "precise"], {"default": "auto"}),
                "interaction_points": ("STRING", {
                    "multiline": True, 
                    "default": "[]", 
                    "tooltip": "JSONæ ¼å¼äº¤äº’ç‚¹: [{\"type\":\"point\",\"point\":[x,y]}]"
                }),
                "confidence_threshold": ("FLOAT", {
                    "default": 0.4, 
                    "min": 0.1, 
                    "max": 1.0, 
                    "step": 0.1
                }),
                "service_url": ("STRING", {
                    "default": "auto",
                    "tooltip": "æœåŠ¡URLï¼Œautoä¸ºè‡ªåŠ¨æ£€æµ‹"
                }),
                "enable_sam2": ("BOOLEAN", {
                    "default": True,
                    "tooltip": "å¯ç”¨SAM2ç²¾ç¡®æ¨¡å¼"
                }),
                "timeout": ("INT", {
                    "default": 30,
                    "min": 5,
                    "max": 120,
                    "tooltip": "è¯·æ±‚è¶…æ—¶æ—¶é—´(ç§’)"
                })
            }
        }
    
    RETURN_TYPES = ("STRING", "STRING", "STRING", "STRING")
    RETURN_NAMES = ("layers_json", "performance_stats", "service_info", "debug_info")
    FUNCTION = "universal_segment"
    CATEGORY = "kontext/sam2"
    DESCRIPTION = "SAM2é€šç”¨æ™ºèƒ½åˆ†å‰²ï¼Œæ”¯æŒäº‘ç«¯/æœ¬åœ°è‡ªåŠ¨åˆ‡æ¢"
    
    def __init__(self):
        self.service_urls = []
        self.active_service_url = None
        self.last_detection_time = 0
        self.detection_interval = 60  # 60ç§’é‡æ–°æ£€æµ‹ä¸€æ¬¡
        
    def universal_segment(
        self, 
        image: torch.Tensor, 
        mode: str = "auto",
        interaction_points: str = "[]",
        confidence_threshold: float = 0.4,
        service_url: str = "auto",
        enable_sam2: bool = True,
        timeout: int = 30
    ) -> Tuple[str, str, str, str]:
        """æ‰§è¡Œé€šç”¨æ™ºèƒ½åˆ†å‰²"""
        
        try:
            start_time = time.time()
            
            # æ£€æµ‹æˆ–éªŒè¯æœåŠ¡
            active_url = self._get_active_service_url(service_url, timeout)
            
            if not active_url:
                # å›é€€åˆ°æœ¬åœ°æœåŠ¡
                return self._fallback_local_service(
                    image, mode, interaction_points, confidence_threshold, enable_sam2
                )
            
            # è½¬æ¢å›¾åƒä¸ºbase64
            image_data = self._tensor_to_base64(image)
            
            # è§£æäº¤äº’ç‚¹
            try:
                interactions = json.loads(interaction_points) if interaction_points.strip() else []
            except json.JSONDecodeError:
                print("âš ï¸ äº¤äº’ç‚¹JSONè§£æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤ä¸­å¿ƒç‚¹")
                interactions = []
            
            # å¦‚æœæ²¡æœ‰äº¤äº’ç‚¹ï¼Œç”Ÿæˆé»˜è®¤ç‚¹
            if not interactions:
                h, w = image.shape[1:3]
                interactions = [{"type": "point", "point": [w//2, h//2]}]
            
            # è°ƒç”¨è¿œç¨‹æœåŠ¡
            response_data = self._call_remote_service(
                active_url, image_data, interactions, mode, confidence_threshold, enable_sam2, timeout
            )
            
            if response_data["success"]:
                # è½¬æ¢ç»“æœæ ¼å¼
                layers_data = self._convert_results_to_layers(response_data["results"])
                
                # ç”Ÿæˆè¾“å‡º
                layers_json = json.dumps(layers_data, ensure_ascii=False, indent=2)
                
                # æ€§èƒ½ç»Ÿè®¡
                total_time = time.time() - start_time
                perf_stats = {
                    "service_url": active_url,
                    "service_type": self._detect_service_type(active_url),
                    "total_time_ms": total_time * 1000,
                    "remote_time_ms": response_data.get("performance_stats", {}).get("response_time_ms", 0),
                    "method": response_data.get("performance_stats", {}).get("method", "Unknown"),
                    "device": response_data.get("performance_stats", {}).get("device", "Unknown")
                }
                perf_json = json.dumps(perf_stats, ensure_ascii=False, indent=2)
                
                # æœåŠ¡ä¿¡æ¯
                service_info = {
                    "active_url": active_url,
                    "service_type": perf_stats["service_type"],
                    "connection_status": "connected",
                    "response_time_ms": perf_stats["total_time_ms"]
                }
                service_json = json.dumps(service_info, ensure_ascii=False, indent=2)
                
                # è°ƒè¯•ä¿¡æ¯
                debug_info = {
                    "total_interactions": len(interactions),
                    "successful_results": len(response_data["results"]),
                    "service_detection": self.service_urls,
                    "image_info": {
                        "shape": list(image.shape),
                        "device": str(image.device)
                    }
                }
                debug_json = json.dumps(debug_info, ensure_ascii=False, indent=2)
                
                print(f"âœ… SAM2é€šç”¨åˆ†å‰²å®Œæˆ: {len(layers_data)}ä¸ªç»“æœ ({total_time*1000:.1f}ms)")
                return (layers_json, perf_json, service_json, debug_json)
            
            else:
                error_msg = response_data.get("error", "è¿œç¨‹æœåŠ¡è°ƒç”¨å¤±è´¥")
                print(f"âŒ è¿œç¨‹æœåŠ¡å¤±è´¥: {error_msg}")
                return self._create_error_result(error_msg, active_url)
                
        except Exception as e:
            error_msg = f"SAM2é€šç”¨åˆ†å‰²å¤±è´¥: {str(e)}"
            print(f"âŒ {error_msg}")
            return self._create_error_result(error_msg, self.active_service_url)
    
    def _get_active_service_url(self, service_url: str, timeout: int) -> Optional[str]:
        """è·å–æ´»è·ƒçš„æœåŠ¡URL"""
        current_time = time.time()
        
        # å¦‚æœæŒ‡å®šäº†å…·ä½“URL
        if service_url != "auto":
            if self._test_service_connection(service_url, timeout):
                self.active_service_url = service_url
                return service_url
            else:
                print(f"âš ï¸ æŒ‡å®šçš„æœåŠ¡URLä¸å¯ç”¨: {service_url}")
                return None
        
        # å¦‚æœå·²æœ‰æ´»è·ƒæœåŠ¡ä¸”æœªè¶…æ—¶
        if (self.active_service_url and 
            current_time - self.last_detection_time < self.detection_interval and
            self._test_service_connection(self.active_service_url, 5)):
            return self.active_service_url
        
        # é‡æ–°æ£€æµ‹æœåŠ¡
        print("ğŸ” æ£€æµ‹å¯ç”¨çš„SAM2æœåŠ¡...")
        self.service_urls = self._detect_available_services(timeout)
        self.last_detection_time = current_time
        
        if self.service_urls:
            self.active_service_url = self.service_urls[0]
            print(f"âœ… é€‰æ‹©æœåŠ¡: {self.active_service_url}")
            return self.active_service_url
        
        print("âŒ æœªæ‰¾åˆ°å¯ç”¨çš„SAM2æœåŠ¡")
        return None
    
    def _detect_available_services(self, timeout: int) -> List[str]:
        """æ£€æµ‹å¯ç”¨çš„æœåŠ¡åˆ—è¡¨"""
        # æ„å»ºå€™é€‰URLåˆ—è¡¨
        candidate_urls = []
        
        # æ£€æµ‹ç¯å¢ƒç±»å‹
        is_cloud = self._is_cloud_environment()
        
        if is_cloud:
            # äº‘ç«¯ç¯å¢ƒï¼šå°è¯•ç›¸åŒä¸»æœºçš„ä¸åŒç«¯å£
            import socket
            hostname = socket.getfqdn()
            candidate_urls.extend([
                "http://localhost:8002",
                f"http://{hostname}:8002",
                "http://127.0.0.1:8002",
                "http://0.0.0.0:8002"
            ])
        else:
            # æœ¬åœ°ç¯å¢ƒ
            candidate_urls.extend([
                "http://localhost:8002",
                "http://127.0.0.1:8002"
            ])
        
        # æµ‹è¯•æ¯ä¸ªå€™é€‰URL
        available_services = []
        for url in candidate_urls:
            if self._test_service_connection(url, timeout // len(candidate_urls) or 1):
                available_services.append(url)
                print(f"âœ… å‘ç°æœåŠ¡: {url}")
        
        return available_services
    
    def _is_cloud_environment(self) -> bool:
        """æ£€æµ‹æ˜¯å¦ä¸ºäº‘ç«¯ç¯å¢ƒ"""
        indicators = [
            os.getenv("CLOUD_PROVIDER") is not None,
            os.getenv("KUBERNETES_SERVICE_HOST") is not None,
            os.getenv("AWS_EXECUTION_ENV") is not None,
            os.path.exists("/.dockerenv")
        ]
        return any(indicators)
    
    def _test_service_connection(self, url: str, timeout: int) -> bool:
        """æµ‹è¯•æœåŠ¡è¿æ¥"""
        try:
            response = requests.get(f"{url}/health", timeout=timeout)
            if response.status_code == 200:
                data = response.json()
                if data.get("status") == "healthy":
                    return True
        except Exception:
            pass
        return False
    
    def _detect_service_type(self, url: str) -> str:
        """æ£€æµ‹æœåŠ¡ç±»å‹"""
        if "localhost" in url or "127.0.0.1" in url:
            return "local"
        elif url.startswith("http://") and ":" in url:
            return "cloud"
        else:
            return "unknown"
    
    def _tensor_to_base64(self, tensor: torch.Tensor) -> str:
        """å°†tensorè½¬æ¢ä¸ºbase64å­—ç¬¦ä¸²"""
        # è½¬æ¢ä¸ºPILå›¾åƒ
        if len(tensor.shape) == 4:
            tensor = tensor[0]  # ç§»é™¤batchç»´åº¦
        
        if tensor.device.type == 'cuda':
            tensor = tensor.cpu()
        
        numpy_array = tensor.numpy()
        
        # ç¡®ä¿å€¼èŒƒå›´åœ¨[0, 255]
        if numpy_array.max() <= 1.0:
            numpy_array = (numpy_array * 255).astype(np.uint8)
        else:
            numpy_array = numpy_array.astype(np.uint8)
        
        # è½¬æ¢ä¸ºPILå›¾åƒ
        pil_image = Image.fromarray(numpy_array)
        
        # è½¬æ¢ä¸ºbase64
        buffer = io.BytesIO()
        pil_image.save(buffer, format='PNG')
        image_data = base64.b64encode(buffer.getvalue()).decode('utf-8')
        
        return f"data:image/png;base64,{image_data}"
    
    def _call_remote_service(
        self, 
        service_url: str, 
        image_data: str, 
        interactions: List[Dict[str, Any]], 
        mode: str,
        confidence_threshold: float,
        enable_sam2: bool,
        timeout: int
    ) -> Dict[str, Any]:
        """è°ƒç”¨è¿œç¨‹æœåŠ¡"""
        
        # é€‰æ‹©APIç«¯ç‚¹
        if mode == "fast":
            endpoint = "/preview"
        elif mode == "precise":
            endpoint = "/segment"
        else:
            endpoint = "/smart_segment"
        
        # æ„å»ºè¯·æ±‚æ•°æ®
        request_data = {
            "image_data": image_data,
            "interactions": interactions,
            "mode": mode,
            "confidence_threshold": confidence_threshold,
            "enable_sam2": enable_sam2,
            "session_id": f"comfyui_{int(time.time())}"
        }
        
        try:
            response = requests.post(
                f"{service_url}{endpoint}",
                json=request_data,
                timeout=timeout,
                headers={"Content-Type": "application/json"}
            )
            
            if response.status_code == 200:
                return response.json()
            else:
                return {
                    "success": False,
                    "error": f"HTTP {response.status_code}: {response.text}"
                }
                
        except requests.exceptions.Timeout:
            return {
                "success": False,
                "error": f"è¯·æ±‚è¶…æ—¶ ({timeout}ç§’)"
            }
        except requests.exceptions.ConnectionError:
            return {
                "success": False,
                "error": "è¿æ¥å¤±è´¥"
            }
        except Exception as e:
            return {
                "success": False,
                "error": f"è¯·æ±‚å¤±è´¥: {str(e)}"
            }
    
    def _convert_results_to_layers(self, results: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """å°†APIç»“æœè½¬æ¢ä¸ºå±‚æ ¼å¼"""
        layers = []
        
        for i, result in enumerate(results):
            if "annotation" in result:
                annotation = result["annotation"]
                
                # åŸºç¡€å±‚æ•°æ®
                layer = {
                    "id": annotation.get("id", f"sam2_universal_{i}"),
                    "type": annotation.get("type", "detection"),
                    "name": annotation.get("name", f"SAM2_Object_{i+1}"),
                    "confidence": annotation.get("confidence", 0.5),
                    "class_name": annotation.get("class_name", "object"),
                    "method": result.get("method", "SAM2Universal"),
                    "visible": True,
                    "color": annotation.get("color", "#00ff00"),
                    "number": i + 1
                }
                
                # æ·»åŠ å‡ ä½•ä¿¡æ¯
                if "geometry" in annotation:
                    layer["geometry"] = annotation["geometry"]
                
                # æ·»åŠ ä¸­å¿ƒç‚¹
                if "center" in annotation:
                    layer["center"] = annotation["center"]
                
                # æ·»åŠ è½®å»“
                if "contours" in annotation:
                    layer["contours"] = annotation["contours"]
                
                layers.append(layer)
        
        return layers
    
    def _fallback_local_service(
        self,
        image: torch.Tensor,
        mode: str,
        interaction_points: str,
        confidence_threshold: float,
        enable_sam2: bool
    ) -> Tuple[str, str, str, str]:
        """å›é€€åˆ°æœ¬åœ°æœåŠ¡"""
        print("ğŸ”„ ä½¿ç”¨æœ¬åœ°å›é€€æœåŠ¡...")
        
        if not UNIVERSAL_SERVICE_AVAILABLE:
            return self._create_error_result("æœ¬åœ°æœåŠ¡ä¸å¯ç”¨", "local_fallback")
        
        try:
            # è·å–æœ¬åœ°æœåŠ¡å®ä¾‹
            local_service = get_universal_service()
            
            # è½¬æ¢å›¾åƒ
            image_np = self._tensor_to_numpy(image)
            
            # è§£æäº¤äº’ç‚¹
            try:
                interactions = json.loads(interaction_points) if interaction_points.strip() else []
            except json.JSONDecodeError:
                interactions = []
            
            if not interactions:
                h, w = image_np.shape[:2]
                interactions = [{"type": "point", "point": [w//2, h//2]}]
            
            # æ‰§è¡Œæœ¬åœ°åˆ†å‰²
            results = []
            for interaction in interactions:
                result = local_service._smart_segment(image_np, interaction, mode, confidence_threshold)
                if result["success"]:
                    results.append(result)
            
            # è½¬æ¢ç»“æœ
            layers_data = self._convert_results_to_layers(results)
            layers_json = json.dumps(layers_data, ensure_ascii=False, indent=2)
            
            # æ€§èƒ½ç»Ÿè®¡
            perf_stats = {
                "service_type": "local_fallback",
                "device": str(image.device),
                "method": "Local" + ("SAM2" if enable_sam2 else "FastSAM")
            }
            perf_json = json.dumps(perf_stats, ensure_ascii=False, indent=2)
            
            # æœåŠ¡ä¿¡æ¯
            service_info = {
                "active_url": "local_fallback",
                "service_type": "local",
                "connection_status": "fallback"
            }
            service_json = json.dumps(service_info, ensure_ascii=False, indent=2)
            
            # è°ƒè¯•ä¿¡æ¯
            debug_info = {
                "fallback_used": True,
                "successful_results": len(results)
            }
            debug_json = json.dumps(debug_info, ensure_ascii=False, indent=2)
            
            print(f"âœ… æœ¬åœ°å›é€€åˆ†å‰²å®Œæˆ: {len(layers_data)}ä¸ªç»“æœ")
            return (layers_json, perf_json, service_json, debug_json)
            
        except Exception as e:
            return self._create_error_result(f"æœ¬åœ°å›é€€å¤±è´¥: {str(e)}", "local_fallback")
    
    def _tensor_to_numpy(self, tensor: torch.Tensor) -> np.ndarray:
        """å°†tensorè½¬æ¢ä¸ºnumpyæ•°ç»„"""
        if len(tensor.shape) == 4:
            tensor = tensor[0]
        
        if tensor.device.type == 'cuda':
            tensor = tensor.cpu()
        
        numpy_array = tensor.numpy()
        
        if numpy_array.max() <= 1.0:
            numpy_array = (numpy_array * 255).astype(np.uint8)
        else:
            numpy_array = numpy_array.astype(np.uint8)
        
        return numpy_array
    
    def _create_error_result(self, error_msg: str, service_url: Optional[str]) -> Tuple[str, str, str, str]:
        """åˆ›å»ºé”™è¯¯ç»“æœ"""
        error_layers = [{
            "id": "error_annotation",
            "type": "error",
            "name": "Error",
            "confidence": 0.0,
            "class_name": "error",
            "method": "Error",
            "visible": True,
            "color": "#ff0000",
            "geometry": {
                "type": "rectangle",
                "coordinates": [10, 10, 100, 100]
            },
            "error": error_msg
        }]
        
        error_stats = {
            "error": error_msg,
            "service_url": service_url,
            "service_type": "error"
        }
        
        error_service_info = {
            "active_url": service_url,
            "service_type": "error",
            "connection_status": "failed",
            "error": error_msg
        }
        
        error_debug = {
            "error": error_msg,
            "detected_services": self.service_urls,
            "fallback_attempted": True
        }
        
        return (
            json.dumps(error_layers, ensure_ascii=False),
            json.dumps(error_stats, ensure_ascii=False),
            json.dumps(error_service_info, ensure_ascii=False),
            json.dumps(error_debug, ensure_ascii=False)
        )

# ComfyUIèŠ‚ç‚¹æ³¨å†Œ
NODE_CLASS_MAPPINGS = {
    "SAM2UniversalNode": SAM2UniversalNode,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "SAM2UniversalNode": "ğŸŒ SAM2 Universal Segmentation",
}

if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    print("ğŸ§ª SAM2é€šç”¨èŠ‚ç‚¹æµ‹è¯•")
    node = SAM2UniversalNode()
    print("âœ… èŠ‚ç‚¹åˆ›å»ºæˆåŠŸ")