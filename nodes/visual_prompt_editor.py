"""
Visual Prompt Editor Node
Visual prompt editor node for ComfyUI

Combines visual annotation editing and structured prompt generation functionality
Double-click node to open unified editing interface: left side for graphic annotation, right side for prompt editing
"""

import json
import base64
import time
from typing import Dict, List, Any, Tuple, Optional
from datetime import datetime
from PIL import Image, ImageDraw, ImageFont
from PIL import Image as PILImage
# from threading import Event  # ä¸å†éœ€è¦Eventï¼ŒWidgetæ¶æ„ä¸éœ€è¦å¼‚æ­¥ç­‰å¾…

# Optional dependencies
try:
    import torch
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False
    torch = None

try:
    import numpy as np
    NUMPY_AVAILABLE = True
except ImportError:
    NUMPY_AVAILABLE = False
    np = None

try:
    import comfy.model_management as model_management
    from nodes import MAX_RESOLUTION
    from server import PromptServer
    COMFY_AVAILABLE = True
except ImportError:
    COMFY_AVAILABLE = False
    MAX_RESOLUTION = 8192

# ç§»é™¤WebSocketç›¸å…³çš„å­˜å‚¨å‡½æ•°ï¼ŒWidgetæ¶æ„ä¸éœ€è¦

# æ·»åŠ HTTPè·¯ç”±å¤„ç†å‰ç«¯æ•°æ®
try:
    from aiohttp import web
    from server import PromptServer
    
    # âœ… ç§»é™¤WebSocketé€»è¾‘ï¼Œä½¿ç”¨Widgetæ•°æ®æµæ¶æ„
    print("[Kontext] ä½¿ç”¨Widgetæ•°æ®æµæ¶æ„ï¼Œæ— éœ€HTTPè·¯ç”±æˆ–WebSocket")
            
except ImportError:
    print("[Kontext] è­¦å‘Š: aiohttpä¸å¯ç”¨ï¼Œäº‹ä»¶é©±åŠ¨åŠŸèƒ½å°†å—é™")

class VisualPromptEditor:
    """Visual Prompt Editor Node - Unified annotation editing and prompt generation"""
    
    def __init__(self):
        self.node_id = None
    
    @classmethod
    def clean_nodes(cls):
        """Widgetæ¶æ„æ— éœ€å­˜å‚¨æ¸…ç†"""
        print(f"[Kontext] Widgetæ¶æ„ï¼Œæ— éœ€æ¸…ç†å­˜å‚¨")
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
            },
            "optional": {
                "image": ("IMAGE",),
                "annotation_data": ("STRING", {"tooltip": "JSON annotation data from frontend editor"}),
                "canvas_width": ("INT", {"default": 800, "min": 200, "max": 2048, "step": 10, "tooltip": "Canvas width in pixels"}),
                "canvas_height": ("INT", {"default": 600, "min": 200, "max": 2048, "step": 10, "tooltip": "Canvas height in pixels"}),
            },
            "hidden": {"unique_id": "UNIQUE_ID"}
        }
    
    RETURN_TYPES = ("IMAGE", "STRING", "STRING", "STRING")
    RETURN_NAMES = (
        "processed_image", 
        "structured_prompt",
        "annotation_data",
        "model_instruction"
    )
    FUNCTION = "visual_prompt_edit"
    CATEGORY = "lrpg_super_prompt/core"
    DESCRIPTION = "ğŸ¨ LRPG Super Prompt Visual Editor - Unified visual annotation editor with multimodal AI prompt generation capabilities"
    
    def visual_prompt_edit(self, image = None, annotation_data: str = None,
                          canvas_width: int = 800, canvas_height: int = 600, unique_id=None):
        """
        LRPG Transform-Firstæ¶æ„ - äº‹ä»¶é©±åŠ¨å“åº”å¼å¤„ç†
        ä»annotation_dataæ¶æ„å½»åº•å‡çº§ä¸ºTransform-First + Event-Drivenæ¶æ„
        """
        
        try:
            # ===== Widgetæ¶æ„åˆå§‹åŒ– =====
            self.node_id = unique_id
            print(f"[Kontext] ğŸš€ å¯åŠ¨Widgetæ•°æ®æµå¤„ç† (Node: {unique_id})")
            print(f"[Kontext] ğŸ“Š è¾“å…¥å›¾åƒå°ºå¯¸: {image.shape if image is not None else 'None'}")
            
            print(f"[Kontext] ğŸ“ annotation_dataé•¿åº¦: {len(annotation_data) if annotation_data else 0} å­—ç¬¦")
            
            # âœ… Widgetæ¶æ„ï¼šç›´æ¥ä½¿ç”¨annotation_dataï¼Œæ— éœ€WebSocketé€šä¿¡
            print(f"[Kontext] ğŸ“Š Widgetæ¶æ„å¯åŠ¨ï¼Œç›´æ¥è¯»å–annotation_data")
            
            # âœ… Widgetæ¶æ„ï¼šæ— éœ€ç­‰å¾…WebSocketï¼Œç›´æ¥å¤„ç†annotation_data
            print(f"[Kontext] ğŸ“Š Widgetæ¶æ„ï¼šç›´æ¥å¤„ç†annotation_dataå‚æ•°")
            frontend_data = None  # ä¸å†ä½¿ç”¨WebSocketæ•°æ®
            self.clean_nodes()
            
            # ===== Transform-First æ•°æ®å¤„ç† =====
            # ä¼˜å…ˆä½¿ç”¨äº‹ä»¶é©±åŠ¨çš„å‰ç«¯æ•°æ®
            
            # 1. åˆå§‹åŒ–Transformæ•°æ®å®¹å™¨
            transform_data = {}
            canvas_data = {}
            user_edited_prompt = ""
            constraint_prompts = []
            decorative_prompts = []
            
            # 2. å¤„ç†æ•°æ®ï¼ˆä¼˜å…ˆçº§ï¼šannotation_data > é»˜è®¤ï¼‰
            if annotation_data and annotation_data.strip():
                # Widgetæ•°æ®æµï¼šç›´æ¥å¤„ç†annotation_data
                print(f"[Kontext] ğŸ“¦ å¤„ç†annotation_dataï¼Œé•¿åº¦: {len(annotation_data)} å­—ç¬¦")
                print(f"[Kontext] ğŸ” annotation_dataå†…å®¹: {annotation_data[:200]}...")  # æ˜¾ç¤ºå‰200å­—ç¬¦
                
                try:
                    parsed_data = json.loads(annotation_data)
                    
                    # Transform-Firstæ•°æ®æ£€æµ‹å’Œå¤„ç†
                    if self._is_transform_first_data(parsed_data):
                        print(f"[Kontext] âœ… æ£€æµ‹åˆ°Transform-Firstæ•°æ®æ ¼å¼")
                        transform_data, canvas_data = self._process_transform_first_data(parsed_data)
                    else:
                        print(f"[Kontext] ğŸ”„ æ—§æ ¼å¼æ•°æ®ï¼Œè½¬æ¢ä¸ºTransform-Firstæ ¼å¼")
                        transform_data, canvas_data = self._convert_legacy_to_transform(parsed_data)
                    
                    # æå–ç”¨æˆ·ç¼–è¾‘çš„æç¤ºè¯ï¼ˆå…¼å®¹æ–°æ—§å­—æ®µåï¼‰
                    user_edited_prompt = parsed_data.get("user_prompt", 
                                                        parsed_data.get("userEditedPrompt", ""))
                    constraint_prompts = parsed_data.get("constraint_prompts",
                                                        parsed_data.get("constraintPrompts", []))
                    decorative_prompts = parsed_data.get("decorative_prompts",
                                                        parsed_data.get("decorativePrompts", []))
                    
                except json.JSONDecodeError as e:
                    print(f"[Kontext] âš ï¸ æ•°æ®è§£æå¤±è´¥: {e}")
                    # ä½¿ç”¨é»˜è®¤Transformæ•°æ®
                    transform_data, canvas_data = self._create_default_transform_data(image, canvas_width, canvas_height)
            else:
                print(f"[Kontext] ğŸ“ æ— è¾“å…¥æ•°æ®ï¼Œä½¿ç”¨é»˜è®¤Transformé…ç½®")
                transform_data, canvas_data = self._create_default_transform_data(image, canvas_width, canvas_height)
            
            # 3. Transform-Firstå›¾åƒå¤„ç†å’Œåˆæˆ
            print(f"[LRPG] ğŸ¨ å¼€å§‹Transform-Firstå›¾åƒåˆæˆ")
            print(f"[LRPG] ğŸ” Transformæ•°æ®è¯¦æƒ…: {transform_data}")
            print(f"[LRPG] ğŸ” Canvasæ•°æ®è¯¦æƒ…: {canvas_data}")
            print(f"[LRPG] ğŸ” å›¾åƒè¾“å…¥: {image is not None}, å°ºå¯¸: {image.shape if image is not None else 'None'}")
            
            result_image = self._apply_transform_first_processing(
                image, transform_data, canvas_data, canvas_width, canvas_height
            )
            
            # 4. ç”ŸæˆTransform-Firstæç¤ºè¯
            # æå–operation_typeå’Œtarget_description
            operation_type = parsed_data.get("operation_type", "custom") if 'parsed_data' in locals() else "custom"
            target_description = parsed_data.get("target_description", "") if 'parsed_data' in locals() else ""
            
            structured_prompt = self._generate_transform_based_prompt(
                transform_data, user_edited_prompt, constraint_prompts, decorative_prompts,
                operation_type, target_description
            )
            
            # 5. æ„å»ºè¾“å‡ºæ•°æ®
            enhanced_prompts = self._build_enhanced_prompts(constraint_prompts, decorative_prompts)
            
            print(f"[LRPG] âœ… Transform-Firstå¤„ç†å®Œæˆ")
            print(f"[LRPG] ğŸ“Š è¾“å‡ºå›¾åƒå°ºå¯¸: {result_image.shape}")
            print(f"[LRPG] ğŸ“ ç”Ÿæˆæç¤ºè¯é•¿åº¦: {len(structured_prompt)} å­—ç¬¦")
            
            return (
                result_image,
                structured_prompt,
                enhanced_prompts,
                json.dumps({
                    "version": "transform_first_1.0",
                    "transform_data": transform_data,
                    "canvas_data": canvas_data,
                    "processing_timestamp": time.time()
                })
            )
            
        except Exception as e:
            print(f"[LRPG] âŒ Transform-Firstå¤„ç†å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            
            # é”™è¯¯æƒ…å†µä¸‹è¿”å›åŸå›¾
            fallback_prompt = "Transform-First processing failed, using original image"
            return (
                image if image is not None else torch.zeros((1, 512, 512, 3)),
                fallback_prompt,
                "[]", 
                json.dumps({"error": str(e), "version": "transform_first_1.0"})
            )

    # ===== Transform-First æ ¸å¿ƒå¤„ç†æ–¹æ³• =====
    
    def _is_transform_first_data(self, data):
        """æ£€æµ‹æ˜¯å¦ä¸ºTransform-Firstæ•°æ®æ ¼å¼"""
        return (
            isinstance(data, dict) and 
            ("layer_transforms" in data or "transform_data" in data or 
             "canvas_data" in data or "transform_version" in data)
        )
    
    def _process_transform_first_data(self, data):
        """å¤„ç†LRPGç»Ÿä¸€æ ¼å¼æ•°æ® - æ— è½¬æ¢"""
        layer_transforms = data.get("layer_transforms", {})
        
        print(f"[LRPG] ğŸ“Š ç»Ÿä¸€æ ¼å¼å›¾å±‚æ•°: {len(layer_transforms)}")
        
        # âœ… è°ƒè¯•ï¼šæ‰“å°å®é™…æ¥æ”¶çš„æ•°æ®
        for layer_id, layer_data in layer_transforms.items():
            if layer_id != 'background':
                print(f"[LRPG] ğŸ” å›¾å±‚ {layer_id} æ•°æ®:")
                print(f"  - centerX: {layer_data.get('centerX', 'NOT_FOUND')}")
                print(f"  - centerY: {layer_data.get('centerY', 'NOT_FOUND')}")
                print(f"  - scaleX: {layer_data.get('scaleX', 'NOT_FOUND')}")
                print(f"  - angle: {layer_data.get('angle', 'NOT_FOUND')}")
                print(f"  - type: {layer_data.get('type', 'NOT_FOUND')}")
                # ğŸ”§ æ£€æŸ¥pointsæ•°æ®ï¼ˆå¤šè¾¹å½¢ï¼‰
                if layer_data.get('type') == 'polygon':
                    points = layer_data.get('points', [])
                    print(f"  - points: {'æœ‰' if points else 'æ— '} ({len(points)} ä¸ªç‚¹)")
                    if points:
                        print(f"  - pointsç¤ºä¾‹: {points[:2]}{'...' if len(points) > 2 else ''}")
                print(f"  - crop_path: {'æœ‰' if layer_data.get('crop_path') else 'æ— '} ({len(layer_data.get('crop_path', []))} ä¸ªç‚¹)")
        
        # âœ… LRPGæ ¼å¼ï¼šç›´æ¥ä½¿ç”¨ï¼Œæ— è½¬æ¢
        background = layer_transforms.get('background', {})
        canvas_data = {
            'width': background.get('width', 800),
            'height': background.get('height', 600)
        }
        
        print(f"[LRPG] ğŸ¨ Canvaså°ºå¯¸: {canvas_data['width']}x{canvas_data['height']}")
        print(f"[LRPG] âœ… LRPGç»Ÿä¸€æ ¼å¼å¤„ç†å®Œæˆ")
        
        return layer_transforms, canvas_data
    
    def _convert_layer_to_kontext_format(self, layer_data):
        """å°†å•ä¸ªå›¾å±‚ä»æ—§æ ¼å¼è½¬æ¢ä¸ºKontextæ ¼å¼"""
        try:
            # æå–æ—§æ ¼å¼æ•°æ®
            position = layer_data.get('position', {})
            size = layer_data.get('size', {})
            transform = layer_data.get('transform', {})
            
            left = position.get('left', 0)
            top = position.get('top', 0)
            width = size.get('width', 100)
            height = size.get('height', 100)
            scaleX = transform.get('scaleX', 1)
            scaleY = transform.get('scaleY', 1)
            angle = transform.get('angle', 0)
            
            # âœ… è½¬æ¢ä¸ºKontextä¸­å¿ƒç‚¹åæ ‡ç³»ç»Ÿ
            centerX = left + width / 2
            centerY = top + height / 2
            
            kontext_layer = {
                'centerX': centerX,
                'centerY': centerY,
                'scaleX': scaleX,
                'scaleY': scaleY,
                'angle': angle,
                'width': width,
                'height': height,
                'flipX': layer_data.get('flipX', False),
                'flipY': layer_data.get('flipY', False),
                'type': layer_data.get('type', 'rect'),
                'style': layer_data.get('style', {}),
                'converted_from_legacy': True
            }
            
            print(f"[LRPG] ğŸ”„ æ—§æ ¼å¼è½¬æ¢:")
            print(f"  - ä½ç½®: ({left}, {top}) + å°ºå¯¸: ({width}, {height})")
            print(f"  - è½¬æ¢ä¸ºä¸­å¿ƒç‚¹: ({centerX:.1f}, {centerY:.1f})")
            print(f"  - å˜æ¢: ç¼©æ”¾({scaleX:.3f}, {scaleY:.3f}), æ—‹è½¬{angle:.1f}Â°")
            
            return kontext_layer
            
        except Exception as e:
            print(f"[LRPG] âŒ å›¾å±‚æ ¼å¼è½¬æ¢å¤±è´¥: {str(e)}")
            return layer_data
    
    def _convert_legacy_to_transform(self, data):
        """å°†æ—§çš„annotationæ•°æ®è½¬æ¢ä¸ºTransform-Firstæ ¼å¼"""
        print(f"[LRPG] ğŸ”„ è½¬æ¢æ—§æ ¼å¼annotationæ•°æ®ä¸ºTransformæ ¼å¼")
        
        transform_data = {}
        canvas_data = {
            "background_color": data.get("backgroundColor", "#ffffff"),
            "version": "converted_from_legacy"
        }
        
        # å°è¯•ä»annotationæ•°æ®æå–transformä¿¡æ¯
        annotations = data.get("annotations", [])
        for i, annotation in enumerate(annotations):
            if annotation.get("fabricObject"):
                fabric_obj = annotation["fabricObject"]
                transform_data[f"layer_{i}"] = {
                    "centerX": fabric_obj.get("left", 0) + fabric_obj.get("width", 0) / 2,
                    "centerY": fabric_obj.get("top", 0) + fabric_obj.get("height", 0) / 2,
                    "scaleX": fabric_obj.get("scaleX", 1),
                    "scaleY": fabric_obj.get("scaleY", 1),
                    "angle": fabric_obj.get("angle", 0),
                    "width": fabric_obj.get("width", 100),
                    "height": fabric_obj.get("height", 100),
                    "type": annotation.get("type", "unknown")
                }
        
        print(f"[LRPG] âœ… å·²è½¬æ¢ {len(transform_data)} ä¸ªå›¾å±‚ä¸ºTransformæ ¼å¼")
        return transform_data, canvas_data
    
    def _create_default_transform_data(self, image, canvas_width, canvas_height):
        """åˆ›å»ºé»˜è®¤çš„Transformæ•°æ®"""
        transform_data = {}
        canvas_data = {
            "width": canvas_width,
            "height": canvas_height,
            "background_color": "#ffffff",
            "version": "default_transform_first"
        }
        
        if image is not None:
            # ä¸ºè¾“å…¥å›¾åƒåˆ›å»ºé»˜è®¤transform
            img_height, img_width = image.shape[1], image.shape[2]
            transform_data["background_image"] = {
                "centerX": canvas_width / 2,
                "centerY": canvas_height / 2,
                "scaleX": 1.0,
                "scaleY": 1.0,
                "angle": 0,
                "width": img_width,
                "height": img_height,
                "type": "background"
            }
        
        return transform_data, canvas_data
    
    def _apply_transform_first_processing(self, image, transform_data, canvas_data, canvas_width, canvas_height):
        """ğŸš€ Kontext Transform-Firstå›¾åƒå¤„ç† - åˆ†è¾¨ç‡ç‹¬ç«‹HDè¿˜åŸç®—æ³•"""
        print(f"[LRPG] ğŸ¯ å¯åŠ¨Transform-Firsté«˜æ¸…è¿˜åŸå¤„ç†")
        print(f"[LRPG] ğŸ“Š æ¥æ”¶å‚æ•°:")
        print(f"  - è¾“å…¥å›¾åƒ: {image is not None}, å½¢çŠ¶: {image.shape if image is not None else 'None'}")
        print(f"  - å˜æ¢æ•°æ®: {type(transform_data)}, å›¾å±‚æ•°: {len(transform_data) if transform_data else 0}")
        print(f"  - ç”»å¸ƒæ•°æ®: {canvas_data}")
        print(f"  - ç›®æ ‡ç”»å¸ƒå°ºå¯¸: {canvas_width} x {canvas_height}")
        
        if image is None:
            print(f"[LRPG] âš ï¸ å›¾åƒä¸ºç©ºï¼Œåˆ›å»ºé»˜è®¤HDç”»å¸ƒ")
            return torch.ones((1, canvas_height, canvas_width, 3), dtype=torch.float32)
        
        if not transform_data:
            print(f"[LRPG] â„¹ï¸ æ— å˜æ¢æ•°æ®ï¼Œè¿”å›åŸå›¾")
            return image
        
        # âœ… Kontextæ ¸å¿ƒï¼šHDè¿˜åŸç®—æ³•é¢„å¤„ç†
        hd_scale = self._calculate_hd_scale(transform_data, canvas_data, image.shape)
        scaled_transform_data = self._scale_hd_transforms(transform_data, hd_scale)
        
        print(f"[LRPG] ğŸ”¬ HDè¿˜åŸåˆ†æ:")
        print(f"  - HDç¼©æ”¾æ¯”ä¾‹: {hd_scale:.3f}")
        print(f"  - åŸå§‹å˜æ¢æ•°: {len(transform_data)}")
        print(f"  - HDå˜æ¢æ•°: {len(scaled_transform_data)}")
        
        print(f"[LRPG] ğŸ¨ å¼€å§‹Transform-Firstå˜æ¢å¤„ç†")
        
        # ç¡®ä¿å›¾åƒæ ¼å¼æ­£ç¡®
        if len(image.shape) == 3:
            image = image.unsqueeze(0)
        if image.shape[-1] != 3 and image.shape[1] == 3:
            image = image.permute(0, 2, 3, 1)
        
        try:
            import cv2
            import numpy as np
            from PIL import Image as PILImage, ImageDraw
            
            # å¤„ç†æ‰¹é‡å›¾åƒ - æ”¯æŒå¤šå›¾åƒè¾“å…¥
            batch_size = image.shape[0]
            print(f"[LRPG] ğŸ“¦ æ£€æµ‹åˆ°æ‰¹é‡å›¾åƒ: {batch_size} å¼ ")
            
            # è·å–å›¾å±‚åˆ—è¡¨ï¼ˆæ’é™¤backgroundï¼‰
            layer_ids = [layer_id for layer_id in scaled_transform_data.keys() if layer_id != 'background']
            print(f"[LRPG] ğŸ“Š å›¾å±‚æ•°é‡: {len(layer_ids)}, å›¾åƒæ•°é‡: {batch_size}")
            print(f"[LRPG] ğŸ“‹ å›¾å±‚åˆ—è¡¨: {layer_ids}")
            
            processed_images = []
            
            # ä½¿ç”¨å®é™…ç”»å¸ƒå°ºå¯¸ï¼ˆä»canvas_dataè·å–ï¼‰
            actual_canvas_width = canvas_data.get('width', canvas_width)
            actual_canvas_height = canvas_data.get('height', canvas_height)
            
            # ä¸ºæ¯å¼ å›¾åƒå•ç‹¬å¤„ç†
            for batch_idx in range(batch_size):
                print(f"[LRPG] ğŸ”„ å¤„ç†ç¬¬ {batch_idx + 1}/{batch_size} å¼ å›¾åƒ")
                
                # è½¬æ¢å½“å‰å›¾åƒä¸ºPILå›¾åƒè¿›è¡Œå¤„ç†
                img_array = image[batch_idx].cpu().numpy()
                if img_array.max() <= 1.0:
                    img_array = (img_array * 255).astype(np.uint8)
                else:
                    img_array = img_array.astype(np.uint8)
                
                # åˆ›å»ºç”»å¸ƒ
                canvas = PILImage.fromarray(img_array)
                draw = ImageDraw.Draw(canvas)
                
                print(f"[LRPG] ğŸ–¼ï¸ ç¬¬{batch_idx + 1}å¼ å›¾åƒå°ºå¯¸: {canvas.size}")
                print(f"[LRPG] ğŸ¨ ç›®æ ‡ç”»å¸ƒå°ºå¯¸: {actual_canvas_width}x{actual_canvas_height}")
                
                # ğŸš€ æ–°æ¶æ„ï¼šå¤šå›¾åƒåˆæˆå¤„ç†
                print(f"[LRPG] ğŸ¨ å¼€å§‹å¤šå›¾åƒåˆæˆå¤„ç† - è¾“å…¥å›¾åƒ{batch_idx + 1}")
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆæˆæ¨¡å¼
                has_multiple_sources = any(
                    layer_data.get('source') == 'upload' 
                    for layer_data in scaled_transform_data.values() 
                    if isinstance(layer_data, dict) and 'source' in layer_data
                )
                
                # ğŸ¯ æ£€æŸ¥inputå›¾åƒæ˜¯å¦è¢«æ˜¾è‘—å˜æ¢
                has_transformed_input = False
                for layer_id, layer_data in scaled_transform_data.items():
                    if isinstance(layer_data, dict) and layer_data.get('source') == 'input':
                        # æ£€æŸ¥æ˜¯å¦åç¦»äº†é»˜è®¤çš„å±…ä¸­æ»¡å±çŠ¶æ€
                        centerX = layer_data.get('centerX', actual_canvas_width/2)
                        centerY = layer_data.get('centerY', actual_canvas_height/2)
                        scaleX = layer_data.get('scaleX', 1.0)
                        scaleY = layer_data.get('scaleY', 1.0)
                        
                        # è®¡ç®—é¢„æœŸçš„å±…ä¸­ä½ç½®
                        expected_centerX = actual_canvas_width / 2
                        expected_centerY = actual_canvas_height / 2
                        
                        # æ£€æŸ¥ä½ç½®åç§»
                        position_offset = abs(centerX - expected_centerX) + abs(centerY - expected_centerY)
                        
                        # æ£€æŸ¥ç¼©æ”¾å˜åŒ–ï¼ˆä¸æ˜¯æ¥è¿‘1.0çš„æ»¡å±ç¼©æ”¾ï¼‰
                        scale_change = abs(1.0 - scaleX) + abs(1.0 - scaleY)
                        
                        if position_offset > 50 or scale_change > 0.3:  # æ˜¾è‘—å˜æ¢é˜ˆå€¼
                            has_transformed_input = True
                            print(f"[LRPG] ğŸ¯ æ£€æµ‹åˆ°inputå›¾åƒå˜æ¢: ä½ç½®åç§»={position_offset:.1f}, ç¼©æ”¾å˜åŒ–={scale_change:.2f}")
                            break
                
                needs_composite_canvas = has_multiple_sources or has_transformed_input
                
                if needs_composite_canvas:
                    # åˆæˆæ¨¡å¼ï¼šåˆ›å»ºç©ºç™½ç”»å¸ƒï¼ˆå¤šå›¾åƒæˆ–å˜æ¢åçš„å•å›¾åƒï¼‰
                    canvas = self._create_composite_canvas(actual_canvas_width, actual_canvas_height)
                    if has_multiple_sources:
                        print(f"[LRPG] ğŸ¨ åˆ›å»ºåˆæˆç”»å¸ƒï¼ˆå¤šå›¾åƒæ¨¡å¼ï¼‰: {canvas.size}")
                    else:
                        print(f"[LRPG] ğŸ¨ åˆ›å»ºåˆæˆç”»å¸ƒï¼ˆå•å›¾åƒå˜æ¢æ¨¡å¼ï¼‰: {canvas.size}")
                else:
                    # å•å›¾åƒåŸå§‹æ¨¡å¼ï¼šä½¿ç”¨è¾“å…¥å›¾åƒä½œä¸ºåŸºç¡€
                    canvas = PILImage.fromarray(img_array)
                    print(f"[LRPG] ğŸ“· ä½¿ç”¨è¾“å…¥å›¾åƒä½œä¸ºåŸºç¡€ï¼ˆæœªå˜æ¢ï¼‰: {canvas.size}")
                
                # å¤„ç†æ‰€æœ‰å›¾å±‚
                for layer_id in layer_ids:
                    layer_data = scaled_transform_data.get(layer_id)
                    if layer_data:
                        print(f"[LRPG] ğŸ”„ å¤„ç†å›¾å±‚: {layer_id}")
                        canvas = self._process_image_layer(canvas, layer_data, layer_id, 
                                                         image[batch_idx] if layer_data.get('source') == 'input' else None,
                                                         actual_canvas_width, actual_canvas_height)
                    else:
                        print(f"[LRPG] âš ï¸ å›¾å±‚æ•°æ®ç¼ºå¤±: {layer_id}")
                
                # è½¬æ¢å½“å‰å¤„ç†çš„å›¾åƒå›tensorå¹¶æ·»åŠ åˆ°æ‰¹æ¬¡ä¸­
                result_array = np.array(canvas).astype(np.float32) / 255.0
                processed_images.append(result_array)
                
                print(f"[LRPG] âœ… ç¬¬{batch_idx + 1}å¼ å›¾åƒå¤„ç†å®Œæˆ")
            
            # å°†æ‰€æœ‰å¤„ç†åçš„å›¾åƒåˆå¹¶ä¸ºæ‰¹æ¬¡tensor
            if processed_images:
                batch_tensor = torch.from_numpy(np.stack(processed_images, axis=0))
                print(f"[LRPG] âœ… Transform-Firstæ‰¹é‡å¤„ç†å®Œæˆï¼Œè¾“å‡º {len(processed_images)} å¼ å›¾åƒ")
                return batch_tensor
            else:
                print(f"[LRPG] âš ï¸ æ²¡æœ‰å¤„ç†ä»»ä½•å›¾åƒ")
                return image
                
        except Exception as e:
            print(f"[LRPG] âŒ Transform-Firstå¤„ç†å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            return image
    
    def _create_composite_canvas(self, width, height):
        """åˆ›å»ºç©ºç™½åˆæˆç”»å¸ƒ"""
        from PIL import Image as PILImage
        return PILImage.new('RGB', (width, height), (255, 255, 255))
    
    def _process_image_layer(self, canvas, layer_data, layer_id, input_tensor, canvas_width, canvas_height):
        """å¤„ç†å•ä¸ªå›¾åƒå›¾å±‚"""
        try:
            import base64
            import io
            import numpy as np
            from PIL import Image as PILImage
            
            source = layer_data.get('source', 'input')
            print(f"[LRPG] ğŸ“· å›¾å±‚{layer_id}æºç±»å‹: {source}")
            # ğŸ” è°ƒè¯•ï¼šæ˜¾ç¤ºåŸå§‹å±‚æ•°æ®
            debug_fabricId = layer_data.get('_debug_fabricId', 'none')
            debug_name = layer_data.get('_debug_name', 'none')
            print(f"[LRPG] ğŸ” å›¾å±‚{layer_id}è°ƒè¯•ä¿¡æ¯: fabricId={debug_fabricId}, name={debug_name}")
            # ğŸ” CRITICALè°ƒè¯•ï¼šæ˜¾ç¤ºå®Œæ•´layer_dataç»“æ„
            print(f"[LRPG] ğŸš¨ CRITICAL: layer_dataå®Œæ•´ç»“æ„: {layer_data}")
            print(f"[LRPG] ğŸš¨ CRITICAL: layer_data keys: {list(layer_data.keys())}")
            if 'image_data' in layer_data:
                image_data_len = len(str(layer_data['image_data'])) if layer_data['image_data'] else 0
                print(f"[LRPG] ğŸš¨ CRITICAL: image_dataå­˜åœ¨ä¸”é•¿åº¦: {image_data_len}")
            else:
                print(f"[LRPG] ğŸš¨ CRITICAL: image_dataå­—æ®µç¼ºå¤±")
            
            if source == 'input':
                # è¾“å…¥å›¾åƒï¼šä½¿ç”¨ä¼ å…¥çš„tensoræ•°æ®
                if input_tensor is not None:
                    img_array = input_tensor.cpu().numpy()
                    if img_array.max() <= 1.0:
                        img_array = (img_array * 255).astype(np.uint8)
                    else:
                        img_array = img_array.astype(np.uint8)
                    source_image = PILImage.fromarray(img_array)
                    print(f"[LRPG] âœ… åŠ è½½è¾“å…¥å›¾åƒ: {source_image.size}")
                else:
                    print(f"[LRPG] âš ï¸ è¾“å…¥å›¾åƒtensorä¸ºç©ºï¼Œè·³è¿‡æ­¤å›¾å±‚")
                    return canvas  # æ­£ç¡®ï¼šç»§ç»­å¤„ç†å…¶ä»–å›¾å±‚
                    
            elif source == 'upload':
                # ä¸Šä¼ å›¾åƒï¼šè§£ç base64æ•°æ®
                image_data = layer_data.get('image_data')
                if not image_data:
                    print(f"[LRPG] âš ï¸ ä¸Šä¼ å›¾åƒæ•°æ®ä¸ºç©ºï¼Œè·³è¿‡")
                    return canvas
                    
                try:
                    # è§£ç base64å›¾åƒ
                    if image_data.startswith('data:image/'):
                        # å®Œæ•´çš„data URL
                        header, encoded = image_data.split(',', 1)
                        image_bytes = base64.b64decode(encoded)
                    else:
                        # çº¯base64æ•°æ®
                        image_bytes = base64.b64decode(image_data)
                    
                    source_image = PILImage.open(io.BytesIO(image_bytes)).convert('RGB')
                    print(f"[LRPG] âœ… è§£ç ä¸Šä¼ å›¾åƒ: {source_image.size}")
                    
                except Exception as e:
                    print(f"[LRPG] âŒ è§£ç ä¸Šä¼ å›¾åƒå¤±è´¥: {str(e)}")
                    return canvas
                    
            elif source == 'annotation':
                # æ ‡æ³¨å¤„ç†ï¼šç»˜åˆ¶å‡ ä½•å½¢çŠ¶
                print(f"[LRPG] ğŸ¯ å¤„ç†æ ‡æ³¨: {layer_data.get('type', 'unknown')}")
                canvas = self._draw_annotation_on_canvas(canvas, layer_data, canvas_width, canvas_height)
                return canvas
                
            else:
                print(f"[LRPG] â“ æœªçŸ¥å›¾åƒæºç±»å‹: {source}")
                return canvas
            
            # åº”ç”¨å˜æ¢å¹¶åˆæˆåˆ°ç”»å¸ƒ
            transformed_image = self._apply_image_transform(source_image, layer_data)
            canvas = self._composite_image_to_canvas(canvas, transformed_image, layer_data)
            
            return canvas
            
        except Exception as e:
            print(f"[LRPG] âŒ å¤„ç†å›¾å±‚{layer_id}å¤±è´¥: {str(e)}")
            return canvas
    
    def _draw_annotation_on_canvas(self, canvas, layer_data, canvas_width, canvas_height):
        """åœ¨ç”»å¸ƒä¸Šç»˜åˆ¶æ ‡æ³¨"""
        try:
            from PIL import Image as PILImage, ImageDraw
            
            # è·å–æ ‡æ³¨å‚æ•°
            annotation_type = layer_data.get('type', 'rect')
            centerX = layer_data.get('centerX', 0)
            centerY = layer_data.get('centerY', 0)
            width = layer_data.get('width', 100)
            height = layer_data.get('height', 100)
            
            # è®¡ç®—å·¦ä¸Šè§’åæ ‡
            left = centerX - width / 2
            top = centerY - height / 2
            right = centerX + width / 2
            bottom = centerY + height / 2
            
            print(f"[LRPG] ğŸ”² ç»˜åˆ¶{annotation_type}æ ‡æ³¨: ä¸­å¿ƒ({centerX}, {centerY}), å°ºå¯¸({width}, {height})")
            print(f"[LRPG] ğŸ“ æ ‡æ³¨åæ ‡: ({left}, {top}) -> ({right}, {bottom})")
            
            # ğŸ”§ ä»å‰ç«¯æ•°æ®ä¸­è¯»å–é¢œè‰²å’Œé€æ˜åº¦ä¿¡æ¯
            # è·å–é¢œè‰²ä¿¡æ¯ (æ”¯æŒ fill å’Œ stroke å±æ€§)
            color_hex = layer_data.get('fill') or layer_data.get('stroke') or '#ff0000'
            if color_hex.startswith('#'):
                color_hex = color_hex[1:]  # å»æ‰#å·
            
            # å°†åå…­è¿›åˆ¶é¢œè‰²è½¬æ¢ä¸ºRGB
            try:
                r = int(color_hex[0:2], 16)
                g = int(color_hex[2:4], 16) 
                b = int(color_hex[4:6], 16)
            except (ValueError, IndexError):
                r, g, b = 255, 0, 0  # é»˜è®¤çº¢è‰²
            
            # ğŸ”§ è·å–é€æ˜åº¦ä¿¡æ¯ï¼ˆä¼˜åŒ–åçš„å¤šè·¯å¾„æ”¯æŒï¼‰
            # ä¼˜å…ˆçº§ï¼šstyle.opacity > ç›´æ¥å±æ€§ > é»˜è®¤å€¼
            opacity = None
            
            # æ–¹æ³•1ï¼šä»styleå¯¹è±¡è·å–ï¼ˆä¸»è¦è·¯å¾„ï¼‰
            if 'style' in layer_data and layer_data['style'] and 'opacity' in layer_data['style']:
                opacity = layer_data['style'].get('opacity')
                print(f"[LRPG] ğŸ” ä»style.opacityè·å–: {opacity}")
            
            # æ–¹æ³•2ï¼šç›´æ¥ä»layer_dataè·å–ï¼ˆå¤‡ç”¨è·¯å¾„ï¼‰
            elif 'opacity' in layer_data:
                opacity = layer_data.get('opacity')
                print(f"[LRPG] ğŸ” ä»layer_data.opacityè·å–: {opacity}")
            
            # æ–¹æ³•3ï¼šå°è¯•ä»å…¶ä»–å¯èƒ½çš„è·¯å¾„è·å–
            elif 'fill_opacity' in layer_data:
                opacity = layer_data.get('fill_opacity')
                print(f"[LRPG] ğŸ” ä»fill_opacityè·å–: {opacity}")
                
            # é»˜è®¤å€¼
            if opacity is None:
                opacity = 0.5  # é»˜è®¤50%é€æ˜åº¦
                print(f"[LRPG] ğŸ” ä½¿ç”¨é»˜è®¤opacity: {opacity}")
            
            # ç¡®ä¿opacityåœ¨æ­£ç¡®èŒƒå›´å†…
            if opacity > 1:
                opacity = opacity / 100.0  # å¦‚æœæ˜¯ç™¾åˆ†æ¯”å½¢å¼ï¼Œè½¬æ¢ä¸ºå°æ•°
            
            alpha = int(opacity * 255)
            
            # ğŸ”§ è°ƒè¯•ï¼šæ‰“å°styleå†…å®¹ç¡®è®¤ä¿®å¤æ•ˆæœ
            if 'style' in layer_data:
                print(f"[LRPG] ğŸ” styleå†…å®¹: {layer_data.get('style', {})}")
            
            print(f"[LRPG] ğŸ¨ æ ‡æ³¨æ ·å¼: é¢œè‰²=#{color_hex}, é€æ˜åº¦={opacity:.2f} (alpha={alpha})")
            
            # ğŸ”§ ä½¿ç”¨é€æ˜åº¦æ··åˆç»˜åˆ¶æ–¹æ³•
            if opacity < 1.0:  # éœ€è¦é€æ˜åº¦
                # åˆ›å»ºä¸€ä¸ªRGBAé€æ˜å›¾å±‚ç”¨äºç»˜åˆ¶æ ‡æ³¨
                annotation_layer = PILImage.new('RGBA', canvas.size, (0, 0, 0, 0))
                draw_layer = ImageDraw.Draw(annotation_layer)
                
                # è®¾ç½®ç»˜åˆ¶æ ·å¼ï¼ˆRGBAé¢œè‰²ï¼‰
                outline_color = (r, g, b, 255)  # è¾¹æ¡†å®Œå…¨ä¸é€æ˜
                fill_color = (r, g, b, alpha)   # å¡«å……ä½¿ç”¨è®¾ç½®çš„é€æ˜åº¦
                
                if annotation_type == 'rect':
                    # åœ¨é€æ˜å›¾å±‚ä¸Šç»˜åˆ¶çŸ©å½¢
                    draw_layer.rectangle([left, top, right, bottom], outline=outline_color, fill=fill_color, width=2)
                    print(f"[LRPG] âœ… é€æ˜çŸ©å½¢æ ‡æ³¨å·²ç»˜åˆ¶åˆ°å›¾å±‚")
                    
                elif annotation_type == 'circle':
                    # åœ¨é€æ˜å›¾å±‚ä¸Šç»˜åˆ¶åœ†å½¢/æ¤­åœ†
                    draw_layer.ellipse([left, top, right, bottom], outline=outline_color, fill=fill_color, width=2)
                    print(f"[LRPG] âœ… é€æ˜åœ†å½¢æ ‡æ³¨å·²ç»˜åˆ¶åˆ°å›¾å±‚")
                    
                elif annotation_type == 'polygon':
                    # ç»˜åˆ¶å¤šè¾¹å½¢
                    points = layer_data.get('points', [])
                    if points and len(points) >= 3:
                        # å°†pointsè½¬æ¢ä¸ºPILæ ¼å¼çš„åæ ‡åˆ—è¡¨ [(x1,y1), (x2,y2), ...]
                        polygon_coords = []
                        for point in points:
                            if isinstance(point, dict) and 'x' in point and 'y' in point:
                                polygon_coords.extend([point['x'], point['y']])
                            elif isinstance(point, (list, tuple)) and len(point) >= 2:
                                polygon_coords.extend([point[0], point[1]])
                        
                        if len(polygon_coords) >= 6:  # è‡³å°‘3ä¸ªç‚¹
                            draw_layer.polygon(polygon_coords, outline=outline_color, fill=fill_color)
                            print(f"[LRPG] âœ… é€æ˜å¤šè¾¹å½¢æ ‡æ³¨å·²ç»˜åˆ¶åˆ°å›¾å±‚: {len(points)} ä¸ªç‚¹")
                        else:
                            print(f"[LRPG] âš ï¸ å¤šè¾¹å½¢åæ ‡æ•°æ®ä¸è¶³: {polygon_coords}")
                    else:
                        print(f"[LRPG] âš ï¸ å¤šè¾¹å½¢ç¼ºå°‘pointsæ•°æ®: {points}")
                        
                elif annotation_type == 'text' or annotation_type == 'i-text':
                    # ğŸ¯ æ–°å¢ï¼šæ–‡å­—æ ‡æ³¨ç»˜åˆ¶ï¼ˆé€æ˜ç‰ˆï¼‰
                    text_content = layer_data.get('text', 'Text')
                    font_size = layer_data.get('fontSize', 20)
                    
                    try:
                        from PIL import ImageFont
                        import os
                        
                        # ä¸­æ–‡å­—ä½“å›é€€åˆ—è¡¨
                        chinese_fonts = [
                            "C:/Windows/Fonts/msyh.ttf",      # å¾®è½¯é›…é»‘
                            "C:/Windows/Fonts/simsun.ttc",    # å®‹ä½“
                            "C:/Windows/Fonts/simhei.ttf",    # é»‘ä½“
                            "C:/Windows/Fonts/simkai.ttf",    # æ¥·ä½“
                            "msyh.ttf",                       # ç³»ç»Ÿè·¯å¾„å¾®è½¯é›…é»‘
                            "simsun.ttc",                     # ç³»ç»Ÿè·¯å¾„å®‹ä½“
                            "simhei.ttf"                      # ç³»ç»Ÿè·¯å¾„é»‘ä½“
                        ]
                        
                        font = None
                        for font_path in chinese_fonts:
                            try:
                                if os.path.exists(font_path) or not font_path.startswith("C:/"):
                                    font = ImageFont.truetype(font_path, font_size)
                                    print(f"[LRPG] âœ… æˆåŠŸåŠ è½½ä¸­æ–‡å­—ä½“: {font_path}")
                                    break
                            except Exception as e:
                                print(f"[LRPG] âš ï¸ å­—ä½“åŠ è½½å¤±è´¥ {font_path}: {str(e)}")
                                continue
                        
                        if font is None:
                            font = ImageFont.load_default()
                            print(f"[LRPG] âš ï¸ ä½¿ç”¨é»˜è®¤å­—ä½“ï¼Œå¯èƒ½ä¸æ”¯æŒä¸­æ–‡")
                        
                        # è®¡ç®—æ–‡å­—ä½ç½® (centerX, centerY ä¸ºä¸­å¿ƒç‚¹)
                        text_x = int(centerX - width / 2)
                        text_y = int(centerY - height / 2)
                        
                        # åœ¨é€æ˜å›¾å±‚ä¸Šç»˜åˆ¶æ–‡å­—
                        draw_layer.text((text_x, text_y), text_content, font=font, fill=fill_color)
                        print(f"[LRPG] âœ… é€æ˜æ–‡å­—æ ‡æ³¨å·²ç»˜åˆ¶: '{text_content}'")
                        
                    except Exception as e:
                        print(f"[LRPG] âŒ æ–‡å­—æ ‡æ³¨ç»˜åˆ¶å¤±è´¥: {str(e)}")
                        # å›é€€ï¼šä½¿ç”¨åŸºæœ¬ç»˜åˆ¶
                        draw_layer.text((int(centerX), int(centerY)), text_content, fill=fill_color)
                        
                else:
                    print(f"[LRPG] âš ï¸ æœªæ”¯æŒçš„æ ‡æ³¨ç±»å‹: {annotation_type}")
                
                # ğŸ¨ å°†é€æ˜å›¾å±‚æ··åˆåˆ°ä¸»ç”»å¸ƒä¸Š
                if canvas.mode != 'RGBA':
                    canvas = canvas.convert('RGBA')
                canvas = PILImage.alpha_composite(canvas, annotation_layer)
                # è½¬æ¢å›RGBï¼ˆå¦‚æœéœ€è¦ï¼‰
                if canvas.mode == 'RGBA':
                    # åˆ›å»ºç™½è‰²èƒŒæ™¯å¹¶åˆæˆ
                    background = PILImage.new('RGB', canvas.size, (255, 255, 255))
                    background.paste(canvas, mask=canvas.split()[-1])  # ä½¿ç”¨alphaé€šé“ä½œä¸ºmask
                    canvas = background
                    
                print(f"[LRPG] âœ… é€æ˜æ ‡æ³¨å·²æ··åˆåˆ°ä¸»ç”»å¸ƒ")
                
            else:  # å®Œå…¨ä¸é€æ˜ï¼Œä½¿ç”¨åŸæ¥çš„æ–¹æ³•
                draw = ImageDraw.Draw(canvas)
                # è®¾ç½®ç»˜åˆ¶æ ·å¼ï¼ˆRGBé¢œè‰²ï¼‰
                outline_color = (r, g, b)
                fill_color = (r, g, b)
                
                if annotation_type == 'rect':
                    # ç»˜åˆ¶çŸ©å½¢
                    draw.rectangle([left, top, right, bottom], outline=outline_color, fill=fill_color, width=2)
                    print(f"[LRPG] âœ… ä¸é€æ˜çŸ©å½¢æ ‡æ³¨å·²ç»˜åˆ¶")
                    
                elif annotation_type == 'circle':
                    # ç»˜åˆ¶åœ†å½¢/æ¤­åœ†
                    draw.ellipse([left, top, right, bottom], outline=outline_color, fill=fill_color, width=2)
                    print(f"[LRPG] âœ… ä¸é€æ˜åœ†å½¢æ ‡æ³¨å·²ç»˜åˆ¶")
                    
                elif annotation_type == 'polygon':
                    # ç»˜åˆ¶å¤šè¾¹å½¢
                    points = layer_data.get('points', [])
                    if points and len(points) >= 3:
                        # å°†pointsè½¬æ¢ä¸ºPILæ ¼å¼çš„åæ ‡åˆ—è¡¨ [(x1,y1), (x2,y2), ...]
                        polygon_coords = []
                        for point in points:
                            if isinstance(point, dict) and 'x' in point and 'y' in point:
                                polygon_coords.extend([point['x'], point['y']])
                            elif isinstance(point, (list, tuple)) and len(point) >= 2:
                                polygon_coords.extend([point[0], point[1]])
                        
                        if len(polygon_coords) >= 6:  # è‡³å°‘3ä¸ªç‚¹
                            draw.polygon(polygon_coords, outline=outline_color, fill=fill_color)
                            print(f"[LRPG] âœ… ä¸é€æ˜å¤šè¾¹å½¢æ ‡æ³¨å·²ç»˜åˆ¶: {len(points)} ä¸ªç‚¹")
                        else:
                            print(f"[LRPG] âš ï¸ å¤šè¾¹å½¢åæ ‡æ•°æ®ä¸è¶³: {polygon_coords}")
                    else:
                        print(f"[LRPG] âš ï¸ å¤šè¾¹å½¢ç¼ºå°‘pointsæ•°æ®: {points}")
                        
                elif annotation_type == 'text' or annotation_type == 'i-text':
                    # ğŸ¯ æ–°å¢ï¼šæ–‡å­—æ ‡æ³¨ç»˜åˆ¶ï¼ˆä¸é€æ˜ç‰ˆï¼‰
                    text_content = layer_data.get('text', 'Text')
                    font_size = layer_data.get('fontSize', 20)
                    
                    try:
                        from PIL import ImageFont
                        import os
                        
                        # ä¸­æ–‡å­—ä½“å›é€€åˆ—è¡¨
                        chinese_fonts = [
                            "C:/Windows/Fonts/msyh.ttf",      # å¾®è½¯é›…é»‘
                            "C:/Windows/Fonts/simsun.ttc",    # å®‹ä½“
                            "C:/Windows/Fonts/simhei.ttf",    # é»‘ä½“
                            "C:/Windows/Fonts/simkai.ttf",    # æ¥·ä½“
                            "msyh.ttf",                       # ç³»ç»Ÿè·¯å¾„å¾®è½¯é›…é»‘
                            "simsun.ttc",                     # ç³»ç»Ÿè·¯å¾„å®‹ä½“
                            "simhei.ttf"                      # ç³»ç»Ÿè·¯å¾„é»‘ä½“
                        ]
                        
                        font = None
                        for font_path in chinese_fonts:
                            try:
                                if os.path.exists(font_path) or not font_path.startswith("C:/"):
                                    font = ImageFont.truetype(font_path, font_size)
                                    print(f"[LRPG] âœ… æˆåŠŸåŠ è½½ä¸­æ–‡å­—ä½“: {font_path}")
                                    break
                            except Exception as e:
                                print(f"[LRPG] âš ï¸ å­—ä½“åŠ è½½å¤±è´¥ {font_path}: {str(e)}")
                                continue
                        
                        if font is None:
                            font = ImageFont.load_default()
                            print(f"[LRPG] âš ï¸ ä½¿ç”¨é»˜è®¤å­—ä½“ï¼Œå¯èƒ½ä¸æ”¯æŒä¸­æ–‡")
                        
                        # è®¡ç®—æ–‡å­—ä½ç½® (centerX, centerY ä¸ºä¸­å¿ƒç‚¹)
                        text_x = int(centerX - width / 2)
                        text_y = int(centerY - height / 2)
                        
                        # ç»˜åˆ¶æ–‡å­—
                        draw.text((text_x, text_y), text_content, font=font, fill=fill_color)
                        print(f"[LRPG] âœ… ä¸é€æ˜æ–‡å­—æ ‡æ³¨å·²ç»˜åˆ¶: '{text_content}'")
                        
                    except Exception as e:
                        print(f"[LRPG] âŒ æ–‡å­—æ ‡æ³¨ç»˜åˆ¶å¤±è´¥: {str(e)}")
                        # å›é€€ï¼šä½¿ç”¨åŸºæœ¬ç»˜åˆ¶
                        draw.text((int(centerX), int(centerY)), text_content, fill=fill_color)
                        
                else:
                    print(f"[LRPG] âš ï¸ æœªæ”¯æŒçš„æ ‡æ³¨ç±»å‹: {annotation_type}")
            
            return canvas
            
        except Exception as e:
            print(f"[LRPG] âŒ ç»˜åˆ¶æ ‡æ³¨å¤±è´¥: {str(e)}")
            return canvas
    
    def _apply_image_transform(self, image, layer_data):
        """å¯¹å›¾åƒåº”ç”¨å˜æ¢"""
        try:
            from PIL import Image as PILImage
            # è·å–å˜æ¢å‚æ•°
            scaleX = layer_data.get('scaleX', 1)
            scaleY = layer_data.get('scaleY', 1)
            angle = layer_data.get('angle', 0)
            flipX = layer_data.get('flipX', False)
            flipY = layer_data.get('flipY', False)
            
            # åº”ç”¨ç¼©æ”¾
            if scaleX != 1 or scaleY != 1:
                new_width = int(image.width * scaleX)
                new_height = int(image.height * scaleY)
                image = image.resize((new_width, new_height), PILImage.LANCZOS)
                print(f"[LRPG] ğŸ“ å›¾åƒç¼©æ”¾: {scaleX}x{scaleY} -> {image.size}")
            
            # åº”ç”¨æ—‹è½¬
            if angle != 0:
                image = image.rotate(-angle, expand=True, fillcolor=(255, 255, 255))
                print(f"[LRPG] ğŸ”„ å›¾åƒæ—‹è½¬: {angle}åº¦")
            
            # åº”ç”¨ç¿»è½¬
            if flipX:
                image = image.transpose(PILImage.FLIP_LEFT_RIGHT)
                print(f"[LRPG] â†”ï¸ æ°´å¹³ç¿»è½¬")
            if flipY:
                image = image.transpose(PILImage.FLIP_TOP_BOTTOM)
                print(f"[LRPG] â†•ï¸ å‚ç›´ç¿»è½¬")
            
            return image
            
        except Exception as e:
            print(f"[LRPG] âŒ å›¾åƒå˜æ¢å¤±è´¥: {str(e)}")
            return image
    
    def _composite_image_to_canvas(self, canvas, image, layer_data):
        """å°†å˜æ¢åçš„å›¾åƒåˆæˆåˆ°ç”»å¸ƒä¸Š"""
        try:
            from PIL import Image as PILImage
            # è®¡ç®—ç²˜è´´ä½ç½®ï¼ˆä»ä¸­å¿ƒç‚¹åæ ‡è½¬æ¢ä¸ºå·¦ä¸Šè§’åæ ‡ï¼‰
            centerX = layer_data.get('centerX', 0)
            centerY = layer_data.get('centerY', 0)
            
            left = int(centerX - image.width / 2)
            top = int(centerY - image.height / 2)
            
            print(f"[LRPG] ğŸ“ å›¾åƒå®šä½: ä¸­å¿ƒ({centerX}, {centerY}) -> å·¦ä¸Šè§’({left}, {top})")
            
            # åˆ›å»ºå¸¦é€æ˜åº¦çš„å›¾åƒç”¨äºåˆæˆ
            if image.mode != 'RGBA':
                image = image.convert('RGBA')
            
            # ç²˜è´´åˆ°ç”»å¸ƒ
            if canvas.mode != 'RGBA':
                canvas = canvas.convert('RGBA')
            
            canvas.paste(image, (left, top), image)
            
            # è½¬æ¢å›RGB
            if canvas.mode == 'RGBA':
                canvas = canvas.convert('RGB')
            
            print(f"[LRPG] âœ… å›¾åƒå·²åˆæˆåˆ°ç”»å¸ƒ")
            return canvas
            
        except Exception as e:
            print(f"[LRPG] âŒ å›¾åƒåˆæˆå¤±è´¥: {str(e)}")
            return canvas
            
    def _apply_single_layer_transform(self, canvas, layer_data, draw, actual_canvas_width, actual_canvas_height):
        """å¯¹å•ä¸ªå›¾å±‚åº”ç”¨å˜æ¢"""
        try:
            if not layer_data:
                return canvas
                
            # âœ… LRPGç»Ÿä¸€æ ¼å¼ï¼šç›´æ¥æå–å‚æ•°
            layer_type = layer_data.get('type', 'image')
            centerX = layer_data.get('centerX', 0)
            centerY = layer_data.get('centerY', 0)
            scaleX = layer_data.get('scaleX', 1)
            scaleY = layer_data.get('scaleY', 1)
            angle = layer_data.get('angle', 0)
            width = layer_data.get('width', 100)
            height = layer_data.get('height', 100)
            flipX = layer_data.get('flipX', False)
            flipY = layer_data.get('flipY', False)
            crop_path = layer_data.get('crop_path', [])
            
            print(f"[LRPG] ğŸ“ LRPGå˜æ¢å‚æ•°:")
            print(f"  - ä¸­å¿ƒç‚¹: ({centerX:.1f}, {centerY:.1f})")
            print(f"  - ç¼©æ”¾: {scaleX:.3f} x {scaleY:.3f}")
            print(f"  - æ—‹è½¬: {angle:.1f}Â°")
            print(f"  - ç¿»è½¬: X={flipX}, Y={flipY}")
            print(f"  - è£åˆ‡: {len(crop_path)} ä¸ªç‚¹")
            
            # âœ… LRPGæ¶æ„ï¼šåªå¯¹æ ‡æ³¨å›¾å±‚åº”ç”¨å®šä½å˜æ¢ï¼Œè¾“å…¥å›¾åƒç›´æ¥å¤„ç†
            if layer_type != 'image':
                return self._apply_lrpg_transform_to_image(
                    canvas, centerX, centerY, scaleX, scaleY, angle, 
                    flipX, flipY, crop_path
                )
            
            if layer_type == 'image':
                # ğŸš€ LRPGæ¶æ„ï¼šè¾“å…¥å›¾åƒç›´æ¥å˜æ¢ï¼Œæ— éœ€é‡æ–°å®šä½
                print(f"[LRPG] ğŸ–¼ï¸ å¤„ç†è¾“å…¥å›¾åƒå˜æ¢")
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦åº”ç”¨å˜æ¢
                needs_transform = (abs(angle) > 0.1 or abs(scaleX - 1) > 0.01 or 
                                 abs(scaleY - 1) > 0.01 or flipX or flipY)
                
                if needs_transform:
                    print(f"[LRPG] ğŸ”§ åœ¨å›ºå®šç”»å¸ƒ{actual_canvas_width}x{actual_canvas_height}ä¸Šåº”ç”¨å›¾åƒå˜æ¢:")
                    print(f"  - ç¼©æ”¾: ({scaleX:.3f}, {scaleY:.3f})")  
                    print(f"  - æ—‹è½¬: {angle:.1f}Â°")
                    print(f"  - ç¿»è½¬: X={flipX}, Y={flipY}")
                    
                    # âœ… ä¿æŒç”»å¸ƒå°ºå¯¸ï¼Œåœ¨ç”»å¸ƒä¸Šåº”ç”¨å˜æ¢
                    # 1. å…ˆå¯¹å›¾åƒåº”ç”¨å˜æ¢
                    work_image = canvas.copy()
                    
                    if abs(scaleX - 1) > 0.01 or abs(scaleY - 1) > 0.01:
                        new_width = int(canvas.size[0] * scaleX)
                        new_height = int(canvas.size[1] * scaleY)
                        work_image = work_image.resize((new_width, new_height), PILImage.Resampling.LANCZOS)
                        print(f"[LRPG] ğŸ“ å›¾åƒç¼©æ”¾è‡³: {new_width}x{new_height}")
                        
                    if flipX:
                        work_image = work_image.transpose(PILImage.Transpose.FLIP_LEFT_RIGHT)
                        print(f"[LRPG] â†”ï¸ å›¾åƒXè½´ç¿»è½¬")
                    if flipY:
                        work_image = work_image.transpose(PILImage.Transpose.FLIP_TOP_BOTTOM) 
                        print(f"[LRPG] â†•ï¸ å›¾åƒYè½´ç¿»è½¬")
                        
                    if abs(angle) > 0.1:
                        work_image = work_image.rotate(-angle, expand=True, fillcolor=(255, 255, 255))
                        print(f"[LRPG] ğŸ”„ å›¾åƒæ—‹è½¬: {angle}Â°")
                    
                    # 2. åˆ›å»ºå›ºå®šå°ºå¯¸ç”»å¸ƒå¹¶æŒ‰å‰ç«¯ä½ç½®æ”¾ç½®å˜æ¢åçš„å›¾åƒ
                    final_canvas = PILImage.new('RGB', (actual_canvas_width, actual_canvas_height), (255, 255, 255))
                    
                    # âœ… LRPGç»Ÿä¸€åæ ‡ç³»ï¼šæ¨¡ä»¿lg_toolsï¼Œä¸­å¿ƒç‚¹è½¬å·¦ä¸Šè§’ï¼ˆPILæ ‡å‡†ï¼‰
                    work_width, work_height = work_image.size
                    paste_x = int(centerX - work_width / 2)
                    paste_y = int(centerY - work_height / 2)
                    
                    print(f"[LRPG] ğŸ“ ç»Ÿä¸€åæ ‡è½¬æ¢: ä¸­å¿ƒç‚¹({centerX}, {centerY}) -> å·¦ä¸Šè§’({paste_x}, {paste_y})")
                    
                    # ç¡®ä¿å›¾åƒä¸å®Œå…¨è¶…å‡ºç”»å¸ƒèŒƒå›´
                    paste_x = max(-work_width//2, min(paste_x, actual_canvas_width - work_width//2))
                    paste_y = max(-work_height//2, min(paste_y, actual_canvas_height - work_height//2))
                    
                    print(f"[LRPG] ğŸ¯ è¾¹ç•Œä¿®æ­£åç²˜è´´ä½ç½®: ({paste_x}, {paste_y})")
                    
                    final_canvas.paste(work_image, (paste_x, paste_y))
                    canvas = final_canvas
                    
                    print(f"[LRPG] âœ… å›¾åƒå˜æ¢å®Œæˆï¼Œå˜æ¢åå›¾åƒ{work_width}x{work_height}å·²æ”¾ç½®åœ¨{actual_canvas_width}x{actual_canvas_height}ç”»å¸ƒçš„({paste_x}, {paste_y})ä½ç½®")
                else:
                    print(f"[LRPG] â„¹ï¸ è¾“å…¥å›¾åƒæ— éœ€å˜æ¢ï¼Œä¿æŒç”»å¸ƒå°ºå¯¸{actual_canvas_width}x{actual_canvas_height}")
                
                # âœ‚ï¸ å¤„ç†è¾“å…¥å›¾åƒçš„è£åˆ‡è·¯å¾„
                if len(crop_path) >= 3:
                    print(f"[LRPG] âœ‚ï¸ å¯¹è¾“å…¥å›¾åƒåº”ç”¨è£åˆ‡ï¼Œè·¯å¾„ç‚¹æ•°: {len(crop_path)}")
                    canvas = self._apply_lrpg_crop(canvas, crop_path)
                    print(f"[LRPG] âœ… è¾“å…¥å›¾åƒè£åˆ‡å®Œæˆ")
                else:
                    if len(crop_path) == 0:
                        print(f"[LRPG] âœ… è¾“å…¥å›¾åƒæ— éœ€è£åˆ‡ - æ¥æ”¶åˆ°å·²å¤„ç†å›¾åƒæˆ–æ— è£åˆ‡æ“ä½œ")
                    else:
                        print(f"[LRPG] âš ï¸ è£åˆ‡è·¯å¾„ç‚¹æ•°ä¸è¶³({len(crop_path)}ä¸ª)ï¼Œè·³è¿‡è£åˆ‡")
            
            return canvas
            
        except Exception as e:
            print(f"[LRPG] âŒ å•å›¾å±‚å˜æ¢å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            return canvas
    
    def _apply_crop_to_pil(self, pil_image, crop_transforms):
        """å¯¹PILå›¾åƒåº”ç”¨è£åˆ‡å˜æ¢"""
        try:
            from PIL import Image, ImageDraw
            import numpy as np
            
            for crop_transform in crop_transforms:
                if crop_transform.get('type') == 'crop_mask':
                    crop_path = crop_transform.get('crop_path', [])
                    if len(crop_path) < 3:
                        continue
                    
                    # åˆ›å»ºè’™ç‰ˆ
                    mask = Image.new('L', pil_image.size, 0)
                    draw = ImageDraw.Draw(mask)
                    
                    # è½¬æ¢è·¯å¾„ç‚¹
                    polygon_points = [(int(point['x']), int(point['y'])) for point in crop_path]
                    draw.polygon(polygon_points, fill=255)
                    
                    # åº”ç”¨è’™ç‰ˆ
                    result = Image.new('RGBA', pil_image.size, (0, 0, 0, 0))
                    result.paste(pil_image, mask=mask)
                    pil_image = result.convert('RGB')
                    
            return pil_image
        except Exception as e:
            print(f"[LRPG] âŒ PILè£åˆ‡å¤±è´¥: {str(e)}")
            return pil_image
    
    def _apply_crop_transform(self, image, crop_transform):
        """åº”ç”¨Transform-Firstè£åˆ‡å˜æ¢åˆ°å›¾åƒ"""
        try:
            import cv2
            import numpy as np
            from PIL import Image, ImageDraw
            
            # è·å–è£åˆ‡è·¯å¾„ç‚¹
            crop_path = crop_transform.get('crop_path', [])
            if len(crop_path) < 3:
                print(f"[LRPG] âš ï¸ è£åˆ‡è·¯å¾„ç‚¹æ•°ä¸è¶³ï¼Œè·³è¿‡è£åˆ‡")
                return image
            
            # å°†tensorè½¬æ¢ä¸ºnumpyæ•°ç»„
            if len(image.shape) == 4:
                img_array = image[0].numpy()  # å–ç¬¬ä¸€ä¸ªbatch
            else:
                img_array = image.numpy()
                
            # ç¡®ä¿å€¼åœ¨0-255èŒƒå›´å†…
            if img_array.max() <= 1.0:
                img_array = (img_array * 255).astype(np.uint8)
            else:
                img_array = img_array.astype(np.uint8)
            
            height, width = img_array.shape[:2]
            
            # åˆ›å»ºè’™ç‰ˆ
            mask = Image.new('L', (width, height), 0)
            draw = ImageDraw.Draw(mask)
            
            # å°†è£åˆ‡è·¯å¾„è½¬æ¢ä¸ºPILåæ ‡
            polygon_points = [(int(point['x']), int(point['y'])) for point in crop_path]
            
            # ç»˜åˆ¶è£åˆ‡åŒºåŸŸï¼ˆç™½è‰²ä¸ºä¿ç•™åŒºåŸŸï¼‰
            draw.polygon(polygon_points, fill=255)
            
            # å°†è’™ç‰ˆè½¬æ¢ä¸ºnumpyæ•°ç»„
            mask_array = np.array(mask)
            
            # åº”ç”¨è’™ç‰ˆåˆ°å›¾åƒ
            if len(img_array.shape) == 3:  # RGBå›¾åƒ
                # å°†è’™ç‰ˆåº”ç”¨åˆ°æ¯ä¸ªé€šé“
                for i in range(3):
                    img_array[:, :, i] = np.where(mask_array > 0, img_array[:, :, i], 0)
            
            # è½¬æ¢å›tensor
            result_tensor = torch.from_numpy(img_array.astype(np.float32) / 255.0)
            
            # ç¡®ä¿ç»´åº¦æ­£ç¡®
            if len(result_tensor.shape) == 3:
                result_tensor = result_tensor.unsqueeze(0)
            
            print(f"[LRPG] âœ‚ï¸ è£åˆ‡å˜æ¢å®Œæˆï¼Œå¤„ç†äº† {len(polygon_points)} ä¸ªè·¯å¾„ç‚¹")
            return result_tensor
            
        except Exception as e:
            print(f"[LRPG] âŒ è£åˆ‡å˜æ¢å¤±è´¥: {str(e)}")
            return image  # å¤±è´¥æ—¶è¿”å›åŸå›¾
    
    def _generate_transform_based_prompt(self, transform_data, user_prompt, constraint_prompts, decorative_prompts, 
                                       operation_type="custom", target_description=""):
        """åŸºäºTransformæ•°æ®ç”Ÿæˆæç¤ºè¯"""
        if user_prompt and user_prompt.strip():
            print(f"[LRPG] âœ… ä½¿ç”¨ç”¨æˆ·ç¼–è¾‘çš„æç¤ºè¯")
            return user_prompt.strip()
        
        # åŸºäºoperation_typeç”Ÿæˆç»“æ„åŒ–æç¤ºè¯
        print(f"[LRPG] ğŸ¤– è‡ªåŠ¨ç”Ÿæˆæç¤ºè¯ - æ“ä½œç±»å‹: {operation_type}")
        
        # æ“ä½œç±»å‹æ¨¡æ¿
        operation_templates = {
            'add_object': lambda desc: f"add {desc or 'a new object'} to the image",
            'change_color': lambda desc: f"make the selected area {desc or 'red'}",
            'change_style': lambda desc: f"turn the selected area into {desc or 'cartoon'} style",
            'replace_object': lambda desc: f"replace the selected area with {desc or 'a different object'}",
            'remove_object': lambda desc: "remove the selected area",
            'enhance_quality': lambda desc: "enhance the image quality",
            'custom': lambda desc: desc or "apply modifications to the image"
        }
        
        # ç”ŸæˆåŸºç¡€æç¤ºè¯
        template_func = operation_templates.get(operation_type, operation_templates['custom'])
        base_prompt = template_func(target_description)
        
        prompt_parts = [base_prompt]
        
        # å¦‚æœæœ‰transformæ•°æ®ï¼Œæ·»åŠ å˜æ¢ä¿¡æ¯
        if transform_data:
            layer_count = len(transform_data)
            print(f"[LRPG] ğŸ“Š åº”ç”¨äº† {layer_count} ä¸ªå›¾å±‚å˜æ¢")
        
        # æ·»åŠ çº¦æŸæç¤ºè¯
        if constraint_prompts:
            prompt_parts.extend(constraint_prompts)
        
        # æ·»åŠ è£…é¥°æç¤ºè¯  
        if decorative_prompts:
            prompt_parts.extend(decorative_prompts)
        
        final_prompt = ", ".join(prompt_parts)
        print(f"[LRPG] ğŸ¤– è‡ªåŠ¨ç”ŸæˆTransformæç¤ºè¯: {final_prompt[:100]}...")
        
        return final_prompt
    
    def _build_enhanced_prompts(self, constraint_prompts, decorative_prompts):
        """æ„å»ºå¢å¼ºæç¤ºè¯JSON"""
        enhanced_data = {
            "constraint_prompts": constraint_prompts,
            "decorative_prompts": decorative_prompts,
            "version": "transform_first_1.0"
        }
        return json.dumps(enhanced_data)
    
    # ===== Kontextåˆ†è¾¨ç‡ç‹¬ç«‹HDè¿˜åŸç®—æ³•æ ¸å¿ƒæ–¹æ³• =====
    
    def _calculate_hd_scale(self, transform_data, canvas_data, image_shape):
        """è®¡ç®—HDè¿˜åŸç¼©æ”¾æ¯”ä¾‹ - Kontextåˆ†è¾¨ç‡ç‹¬ç«‹ç®—æ³•"""
        try:
            # è·å–ç”»å¸ƒå®é™…å°ºå¯¸
            canvas_width = canvas_data.get('width', 800)
            canvas_height = canvas_data.get('height', 600)
            
            # è·å–å›¾åƒå®é™…åˆ†è¾¨ç‡
            if len(image_shape) >= 3:
                img_height, img_width = image_shape[1], image_shape[2]
            else:
                img_height, img_width = image_shape[0], image_shape[1]
            
            # æ‰¾åˆ°ä¸»è¦çš„å›¾åƒå›¾å±‚æ¥è®¡ç®—ç¼©æ”¾æ¯”ä¾‹
            image_layer = None
            for layer_id, layer_data in transform_data.items():
                if layer_data.get('type') == 'image':
                    image_layer = layer_data
                    break
            
            if not image_layer:
                print(f"[LRPG] âš ï¸ æœªæ‰¾åˆ°å›¾åƒå›¾å±‚ï¼Œä½¿ç”¨é»˜è®¤ç¼©æ”¾æ¯”ä¾‹1.0")
                return 1.0
            
            # âœ… Kontextç®—æ³•ï¼šè®¡ç®—å‰ç«¯æ˜¾ç¤ºvsé«˜æ¸…åŸå›¾çš„æ¯”ä¾‹
            frontend_width = image_layer.get('width', img_width)
            frontend_height = image_layer.get('height', img_height)
            
            # å¤„ç†æ˜¾ç¤ºç¼©æ”¾çš„å½±å“
            display_scale_info = image_layer.get('display_scale', {})
            if display_scale_info.get('optimized', False):
                frontend_scale = display_scale_info.get('scaleX', 1)
                actual_frontend_width = frontend_width * frontend_scale
                actual_frontend_height = frontend_height * frontend_scale
            else:
                actual_frontend_width = frontend_width
                actual_frontend_height = frontend_height
            
            # è®¡ç®—HDè¿˜åŸæ¯”ä¾‹
            scale_x = img_width / actual_frontend_width if actual_frontend_width > 0 else 1.0
            scale_y = img_height / actual_frontend_height if actual_frontend_height > 0 else 1.0
            
            # ä½¿ç”¨æœ€å°çš„ç¼©æ”¾æ¯”ä¾‹ä¿æŒå®½é«˜æ¯”
            hd_scale = min(scale_x, scale_y)
            
            print(f"[LRPG] ğŸ”¬ HDç¼©æ”¾æ¯”ä¾‹è®¡ç®—:")
            print(f"  - åŸå›¾å°ºå¯¸: {img_width} x {img_height}")
            print(f"  - å‰ç«¯å°ºå¯¸: {actual_frontend_width:.1f} x {actual_frontend_height:.1f}")
            print(f"  - ç¼©æ”¾æ¯”ä¾‹: X={scale_x:.3f}, Y={scale_y:.3f}")
            print(f"  - æœ€ç»ˆHDæ¯”ä¾‹: {hd_scale:.3f}")
            
            return max(hd_scale, 0.1)  # ç¡®ä¿æ¯”ä¾‹ä¸ä¼šè¿‡å°
            
        except Exception as e:
            print(f"[LRPG] âŒ HDç¼©æ”¾æ¯”ä¾‹è®¡ç®—å¤±è´¥: {str(e)}")
            return 1.0
    
    def _scale_hd_transforms(self, transform_data, scale):
        """å°†å‰ç«¯æ˜¾ç¤ºå˜æ¢æ˜ å°„åˆ°é«˜åˆ†è¾¨ç‡å˜æ¢ - Kontextåˆ†è¾¨ç‡ç‹¬ç«‹ç®—æ³•"""
        try:
            hd_transform_data = {}
            
            for layer_id, layer_data in transform_data.items():
                if layer_data.get('type') == 'image':
                    # âœ… Kontextç®—æ³•ï¼šå›¾åƒå›¾å±‚çš„HDå˜æ¢æ˜ å°„
                    hd_transform_data[layer_id] = {
                        'centerX': layer_data.get('centerX', 0) * scale,     # ä¸­å¿ƒç‚¹XæŒ‰æ¯”ä¾‹æ˜ å°„
                        'centerY': layer_data.get('centerY', 0) * scale,     # ä¸­å¿ƒç‚¹YæŒ‰æ¯”ä¾‹æ˜ å°„
                        'scaleX': layer_data.get('scaleX', 1) * scale,       # ç¼©æ”¾å åŠ 
                        'scaleY': layer_data.get('scaleY', 1) * scale,       # ç¼©æ”¾å åŠ 
                        'angle': layer_data.get('angle', 0),                # è§’åº¦ä¿æŒä¸å˜
                        'width': layer_data.get('width', 100),              # åŸå§‹å°ºå¯¸ä¸å˜
                        'height': layer_data.get('height', 100),            # åŸå§‹å°ºå¯¸ä¸å˜
                        'flipX': layer_data.get('flipX', False),            # ç¿»è½¬ä¸å˜
                        'flipY': layer_data.get('flipY', False),            # ç¿»è½¬ä¸å˜
                        'type': layer_data.get('type'),
                        'hd_scale_applied': scale,
                        # ğŸš€ CRITICAL: ä¿ç•™å›¾åƒæºä¿¡æ¯å’Œæ•°æ®
                        'source': layer_data.get('source'),
                        'image_data': layer_data.get('image_data'),
                        '_debug_fabricId': layer_data.get('_debug_fabricId'),
                        '_debug_name': layer_data.get('_debug_name'),
                        'crop_path': layer_data.get('crop_path', [])
                    }
                else:
                    # æ ‡æ³¨å›¾å±‚çš„HDå˜æ¢æ˜ å°„
                    hd_layer_data = {
                        'centerX': layer_data.get('centerX', 0) * scale,
                        'centerY': layer_data.get('centerY', 0) * scale,
                        'scaleX': layer_data.get('scaleX', 1),              # æ ‡æ³¨ç¼©æ”¾ä¿æŒä¸å˜
                        'scaleY': layer_data.get('scaleY', 1),
                        'angle': layer_data.get('angle', 0),
                        'width': layer_data.get('width', 100) * scale,      # æ ‡æ³¨å°ºå¯¸æŒ‰æ¯”ä¾‹æ˜ å°„
                        'height': layer_data.get('height', 100) * scale,
                        'flipX': layer_data.get('flipX', False),
                        'flipY': layer_data.get('flipY', False),
                        'type': layer_data.get('type'),
                        'style': layer_data.get('style', {}),
                        'hd_scale_applied': scale,
                        # ğŸš€ CRITICAL: ä¿ç•™æ ‡æ³¨æºä¿¡æ¯
                        'source': layer_data.get('source'),
                        '_debug_fabricId': layer_data.get('_debug_fabricId'),
                        '_debug_name': layer_data.get('_debug_name')
                    }
                    
                    # ğŸ”§ é’ˆå¯¹ä¸åŒç±»å‹æ ‡æ³¨æ·»åŠ ç‰¹æ®Šå±æ€§
                    annotation_type = layer_data.get('type')
                    if annotation_type == 'polygon':
                        # ä¸ºå¤šè¾¹å½¢æ·»åŠ pointsæ•°æ®ï¼Œå¹¶ç¼©æ”¾åæ ‡
                        original_points = layer_data.get('points', [])
                        if original_points:
                            hd_layer_data['points'] = [
                                {'x': point.get('x', 0) * scale, 'y': point.get('y', 0) * scale}
                                for point in original_points
                            ]
                            print(f"[LRPG] ğŸ¯ HDç¼©æ”¾å¤šè¾¹å½¢points: {len(original_points)} ä¸ªç‚¹ï¼Œç¼©æ”¾æ¯”ä¾‹: {scale}")
                        else:
                            hd_layer_data['points'] = []
                            print(f"[LRPG] âš ï¸ å¤šè¾¹å½¢æ²¡æœ‰pointsæ•°æ®")
                    elif annotation_type == 'path':
                        # ä¸ºè·¯å¾„æ·»åŠ pathæ•°æ®
                        hd_layer_data['path'] = layer_data.get('path', [])
                    elif annotation_type == 'text' or annotation_type == 'i-text':
                        # ğŸ¯ æ–°å¢ï¼šä¸ºæ–‡å­—æ ‡æ³¨æ·»åŠ æ–‡å­—ç›¸å…³æ•°æ®
                        hd_layer_data['text'] = layer_data.get('text', 'Text')
                        hd_layer_data['fontSize'] = layer_data.get('fontSize', 20) * scale  # ğŸ”§ å­—ä½“å¤§å°æŒ‰HDæ¯”ä¾‹ç¼©æ”¾
                        hd_layer_data['fontFamily'] = layer_data.get('fontFamily', 'Arial')
                        hd_layer_data['fontWeight'] = layer_data.get('fontWeight', 'normal')
                        hd_layer_data['textAlign'] = layer_data.get('textAlign', 'left')
                        print(f"[LRPG] ğŸ¯ HDç¼©æ”¾æ–‡å­—æ ‡æ³¨: åŸå§‹å­—ä½“å¤§å°{layer_data.get('fontSize', 20)} -> HDå­—ä½“å¤§å°{hd_layer_data['fontSize']}")
                    
                    hd_transform_data[layer_id] = hd_layer_data
                
                print(f"[LRPG] ğŸ”„ HDæ˜ å°„å›¾å±‚ {layer_id}:")
                print(f"  - åŸå§‹ä¸­å¿ƒ: ({layer_data.get('centerX', 0):.1f}, {layer_data.get('centerY', 0):.1f})")
                print(f"  - HDä¸­å¿ƒ: ({hd_transform_data[layer_id]['centerX']:.1f}, {hd_transform_data[layer_id]['centerY']:.1f})")
            
            return hd_transform_data
            
        except Exception as e:
            print(f"[LRPG] âŒ HDå˜æ¢æ˜ å°„å¤±è´¥: {str(e)}")
            return transform_data
    
    def _apply_affine_transform_on_canvas(self, canvas, centerX, centerY, scaleX, scaleY, angle, flipX, flipY, canvas_width, canvas_height):
        """âœ… Kontextæ ¸å¿ƒï¼šä»¿å°„å˜æ¢çŸ©é˜µåœ¨å›ºå®šç”»å¸ƒå†…æ•°å­¦é‡å»º"""
        try:
            from PIL import Image, ImageDraw
            import numpy as np
            import math
            
            print(f"[LRPG] ğŸ”§ åº”ç”¨ä»¿å°„å˜æ¢:")
            print(f"  - ä¸­å¿ƒ: ({centerX:.1f}, {centerY:.1f})")
            print(f"  - ç¼©æ”¾: ({scaleX:.3f}, {scaleY:.3f})")
            print(f"  - æ—‹è½¬: {angle:.1f}Â°")
            print(f"  - ç¿»è½¬: X={flipX}, Y={flipY}")
            
            # âœ… LRPGæ¶æ„ï¼šåœ¨å›ºå®šç”»å¸ƒå°ºå¯¸å†…åº”ç”¨å˜æ¢
            if abs(angle) > 0.1:
                # ä½¿ç”¨ä»¿å°„å˜æ¢åœ¨ç”»å¸ƒä¸­å¿ƒè¿›è¡Œæ—‹è½¬
                # è®¡ç®—æ—‹è½¬ä¸­å¿ƒç‚¹ï¼ˆåŸºäºç”¨æˆ·åœ¨å‰ç«¯çš„æ“ä½œï¼‰
                rotation_center_x = centerX
                rotation_center_y = centerY
                
                # å¦‚æœæ—‹è½¬ä¸­å¿ƒè¶…å‡ºç”»å¸ƒèŒƒå›´ï¼Œè°ƒæ•´åˆ°ç”»å¸ƒå†…
                rotation_center_x = max(0, min(canvas_width, rotation_center_x))
                rotation_center_y = max(0, min(canvas_height, rotation_center_y))
                
                print(f"[LRPG] ğŸ”„ ä»¥ç‚¹({rotation_center_x:.1f}, {rotation_center_y:.1f})ä¸ºä¸­å¿ƒæ—‹è½¬{angle:.1f}Â°")
                
                # âœ… å…³é”®ï¼šä¿æŒç”»å¸ƒå°ºå¯¸ï¼Œåªåœ¨å†…éƒ¨æ—‹è½¬
                rotated_canvas = canvas.rotate(
                    angle, 
                    center=(rotation_center_x, rotation_center_y), 
                    fillcolor='white',
                    expand=False  # âœ… å…³é”®ï¼šä¸æ‰©å±•ç”»å¸ƒï¼Œä¿æŒå›ºå®šå°ºå¯¸
                )
                
                # ç¡®ä¿ç”»å¸ƒå°ºå¯¸å®Œå…¨ä¸€è‡´
                if rotated_canvas.size != (canvas_width, canvas_height):
                    print(f"[LRPG] âš ï¸ ç”»å¸ƒå°ºå¯¸ä¸ä¸€è‡´ï¼Œè°ƒæ•´: {rotated_canvas.size} -> ({canvas_width}, {canvas_height})")
                    # å¦‚æœå°ºå¯¸ä¸ä¸€è‡´ï¼Œè£å‰ªæˆ–å¡«å……åˆ°ç›®æ ‡å°ºå¯¸
                    temp_canvas = Image.new('RGB', (canvas_width, canvas_height), 'white')
                    
                    # è®¡ç®—å±…ä¸­ç²˜è´´çš„ä½ç½®
                    paste_x = (canvas_width - rotated_canvas.size[0]) // 2
                    paste_y = (canvas_height - rotated_canvas.size[1]) // 2
                    temp_canvas.paste(rotated_canvas, (paste_x, paste_y))
                    rotated_canvas = temp_canvas
                
                canvas = rotated_canvas
                print(f"[LRPG] âœ… æ—‹è½¬å®Œæˆï¼Œä¿æŒç”»å¸ƒå°ºå¯¸: {canvas.size}")
            
            # å¤„ç†ç¿»è½¬å˜æ¢
            if flipX or flipY:
                if flipX and not flipY:
                    canvas = canvas.transpose(Image.FLIP_LEFT_RIGHT)
                    print(f"[LRPG] â†”ï¸ åº”ç”¨Xè½´ç¿»è½¬")
                elif flipY and not flipX:
                    canvas = canvas.transpose(Image.FLIP_TOP_BOTTOM)
                    print(f"[LRPG] â†•ï¸ åº”ç”¨Yè½´ç¿»è½¬")
                elif flipX and flipY:
                    canvas = canvas.transpose(Image.FLIP_LEFT_RIGHT).transpose(Image.FLIP_TOP_BOTTOM)
                    print(f"[LRPG] â†”ï¸â†•ï¸ åº”ç”¨åŒè½´ç¿»è½¬")
            
            # âœ… æœ€ç»ˆéªŒè¯ï¼šç¡®ä¿ç”»å¸ƒå°ºå¯¸å®Œå…¨æ­£ç¡®
            final_size = canvas.size
            if final_size != (canvas_width, canvas_height):
                print(f"[LRPG] ğŸ”§ æœ€ç»ˆå°ºå¯¸è°ƒæ•´: {final_size} -> ({canvas_width}, {canvas_height})")
                canvas = canvas.resize((canvas_width, canvas_height), Image.LANCZOS)
            
            print(f"[LRPG] âœ… ä»¿å°„å˜æ¢å®Œæˆï¼Œæœ€ç»ˆç”»å¸ƒå°ºå¯¸: {canvas.size}")
            return canvas
            
        except Exception as e:
            print(f"[LRPG] âŒ ä»¿å°„å˜æ¢å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            return canvas

    # ===== åºŸå¼ƒæ—§æ–¹æ³•çš„å­˜æ ¹ï¼Œä¿æŒå…¼å®¹æ€§ =====
    
    def _render_annotations_on_image(self, image, layers_data, include_annotation_numbers=True, annotation_data_json=None):
        """
        åºŸå¼ƒæ–¹æ³• - Transform-Firstæ¶æ„ä¸å†ä½¿ç”¨annotationæ¸²æŸ“
        ä¿ç•™å­˜æ ¹ç¡®ä¿å…¼å®¹æ€§
        """
        print("[LRPG] âš ï¸ è°ƒç”¨äº†åºŸå¼ƒçš„_render_annotations_on_imageæ–¹æ³•ï¼Œå·²é‡å®šå‘åˆ°Transform-Firstå¤„ç†")
        return self._apply_transform_first_processing(image, {}, {}, 800, 600)
    
    def _apply_lrpg_transform_to_image(self, original_canvas, center_x, center_y, scale_x, scale_y, angle, flip_x, flip_y, crop_path):
        """LRPGç»Ÿä¸€æ ¼å¼å˜æ¢å¤„ç† - æ­£ç¡®å¤„ç†å›¾åƒåœ¨ç”»å¸ƒä¸Šçš„å®šä½"""
        try:
            print(f"[LRPG] ğŸ¨ åº”ç”¨LRPGå˜æ¢:")
            print(f"  - ä¸­å¿ƒç‚¹: ({center_x:.1f}, {center_y:.1f})")
            print(f"  - ç¼©æ”¾: ({scale_x:.3f}, {scale_y:.3f})")
            print(f"  - æ—‹è½¬: {angle:.1f}Â°")
            print(f"  - ç¿»è½¬: X={flip_x}, Y={flip_y}")
            print(f"  - è£åˆ‡ç‚¹æ•°: {len(crop_path)}")
            
            # è·å–åŸå§‹ç”»å¸ƒå°ºå¯¸
            canvas_width, canvas_height = original_canvas.size
            print(f"[LRPG] ğŸ“ ç”»å¸ƒå°ºå¯¸: {canvas_width}x{canvas_height}")
            
            # åˆ›å»ºå·¥ä½œå›¾åƒå‰¯æœ¬
            work_image = original_canvas.copy()
            
            # 1. åº”ç”¨ç¼©æ”¾å˜æ¢
            if abs(scale_x - 1) > 0.01 or abs(scale_y - 1) > 0.01:
                print(f"[LRPG] ğŸ” åº”ç”¨ç¼©æ”¾å˜æ¢")
                new_width = int(canvas_width * scale_x)
                new_height = int(canvas_height * scale_y) 
                work_image = work_image.resize((new_width, new_height), Image.Resampling.LANCZOS)
            
            # 2. åº”ç”¨ç¿»è½¬å˜æ¢
            if flip_x:
                work_image = work_image.transpose(Image.Transpose.FLIP_LEFT_RIGHT)
                print(f"[LRPG] â†”ï¸ åº”ç”¨Xè½´ç¿»è½¬")
            if flip_y:
                work_image = work_image.transpose(Image.Transpose.FLIP_TOP_BOTTOM)
                print(f"[LRPG] â†•ï¸ åº”ç”¨Yè½´ç¿»è½¬")
            
            # 3. åº”ç”¨æ—‹è½¬å˜æ¢
            if abs(angle) > 0.1:
                work_image = work_image.rotate(-angle, expand=True, fillcolor=(255, 255, 255))
                print(f"[LRPG] ğŸ”„ åº”ç”¨æ—‹è½¬å˜æ¢: {angle}Â°")
            
            # 4. åˆ›å»ºæœ€ç»ˆç”»å¸ƒå¹¶å®šä½å›¾åƒ
            final_canvas = Image.new('RGB', (canvas_width, canvas_height), (255, 255, 255))
            
            # è®¡ç®—å›¾åƒåœ¨ç”»å¸ƒä¸Šçš„ä½ç½®
            img_width, img_height = work_image.size
            
            # ä»ä¸­å¿ƒç‚¹è®¡ç®—å·¦ä¸Šè§’ä½ç½®
            paste_x = int(center_x - img_width / 2)
            paste_y = int(center_y - img_height / 2)
            
            print(f"[LRPG] ğŸ“ å›¾åƒå®šä½: å˜æ¢åå°ºå¯¸ {img_width}x{img_height}, ç²˜è´´ä½ç½® ({paste_x}, {paste_y})")
            
            # ç¡®ä¿ç²˜è´´ä½ç½®åœ¨ç”»å¸ƒèŒƒå›´å†…
            paste_x = max(0, min(paste_x, canvas_width))
            paste_y = max(0, min(paste_y, canvas_height))
            
            # è®¡ç®—å®é™…å¯ç²˜è´´çš„åŒºåŸŸ
            max_width = min(img_width, canvas_width - paste_x)
            max_height = min(img_height, canvas_height - paste_y)
            
            if max_width > 0 and max_height > 0:
                # è£å‰ªå·¥ä½œå›¾åƒåˆ°å¯ç²˜è´´åŒºåŸŸ
                crop_box = (0, 0, max_width, max_height)
                cropped_image = work_image.crop(crop_box)
                final_canvas.paste(cropped_image, (paste_x, paste_y))
                print(f"[LRPG] âœ… å›¾åƒå·²å®šä½åˆ°ç”»å¸ƒ: å®é™…ç²˜è´´åŒºåŸŸ {max_width}x{max_height}")
            else:
                print(f"[LRPG] âš ï¸ å›¾åƒå®Œå…¨è¶…å‡ºç”»å¸ƒèŒƒå›´ï¼Œä½¿ç”¨åŸå§‹å›¾åƒ")
                return original_canvas
            
            # 5. LRPGæ ¼å¼è£åˆ‡å¤„ç†
            if len(crop_path) >= 3:
                print(f"[LRPG] âœ‚ï¸ åº”ç”¨LRPGæ ¼å¼è£åˆ‡")
                final_canvas = self._apply_lrpg_crop(final_canvas, crop_path)
            
            print(f"[LRPG] âœ… LRPGå˜æ¢å®Œæˆ")
            return final_canvas
            
        except Exception as e:
            print(f"[LRPG] âŒ LRPGå˜æ¢å¤±è´¥: {str(e)}")
            return original_canvas

    def _apply_lrpg_crop(self, pil_image, crop_path):
        """åº”ç”¨LRPGæ ¼å¼è£åˆ‡"""
        try:
            from PIL import Image, ImageDraw
            
            # åˆ›å»ºè’™ç‰ˆ
            mask = Image.new('L', pil_image.size, 0)
            draw = ImageDraw.Draw(mask)
            
            # è½¬æ¢è£åˆ‡è·¯å¾„ç‚¹
            polygon_points = [(int(point.get('x', 0)), int(point.get('y', 0))) for point in crop_path]
            draw.polygon(polygon_points, fill=255)
            
            # åº”ç”¨è’™ç‰ˆ
            result = Image.new('RGBA', pil_image.size, (0, 0, 0, 0))
            result.paste(pil_image, mask=mask)
            result = result.convert('RGB')
            
            print(f"[LRPG] OK: LRPGè£åˆ‡å®Œæˆï¼Œä½¿ç”¨ {len(polygon_points)} ä¸ªç‚¹")
            return result
            
        except Exception as e:
            print(f"[LRPG] ERROR: LRPGè£åˆ‡å¤±è´¥: {str(e)}")
            return pil_image

    def _create_fallback_output(self, image = None, error_msg: str = ""):
        """LRPG Transform-Firstæ¶æ„çš„é”™è¯¯å›é€€å¤„ç†"""
        print(f"[LRPG] Transform-Firsté”™è¯¯å›é€€: {error_msg}")
        
        # åˆ›å»ºæœ€å°è¾“å‡º
        if TORCH_AVAILABLE and torch is not None:
            fallback_image = image if image is not None else torch.zeros((1, 800, 600, 3), dtype=torch.float32)
        else:
            # å¦‚æœæ²¡æœ‰torchï¼Œåˆ›å»ºä¸€ä¸ªç®€å•çš„å ä½ç¬¦
            fallback_image = image if image is not None else None
        fallback_prompt = "Transform-Firstå¤„ç†å‡ºç°é”™è¯¯"
        fallback_transform_data = json.dumps({"status": "error", "message": error_msg})
        fallback_instruction = "è¯·æ£€æŸ¥è¾“å…¥æ•°æ®æ ¼å¼"
        
        return (fallback_image, fallback_prompt, fallback_transform_data, fallback_instruction)
    
    def __del__(self):
        """Widgetæ¶æ„æ— éœ€ææ„æ¸…ç†"""
        pass


# Node registration - only if dependencies are available
if TORCH_AVAILABLE and NUMPY_AVAILABLE and COMFY_AVAILABLE:
    NODE_CLASS_MAPPINGS = {
        "VisualPromptEditor": VisualPromptEditor,
    }
    
    NODE_DISPLAY_NAME_MAPPINGS = {
        "VisualPromptEditor": "Visual Prompt Editor",
    }
    
    print("[OK] VisualPromptEditor node registered successfully")
else:
    NODE_CLASS_MAPPINGS = {}
    NODE_DISPLAY_NAME_MAPPINGS = {}
    
    print("[WARN] VisualPromptEditor node skipped due to missing dependencies:")
    if not TORCH_AVAILABLE:
        print("  - Missing: torch")
    if not NUMPY_AVAILABLE:
        print("  - Missing: numpy")
    if not COMFY_AVAILABLE:
        print("  - Missing: ComfyUI dependencies")
