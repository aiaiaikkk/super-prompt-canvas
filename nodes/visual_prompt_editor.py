"""
Visual Prompt Editor Node
Visual prompt editor node for ComfyUI

Combines visual annotation editing and structured prompt generation functionality
Double-click node to open unified editing interface: left side for graphic annotation, right side for prompt editing
"""

import json
import base64
import numpy as np
import torch
from typing import Dict, List, Any, Tuple, Optional
from datetime import datetime

try:
    import comfy.model_management as model_management
    from nodes import MAX_RESOLUTION
    COMFY_AVAILABLE = True
except ImportError:
    COMFY_AVAILABLE = False
    MAX_RESOLUTION = 8192

class VisualPromptEditor:
    """Visual Prompt Editor Node - Unified annotation editing and prompt generation"""
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image": ("IMAGE",),
            },
            "optional": {
                "annotation_data": ("STRING", {"tooltip": "JSON annotation data from frontend editor"}),
                "text_prompt": ("STRING", {"multiline": True, "default": "", "tooltip": "Additional text instructions for the edit"}),
                "prompt_template": ([
                    # å±€éƒ¨ç¼–è¾‘æ¨¡æ¿ (L01-L18) - ğŸ”´ Flux Kontextä¼˜åŒ–
                    "change_color", "change_style", "replace_object", "add_object", "remove_object",
                    "change_texture", "change_pose", "change_expression", "change_clothing", "change_background",
                    "enhance_quality", "blur_background", "adjust_lighting", "resize_object", "enhance_skin_texture",
                    "character_expression", "character_hair", "character_accessories",  # ğŸ”´ æ–°å¢è§’è‰²ç¼–è¾‘
                    
                    # å…¨å±€ç¼–è¾‘æ¨¡æ¿ (G01-G12) - ğŸ”´ Flux Kontextä¼˜åŒ–
                    "global_color_grade", "global_style_transfer", "global_brightness_contrast",
                    "global_hue_saturation", "global_sharpen_blur", "global_noise_reduction",
                    "global_enhance", "global_filter", "character_age", "detail_enhance",
                    "realism_enhance", "camera_operation",  # ğŸ”´ æ–°å¢å…¨å±€å¢å¼º
                    
                    # æ–‡å­—ç¼–è¾‘æ¨¡æ¿ (T01-T05) - ğŸ”´ å…¨æ–°ç±»å‹
                    "text_add", "text_remove", "text_edit", "text_resize", "object_combine",
                    
                    # ä¸“ä¸šæ“ä½œæ¨¡æ¿ (P01-P14) - ğŸ”´ Flux Kontextä¼˜åŒ–
                    "geometric_warp", "perspective_transform", "lens_distortion", "global_perspective",
                    "content_aware_fill", "seamless_removal", "smart_patch",
                    "style_blending", "collage_integration", "texture_mixing",
                    "precision_cutout", "alpha_composite", "mask_feathering", "depth_composite",
                    
                    "custom"
                ], {"default": "change_color"}),
            }
        }
    
    RETURN_TYPES = ("IMAGE", "STRING")
    RETURN_NAMES = (
        "processed_image", 
        "structured_prompt"
    )
    FUNCTION = "visual_prompt_edit"
    CATEGORY = "kontext/core"
    DESCRIPTION = "Unified visual annotation editor with structured prompt generation. layers_json is optional - can work standalone or with pre-detected layers."
    
    def visual_prompt_edit(self, image: torch.Tensor, annotation_data: str = None,
                          text_prompt: str = "", prompt_template: str = "object_edit"):
        """Unified visual prompt editing functionality"""
        
        try:
            # Process annotation data
            layers_data = []
            include_annotation_numbers = True  # Default to including numbers
            # Initialize enhanced prompts with defaults - ğŸ”´ æ”¯æŒå¤šé€‰æ ¼å¼
            constraint_prompts = []
            decorative_prompts = []
            
            if annotation_data and annotation_data.strip():
                try:
                    parsed_data = json.loads(annotation_data)
                    print(f"ğŸ” åç«¯æ”¶åˆ°annotation_dataé•¿åº¦: {len(annotation_data)} å­—ç¬¦")
                    
                    # Check if the data has an "annotations" key (new format)
                    if isinstance(parsed_data, dict):
                        if "annotations" in parsed_data:
                            layers_data = parsed_data["annotations"]
                            print(f"ğŸ“Š åç«¯è§£æåˆ° {len(layers_data)} ä¸ªæ ‡æ³¨")
                            # è¯¦ç»†è°ƒè¯•æ¯ä¸ªæ ‡æ³¨
                            for i, layer in enumerate(layers_data):
                                print(f"ğŸ“ æ ‡æ³¨{i+1}: ç±»å‹={layer.get('type')}, ID={layer.get('id')}")
                                if layer.get('type') == 'brush':
                                    print(f"ğŸ–Œï¸ ç”»ç¬”æ•°æ®: points={len(layer.get('points', []))}, brushSize={layer.get('brushSize')}, brushFeather={layer.get('brushFeather')}")
                        elif "layers_data" in parsed_data:  # Alternative key
                            layers_data = parsed_data["layers_data"]
                        else:
                            layers_data = []
                            print("âš ï¸ åç«¯: è§£æçš„æ•°æ®ä¸­æ²¡æœ‰æ‰¾åˆ°annotationsæˆ–layers_dataå­—æ®µ")
                        
                        # Extract include_annotation_numbers setting
                        include_annotation_numbers = parsed_data.get("include_annotation_numbers", True)
                        
                        # Extract synced operation type and text from frontend
                        synced_operation_type = parsed_data.get("operation_type")
                        synced_target_description = parsed_data.get("target_description")
                        
                        # Extract constraint and decorative prompts - ğŸ”´ æ”¯æŒå¤šé€‰æ ¼å¼
                        constraint_prompts = parsed_data.get("constraint_prompts", []) or parsed_data.get("constraint_prompt", "")
                        decorative_prompts = parsed_data.get("decorative_prompts", []) or parsed_data.get("decorative_prompt", "")
                        print(f"ğŸ”’ çº¦æŸæ€§æç¤ºè¯: {constraint_prompts}")
                        print(f"ğŸ¨ ä¿®é¥°æ€§æç¤ºè¯: {decorative_prompts}")
                        
                        # Use synced values if available (frontend takes priority)
                        if synced_operation_type and synced_operation_type != "custom":
                            prompt_template = synced_operation_type
                            print(f"ğŸ”„ Using synced operation type from frontend: {synced_operation_type}")
                        
                        if synced_target_description:
                            text_prompt = synced_target_description
                            print(f"ğŸ”„ Using synced text prompt from frontend: {synced_target_description}")
                        
                    elif isinstance(parsed_data, list):
                        layers_data = parsed_data
                    else:
                        layers_data = []
                            
                except json.JSONDecodeError as e:
                    print(f"Warning: JSON parsing failed: {e}")
                    layers_data = []
            
            # Generate default selection (first 3 objects)
            selected_ids = [layer.get("id", f"layer_{i}") 
                          for i, layer in enumerate(layers_data[:3])]
            
            # Generate structured prompt output with enhanced prompts - ğŸ”´ æ”¯æŒå¤šé€‰
            enhanced_prompts = {
                'constraint_prompts': constraint_prompts,
                'decorative_prompts': decorative_prompts
            }
                
            structured_prompt = self._generate_structured_prompt(
                layers_data, selected_ids, prompt_template, text_prompt, include_annotation_numbers, enhanced_prompts
            )
            
            # If there's layer data, render annotations on image
            if layers_data and len(layers_data) > 0:
                output_image = self._render_annotations_on_image(image, layers_data, include_annotation_numbers)
            else:
                output_image = image
            
            return (
                output_image,  # Image with annotations
                structured_prompt,  # Structured prompt string
            )
            
        except Exception as e:
            return self._create_fallback_output(image, str(e))
    
    
    def _generate_structured_prompt(self, layers_data: List[Dict], 
                                   selected_ids: List[str], 
                                   template: str, text_prompt: str = "", 
                                   include_annotation_numbers: bool = True,
                                   enhanced_prompts: Dict = None) -> str:
        """Generate structured prompt string using the same templates as frontend"""
        
        # 1. Object (å¯¹è±¡) - æ˜ç¡®æŒ‡å®šè¦ç¼–è¾‘çš„åŒºåŸŸæˆ–å¯¹è±¡
        selected_objects = []
        
        for layer in layers_data:
            if layer.get("id") in selected_ids:
                layer_type = layer.get("type", "object")
                color = layer.get("color", "#ff0000")
                
                # Color mapping for structured description
                color_map = {
                    '#ff0000': 'red',
                    '#00ff00': 'green', 
                    '#ffff00': 'yellow',
                    '#0000ff': 'blue'
                }
                
                # Shape mapping for structured description
                shape_map = {
                    'rectangle': 'rectangular',
                    'circle': 'circular',
                    'arrow': 'arrow-marked',
                    'freehand': 'outlined'
                }
                
                color_name = color_map.get(color, 'marked')
                shape_name = shape_map.get(layer_type, 'marked')
                number = layer.get("number", len(selected_objects) + 1)
                
                # Build structured object description
                if include_annotation_numbers:
                    object_desc = f"the {color_name} {shape_name} marked area (annotation {number})"
                else:
                    object_desc = f"the {color_name} {shape_name} marked area"
                selected_objects.append(object_desc)
        
        # Format objects list for structured prompt
        if selected_objects:
            if len(selected_objects) == 1:
                objects_str = selected_objects[0]
            elif len(selected_objects) == 2:
                objects_str = f"{selected_objects[0]} and {selected_objects[1]}"
            else:
                objects_str = f"{', '.join(selected_objects[:-1])}, and {selected_objects[-1]}"
        else:
            objects_str = "the selected marked areas"
        
        # 2. Flux Kontextä¼˜åŒ–æ¨¡æ¿ç³»ç»Ÿ - ä¸å‰ç«¯å®Œå…¨ä¸€è‡´
        operation_templates = {
            # å±€éƒ¨ç¼–è¾‘æ¨¡æ¿ (L01-L18) - ğŸ”´ Flux Kontextä¼˜åŒ–
            'change_color': lambda target: f"make {{object}} {target or 'red'}",  # ğŸ”´ å®˜æ–¹é«˜é¢‘åŠ¨è¯"make"
            'change_style': lambda target: f"turn {{object}} into {target or 'cartoon'} style",  # ğŸ”´ å®˜æ–¹"turn into"
            'replace_object': lambda target: f"replace {{object}} with {target or 'a different object'}",  # ğŸ”´ å®˜æ–¹"replace with"
            'add_object': lambda target: f"add {target or 'a new object'} to {{object}}",  # ğŸ”´ å®˜æ–¹"add to"
            'remove_object': lambda target: "remove the {object}",  # ğŸ”´ å®˜æ–¹"remove the"
            'change_texture': lambda target: f"change {{object}} texture to {target or 'smooth'}",  # ğŸ”´ å®˜æ–¹"change to"
            'change_pose': lambda target: f"make {{object}} {target or 'standing'} pose",  # ğŸ”´ å®˜æ–¹"make pose"
            'change_expression': lambda target: f"give {{object}} {target or 'happy'} expression",  # ğŸ”´ å®˜æ–¹"give"
            'change_clothing': lambda target: f"change {{object}} clothing to {target or 'casual clothes'}",
            'change_background': lambda target: f"change the background to {target or 'natural landscape'}",
            'enhance_quality': lambda target: f"enhance {{object}} quality",  # ğŸ”´ å®˜æ–¹ç®€æ´è¡¨è¾¾
            'blur_background': lambda target: f"blur the background behind {{object}}",  # ğŸ”´ å®˜æ–¹æ¨¡ç³Šå¥å¼
            'adjust_lighting': lambda target: f"adjust lighting on {{object}}",  # ğŸ”´ å®˜æ–¹å…‰ç…§è°ƒæ•´
            'resize_object': lambda target: f"make {{object}} {target or 'larger'} size",  # ğŸ”´ å®˜æ–¹å°ºå¯¸è°ƒæ•´
            'enhance_skin_texture': lambda target: f"enhance {{object}} skin texture",  # ğŸ”´ å®˜æ–¹çš®è‚¤çº¹ç†
            # ğŸ”´ æ–°å¢å±€éƒ¨ç¼–è¾‘æ¨¡æ¿ (L16-L18)
            'character_expression': lambda target: f"make the person {target or 'smile'}",  # ğŸ”´ æ–°å¢è§’è‰²è¡¨æƒ…
            'character_hair': lambda target: f"give the person {target or 'blonde'} hair",  # ğŸ”´ æ–°å¢å‘å‹ç¼–è¾‘
            'character_accessories': lambda target: f"give the person {target or 'glasses'}",  # ğŸ”´ æ–°å¢é…é¥°
            
            # å…¨å±€ç¼–è¾‘æ¨¡æ¿ (G01-G12) - ğŸ”´ Flux Kontextä¼˜åŒ–
            'global_color_grade': lambda target: f"apply {target or 'cinematic'} color grading to entire image",
            'global_style_transfer': lambda target: f"turn entire image into {target or 'vintage'} style",
            'global_brightness_contrast': lambda target: f"adjust image brightness and contrast to {target or 'high'}",
            'global_hue_saturation': lambda target: f"change image hue and saturation to {target or 'vibrant'}",
            'global_sharpen_blur': lambda target: f"apply {target or 'strong'} sharpening to entire image",
            'global_noise_reduction': lambda target: f"reduce noise in entire image",
            'global_enhance': lambda target: f"enhance entire image quality",
            'global_filter': lambda target: f"apply {target or 'sepia'} filter to entire image",
            # ğŸ”´ æ–°å¢å…¨å±€ç¼–è¾‘æ¨¡æ¿ (G09-G12)
            'character_age': lambda target: f"make the person look {target or 'older'}",  # ğŸ”´ æ–°å¢å¹´é¾„ç¼–è¾‘
            'detail_enhance': lambda target: f"add more details to {target or 'the background'}",  # ğŸ”´ æ–°å¢ç»†èŠ‚å¢å¼º
            'realism_enhance': lambda target: f"make {target or 'the portrait'} more realistic",  # ğŸ”´ æ–°å¢çœŸå®æ„Ÿ
            'camera_operation': lambda target: f"zoom out and show {target or 'full body'}",  # ğŸ”´ æ–°å¢é•œå¤´æ“ä½œ
            
            # æ–‡å­—ç¼–è¾‘æ¨¡æ¿ (T01-T05) - ğŸ”´ å…¨æ–°ç±»å‹
            'text_add': lambda target: f'add text saying "{target or "Hello World"}"',  # ğŸ”´ æ–°å¢æ–‡å­—æ·»åŠ 
            'text_remove': lambda target: "remove the text",  # ğŸ”´ æ–°å¢æ–‡å­—åˆ é™¤
            'text_edit': lambda target: f'change the text to "{target or "Welcome"}"',  # ğŸ”´ æ–°å¢æ–‡å­—ç¼–è¾‘
            'text_resize': lambda target: f"make the text {target or 'bigger'} size",  # ğŸ”´ æ–°å¢æ–‡å­—å¤§å°
            'object_combine': lambda target: f"combine {{object}} with {target or 'the background'}",  # ğŸ”´ æ–°å¢å¯¹è±¡ç»„åˆ
            
            # ä¸“ä¸šæ“ä½œæ¨¡æ¿ (P01-P14) - ğŸ”´ Flux Kontextä¼˜åŒ–
            'geometric_warp': lambda target: f"apply {target or 'perspective'} geometric transformation to {{object}}",
            'perspective_transform': lambda target: f"transform {{object}} perspective to {target or 'frontal'}",
            'lens_distortion': lambda target: f"apply {target or 'barrel'} lens distortion to {{object}}",
            'global_perspective': lambda target: f"correct perspective of entire image",
            'content_aware_fill': lambda target: f"remove {{object}} and fill with surrounding content",
            'seamless_removal': lambda target: f"seamlessly remove {{object}}",
            'smart_patch': lambda target: f"patch {{object}} area with smart content",
            'style_blending': lambda target: f"blend {{object}} with {target or 'oil painting'} style",
            'collage_integration': lambda target: f"integrate {{object}} into {target or 'artistic'} composition",
            'texture_mixing': lambda target: f"mix {{object}} texture with {target or 'metal'}",
            'precision_cutout': lambda target: f"precisely cut out {{object}}",
            'alpha_composite': lambda target: f"composite {{object}} onto {target or 'new background'}",
            'mask_feathering': lambda target: f"apply soft feathering to {{object}} edges",
            'depth_composite': lambda target: f"composite {{object}} with depth blending",
            
            'custom': lambda target: target or "Apply custom modification to the selected region"
        }
        
        # Get template function (direct match, no mapping needed)
        template_func = operation_templates.get(template, operation_templates['custom'])
        
        # Generate prompt using template
        target_text = text_prompt.strip() if text_prompt.strip() else None
        structured_prompt = template_func(target_text)
        
        # Replace {object} placeholder with actual object description
        structured_prompt = structured_prompt.replace('{object}', objects_str)
        
        # Add enhanced prompts if provided - ğŸ”´ æ”¯æŒå¤šé€‰æç¤ºè¯
        if enhanced_prompts:
            # æ”¯æŒå•ä¸ªå­—ç¬¦ä¸²ï¼ˆå‘åå…¼å®¹ï¼‰å’Œå¤šé€‰æ•°ç»„
            constraint_prompts = enhanced_prompts.get('constraint_prompts', []) or enhanced_prompts.get('constraint_prompt', '')
            decorative_prompts = enhanced_prompts.get('decorative_prompts', []) or enhanced_prompts.get('decorative_prompt', '')
            
            # å¤„ç†çº¦æŸæ€§æç¤ºè¯
            if constraint_prompts:
                if isinstance(constraint_prompts, list) and constraint_prompts:
                    structured_prompt += f", {', '.join(constraint_prompts)}"
                elif isinstance(constraint_prompts, str) and constraint_prompts.strip():
                    structured_prompt += f", {constraint_prompts}"
                    
            # å¤„ç†ä¿®é¥°æ€§æç¤ºè¯  
            if decorative_prompts:
                if isinstance(decorative_prompts, list) and decorative_prompts:
                    structured_prompt += f", {', '.join(decorative_prompts)}"
                elif isinstance(decorative_prompts, str) and decorative_prompts.strip():
                    structured_prompt += f", {decorative_prompts}"
        
        return structured_prompt
    
    def _render_annotations_on_image(self, image: torch.Tensor, layers_data: List[Dict], include_annotation_numbers: bool = True) -> torch.Tensor:
        """Render annotations on image"""
        try:
            from PIL import Image, ImageDraw, ImageFont
            
            # Convert torch tensor to PIL Image first to get dimensions
            if len(image.shape) == 4:
                # Batch dimension exists, take first
                img_array = image[0].cpu().numpy()
            else:
                img_array = image.cpu().numpy()
            
            # Ensure value range is [0, 1]
            if img_array.max() <= 1.0:
                img_array = (img_array * 255).astype(np.uint8)
            else:
                img_array = img_array.astype(np.uint8)
                
            # Convert to PIL Image
            if len(img_array.shape) == 3:
                pil_image = Image.fromarray(img_array, 'RGB')
            else:
                pil_image = Image.fromarray(img_array, 'L')
                pil_image = pil_image.convert('RGB')
            
            # Get image dimensions
            img_width, img_height = pil_image.size
            
            # Helper function to draw annotation numbers
            def draw_annotation_number(draw, position, number, color_rgba, scale_x=1.0, scale_y=1.0):
                """Draw annotation number label at specified position - simplified style without circles"""
                if not include_annotation_numbers:
                    return
                    
                try:
                    # Calculate font size based on image size - larger for better visibility
                    font_size = max(24, int(min(img_width, img_height) * 0.04))
                    
                    # Try to use a nice font, fallback to default
                    try:
                        font = ImageFont.truetype("arial.ttf", font_size)
                    except:
                        try:
                            font = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf", font_size)
                        except:
                            try:
                                font = ImageFont.load_default()
                                # Scale up the default font size if possible
                                if hasattr(font, 'font_size'):
                                    font.font_size = font_size
                            except:
                                font = None
                    
                    # Position for number label - already calculated as outside position
                    x = int(position['x'] * scale_x)
                    y = int(position['y'] * scale_y)
                    
                    # Text styling
                    text = str(number)
                    
                    # Draw text with black outline for high contrast
                    outline_width = 2
                    text_color = (255, 255, 255, 255)  # White text
                    outline_color = (0, 0, 0, 255)     # Black outline
                    
                    # Draw text outline (multiple passes for better effect)
                    for dx in range(-outline_width, outline_width + 1):
                        for dy in range(-outline_width, outline_width + 1):
                            if dx != 0 or dy != 0:  # Don't draw at center position
                                if font:
                                    draw.text((x + dx, y + dy), text, fill=outline_color, font=font)
                                else:
                                    draw.text((x + dx, y + dy), text, fill=outline_color)
                    
                    # Draw main text
                    if font:
                        draw.text((x, y), text, fill=text_color, font=font)
                    else:
                        draw.text((x, y), text, fill=text_color)
                    
                except Exception as e:
                    print(f"Warning: Failed to draw annotation number {number}: {e}")
            
            # Create drawing object
            draw = ImageDraw.Draw(pil_image, 'RGBA')
            
            # Color mapping (base RGB values, alpha will be calculated per annotation) - æ ‡å‡†çº¯è‰²
            color_map = {
                '#ff0000': (255, 0, 0),      # Standard Red
                '#00ff00': (0, 255, 0),      # Standard Green  
                '#ffff00': (255, 255, 0),    # Standard Yellow
                '#0000ff': (0, 0, 255)       # Standard Blue
            }
            
            # å‰ç«¯SVGç°åœ¨ä½¿ç”¨å›¾åƒå®é™…å°ºå¯¸ä½œä¸ºviewBoxï¼Œæ‰€ä»¥åæ ‡è½¬æ¢æ¯”ä¾‹æ˜¯1:1
            print(f"ğŸ–¼ï¸ åç«¯å›¾åƒæ¸²æŸ“ - å›¾åƒå°ºå¯¸: {img_width}x{img_height}")
            
            # å®šä¹‰å¡«å……æ ·å¼åº”ç”¨å‡½æ•°
            def apply_fill_style(draw, coords, color_rgb, fill_mode, shape_type, opacity=50):
                """æ ¹æ®å¡«å……æ¨¡å¼å’Œä¸é€æ˜åº¦ç»˜åˆ¶å½¢çŠ¶"""
                # è®¡ç®—ä¸é€æ˜åº¦å€¼ (0-255)
                fill_alpha = int(opacity * 255 / 100)
                stroke_alpha = min(int((opacity + 30) * 255 / 100), 255)  # è¾¹æ¡†ç¨å¾®æ›´ä¸é€æ˜ä¸€äº›
                
                if fill_mode == 'outline':
                    # ç©ºå¿ƒæ ·å¼ - åªç»˜åˆ¶è¾¹æ¡†
                    outline_color = (color_rgb[0], color_rgb[1], color_rgb[2], stroke_alpha)
                    if shape_type == 'rectangle':
                        x1, y1, x2, y2 = coords
                        draw.rectangle([x1, y1, x2, y2], outline=outline_color, width=3)
                    elif shape_type == 'ellipse':
                        x1, y1, x2, y2 = coords  
                        draw.ellipse([x1, y1, x2, y2], outline=outline_color, width=3)
                    elif shape_type == 'polygon':
                        draw.polygon(coords, outline=outline_color, width=3)
                else:
                    # å®å¿ƒæ ·å¼ - å¡«å…… (é»˜è®¤)
                    fill_color = (color_rgb[0], color_rgb[1], color_rgb[2], fill_alpha)
                    if shape_type == 'rectangle':
                        x1, y1, x2, y2 = coords
                        draw.rectangle([x1, y1, x2, y2], fill=fill_color)
                    elif shape_type == 'ellipse':
                        x1, y1, x2, y2 = coords
                        draw.ellipse([x1, y1, x2, y2], fill=fill_color)
                    elif shape_type == 'polygon':
                        draw.polygon(coords, fill=fill_color)
            
            # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰æ ‡æ³¨éƒ½ä½¿ç”¨ç›¸åŒçš„åæ ‡åŸºå‡†
            # å¦‚æœåæ ‡å€¼éƒ½åœ¨å›¾åƒå°ºå¯¸èŒƒå›´å†…ï¼Œåˆ™ç›´æ¥ä½¿ç”¨ï¼›å¦åˆ™è¿›è¡Œæ¯”ä¾‹è½¬æ¢
            def detect_coordinate_scale(layers_data, img_width, img_height):
                """æ£€æµ‹åæ ‡æ˜¯å¦éœ€è¦ç¼©æ”¾è½¬æ¢"""
                max_x = max_y = 0
                coord_count = 0
                
                for layer in layers_data:
                    if 'start' in layer and 'end' in layer:
                        start, end = layer['start'], layer['end']
                        if isinstance(start, dict) and isinstance(end, dict):
                            max_x = max(max_x, abs(start.get('x', 0)), abs(end.get('x', 0)))
                            max_y = max(max_y, abs(start.get('y', 0)), abs(end.get('y', 0)))
                            coord_count += 1
                    elif 'geometry' in layer and 'coordinates' in layer['geometry']:
                        coords = layer['geometry']['coordinates']
                        if isinstance(coords, list) and len(coords) >= 4:
                            max_x = max(max_x, abs(coords[0]), abs(coords[2]))
                            max_y = max(max_y, abs(coords[1]), abs(coords[3]))
                            coord_count += 1
                            
                if coord_count == 0:
                    return 1.0, 1.0  # æ²¡æœ‰åæ ‡æ•°æ®ï¼Œä½¿ç”¨1:1
                    
                # å¦‚æœæœ€å¤§åæ ‡å€¼æ˜æ˜¾è¶…å‡ºå›¾åƒå°ºå¯¸ï¼Œè¯´æ˜ä½¿ç”¨çš„æ˜¯æ¯”ä¾‹åæ ‡
                scale_x = img_width / max_x if max_x > img_width * 1.5 else 1.0
                scale_y = img_height / max_y if max_y > img_height * 1.5 else 1.0
                
                print(f"ğŸ” åæ ‡ç¼©æ”¾æ£€æµ‹ - æœ€å¤§åæ ‡: ({max_x}, {max_y}), ç¼©æ”¾æ¯”ä¾‹: ({scale_x:.3f}, {scale_y:.3f})")
                return scale_x, scale_y
            
            # æ£€æµ‹åæ ‡ç¼©æ”¾æ¯”ä¾‹
            scale_x, scale_y = detect_coordinate_scale(layers_data, img_width, img_height)
            
            # Render each annotation
            rendered_count = 0
            for i, layer in enumerate(layers_data):
                color_hex = layer.get('color', '#ff0000')
                color_rgb = color_map.get(color_hex, (255, 0, 0))  # è·å–RGBå€¼
                layer_type = layer.get('type', 'rectangle')
                opacity = layer.get('opacity', 50)  # è·å–ä¸é€æ˜åº¦ï¼Œé»˜è®¤50%
                
                # ğŸ” è°ƒè¯•ï¼šè¾“å‡ºæ¯ä¸ªæ ‡æ³¨çš„ä¸é€æ˜åº¦ä¿¡æ¯
                print(f"ğŸ¨ æ ‡æ³¨{i+1}æ¸²æŸ“ä¿¡æ¯: ç±»å‹={layer_type}, é¢œè‰²={color_hex}, ä¸é€æ˜åº¦={opacity}%")
                
                # Check if coordinates exist and are valid
                # Support multiple coordinate formats: 1) start/end, 2) geometry.coordinates
                has_coordinates = False
                start_point = None
                end_point = None
                fill_mode = layer.get('fillMode', 'filled')  # è·å–å¡«å……æ¨¡å¼
                
                print(f"ğŸ” æ ‡æ³¨{i+1} åæ ‡æ£€æŸ¥: type={layer_type}, åŒ…å«keys={list(layer.keys())}")
                
                if layer_type in ['rectangle', 'circle', 'arrow']:
                    # Format 1: Direct start/end coordinates
                    if 'start' in layer and 'end' in layer:
                        start = layer['start'] 
                        end = layer['end']
                        if isinstance(start, dict) and isinstance(end, dict):
                            if all(key in start for key in ['x', 'y']) and all(key in end for key in ['x', 'y']):
                                has_coordinates = True
                                start_point = start
                                end_point = end
                        
                    # Format 2: Geometry coordinates [x1, y1, x2, y2]
                    elif 'geometry' in layer and 'coordinates' in layer['geometry']:
                        coords = layer['geometry']['coordinates']
                        if isinstance(coords, list) and len(coords) >= 4:
                            x1, y1, x2, y2 = coords[:4]
                            start_point = {'x': x1, 'y': y1}
                            end_point = {'x': x2, 'y': y2}
                            has_coordinates = True
                        
                elif layer_type == 'freehand' or layer_type == 'polygon':
                    if 'points' in layer and isinstance(layer['points'], list):
                        points = layer['points']
                        if len(points) >= 3 and all(isinstance(p, dict) and 'x' in p and 'y' in p for p in points):
                            has_coordinates = True
                            
                elif layer_type == 'brush':
                    # ç”»ç¬”æ ‡æ³¨çš„åæ ‡æ£€æŸ¥
                    if 'points' in layer and isinstance(layer['points'], list):
                        brush_points = layer['points']
                        print(f"ğŸ–Œï¸ ç”»ç¬”æ ‡æ³¨{i+1}: æ‰¾åˆ°pointså­—æ®µï¼Œé•¿åº¦={len(brush_points)}")
                        if len(brush_points) >= 1 and all(isinstance(p, dict) and 'x' in p and 'y' in p for p in brush_points):
                            has_coordinates = True
                            print(f"ğŸ–Œï¸ ç”»ç¬”æ ‡æ³¨{i+1}: åæ ‡éªŒè¯é€šè¿‡")
                        else:
                            print(f"ğŸ–Œï¸ ç”»ç¬”æ ‡æ³¨{i+1}: åæ ‡éªŒè¯å¤±è´¥")
                
                if not has_coordinates:
                    print(f"âš ï¸ æ ‡æ³¨{i+1}: æ²¡æœ‰æœ‰æ•ˆåæ ‡ï¼Œè·³è¿‡æ¸²æŸ“")
                    continue
                
                if layer_type == 'rectangle' and start_point and end_point:
                    # Rectangle annotation
                    # ä½¿ç”¨åŠ¨æ€æ£€æµ‹çš„ç¼©æ”¾æ¯”ä¾‹è¿›è¡Œåæ ‡è½¬æ¢
                    x1 = int(start_point['x'] * scale_x)
                    y1 = int(start_point['y'] * scale_y)
                    x2 = int(end_point['x'] * scale_x)
                    y2 = int(end_point['y'] * scale_y)
                    
                    # Ensure correct coordinate order
                    x1, x2 = min(x1, x2), max(x1, x2)
                    y1, y2 = min(y1, y2), max(y1, y2)
                    
                    print(f"ğŸ”´ çŸ©å½¢æ ‡æ³¨ {i}: åŸå§‹åæ ‡({start_point['x']:.1f},{start_point['y']:.1f})-({end_point['x']:.1f},{end_point['y']:.1f}) â†’ å›¾åƒåæ ‡({x1},{y1})-({x2},{y2}), å¡«å……æ¨¡å¼: {fill_mode}, ä¸é€æ˜åº¦: {opacity}%")
                    print(f"ğŸ”´ çŸ©å½¢ç»˜åˆ¶å‰: drawå¯¹è±¡={id(draw)}, å›¾åƒå¯¹è±¡={id(pil_image)}, å›¾åƒæ¨¡å¼={pil_image.mode}")
                    apply_fill_style(draw, (x1, y1, x2, y2), color_rgb, fill_mode, 'rectangle', opacity)
                    print(f"ğŸ”´ çŸ©å½¢ç»˜åˆ¶å: å®ŒæˆçŸ©å½¢ç»˜åˆ¶")
                    
                    # Draw annotation number at top-left corner outside the annotation
                    annotation_number = layer.get('number', i + 1)
                    color_rgba = (*color_rgb, 255)  # è½¬æ¢ä¸ºRGBAæ ¼å¼ç»™ç¼–å·ä½¿ç”¨
                    # Calculate position outside the rectangle (top-left corner with small offset)
                    number_position = {
                        'x': min(start_point['x'], end_point['x']) - 8,
                        'y': min(start_point['y'], end_point['y']) - 8
                    }
                    draw_annotation_number(draw, number_position, annotation_number, color_rgba, scale_x, scale_y)
                    
                    rendered_count += 1
                    
                elif layer_type == 'circle' and start_point and end_point:
                    # Ellipse annotation
                    # ä½¿ç”¨åŠ¨æ€æ£€æµ‹çš„ç¼©æ”¾æ¯”ä¾‹è¿›è¡Œåæ ‡è½¬æ¢
                    x1 = int(start_point['x'] * scale_x)
                    y1 = int(start_point['y'] * scale_y)
                    x2 = int(end_point['x'] * scale_x)
                    y2 = int(end_point['y'] * scale_y)
                    
                    # Ensure correct coordinate order
                    x1, x2 = min(x1, x2), max(x1, x2)
                    y1, y2 = min(y1, y2), max(y1, y2)
                    
                    print(f"ğŸŸ¡ æ¤­åœ†æ ‡æ³¨ {i}: åŸå§‹åæ ‡({start_point['x']:.1f},{start_point['y']:.1f})-({end_point['x']:.1f},{end_point['y']:.1f}) â†’ å›¾åƒåæ ‡({x1},{y1})-({x2},{y2}), å¡«å……æ¨¡å¼: {fill_mode}, ä¸é€æ˜åº¦: {opacity}%")
                    apply_fill_style(draw, (x1, y1, x2, y2), color_rgb, fill_mode, 'ellipse', opacity)
                    
                    # Draw annotation number at top-left corner outside the annotation
                    annotation_number = layer.get('number', i + 1)
                    color_rgba = (*color_rgb, 255)  # è½¬æ¢ä¸ºRGBAæ ¼å¼ç»™ç¼–å·ä½¿ç”¨
                    # Calculate position outside the ellipse (top-left corner with small offset)
                    number_position = {
                        'x': min(start_point['x'], end_point['x']) - 8,
                        'y': min(start_point['y'], end_point['y']) - 8
                    }
                    draw_annotation_number(draw, number_position, annotation_number, color_rgba, scale_x, scale_y)
                    
                    rendered_count += 1
                    
                elif layer_type == 'freehand' and 'points' in layer:
                    # Polygon annotation
                    points = layer['points']
                    
                    if len(points) >= 3:
                        polygon_points = []
                        for point in points:
                            x = int(point['x'] * scale_x)
                            y = int(point['y'] * scale_y)
                            polygon_points.append((x, y))
                        
                        print(f"ğŸ”— å¤šè¾¹å½¢æ ‡æ³¨ {i}: {len(points)}ä¸ªç‚¹, ç¼©æ”¾æ¯”ä¾‹({scale_x:.3f}, {scale_y:.3f}), å¡«å……æ¨¡å¼: {fill_mode}, ä¸é€æ˜åº¦: {opacity}%")
                        apply_fill_style(draw, polygon_points, color_rgb, fill_mode, 'polygon', opacity)
                        
                        # Draw annotation number outside the polygon (offset from first point)
                        annotation_number = layer.get('number', i + 1)
                        first_point = points[0]
                        color_rgba = (*color_rgb, 255)  # è½¬æ¢ä¸ºRGBAæ ¼å¼ç»™ç¼–å·ä½¿ç”¨
                        # Calculate position outside the polygon (small offset from first point)
                        number_position = {
                            'x': first_point['x'] - 8,
                            'y': first_point['y'] - 8
                        }
                        draw_annotation_number(draw, number_position, annotation_number, color_rgba, scale_x, scale_y)
                        
                        rendered_count += 1
                        
                elif layer_type == 'arrow' and start_point and end_point:
                    # Arrow annotation
                    # ä½¿ç”¨åŠ¨æ€æ£€æµ‹çš„ç¼©æ”¾æ¯”ä¾‹è¿›è¡Œåæ ‡è½¬æ¢
                    x1 = int(start_point['x'] * scale_x)
                    y1 = int(start_point['y'] * scale_y)
                    x2 = int(end_point['x'] * scale_x)
                    y2 = int(end_point['y'] * scale_y)
                    
                    # Draw arrow line with opacity
                    arrow_alpha = int(opacity * 255 / 100)
                    line_color = (*color_rgb, arrow_alpha)
                    draw.line([x1, y1, x2, y2], fill=line_color, width=6)
                    
                    # Calculate arrow head
                    import math
                    
                    # Arrow length and angle
                    arrow_length = 20
                    arrow_angle = math.pi / 6  # 30 degrees
                    
                    # Calculate line angle
                    dx = x2 - x1
                    dy = y2 - y1
                    line_angle = math.atan2(dy, dx)
                    
                    # Calculate arrow two vertices
                    arrow_x1 = x2 - arrow_length * math.cos(line_angle - arrow_angle)
                    arrow_y1 = y2 - arrow_length * math.sin(line_angle - arrow_angle)
                    arrow_x2 = x2 - arrow_length * math.cos(line_angle + arrow_angle)
                    arrow_y2 = y2 - arrow_length * math.sin(line_angle + arrow_angle)
                    
                    # Draw arrow head (triangle)
                    arrow_points = [(x2, y2), (int(arrow_x1), int(arrow_y1)), (int(arrow_x2), int(arrow_y2))]
                    draw.polygon(arrow_points, fill=line_color)
                    
                    print(f"â¡ï¸ ç®­å¤´æ ‡æ³¨ {i}: åŸå§‹åæ ‡({start_point['x']:.1f},{start_point['y']:.1f})-({end_point['x']:.1f},{end_point['y']:.1f}) â†’ å›¾åƒåæ ‡({x1},{y1})-({x2},{y2})")
                    
                    # Draw annotation number outside the arrow (offset from start point)
                    annotation_number = layer.get('number', i + 1)
                    color_rgba = (*color_rgb, 255)  # è½¬æ¢ä¸ºRGBAæ ¼å¼ç»™ç¼–å·ä½¿ç”¨
                    # Calculate position outside the arrow (small offset from start point)
                    number_position = {
                        'x': start_point['x'] - 8,
                        'y': start_point['y'] - 8
                    }
                    draw_annotation_number(draw, number_position, annotation_number, color_rgba, scale_x, scale_y)
                    
                    rendered_count += 1
                    
                elif layer_type == 'brush' and 'points' in layer:
                    # Brush annotation with path data
                    points = layer.get('points', [])
                    path_data = layer.get('pathData', '')
                    
                    print(f"ğŸ–Œï¸ ç”»ç¬”æ ‡æ³¨ {i}: å¼€å§‹å¤„ç†ï¼Œpointsç±»å‹={type(points)}, é•¿åº¦={len(points) if points else 0}")
                    
                    if not points or len(points) == 0:
                        print(f"âš ï¸ ç”»ç¬”æ ‡æ³¨ {i}: æ²¡æœ‰è·¯å¾„ç‚¹ï¼Œè·³è¿‡æ¸²æŸ“")
                        continue
                    
                    # æ£€æŸ¥pointsçš„ç¬¬ä¸€ä¸ªå…ƒç´ ç»“æ„
                    if len(points) > 0:
                        print(f"ğŸ–Œï¸ ç”»ç¬”æ ‡æ³¨ {i}: ç¬¬ä¸€ä¸ªç‚¹ç»“æ„={points[0]}")
                    
                    # éªŒè¯æ‰€æœ‰ç‚¹éƒ½æœ‰x,yåæ ‡
                    valid_points = [p for p in points if isinstance(p, dict) and 'x' in p and 'y' in p]
                    print(f"ğŸ–Œï¸ ç”»ç¬”æ ‡æ³¨ {i}: æœ‰æ•ˆç‚¹æ•°é‡={len(valid_points)}/{len(points)}")
                    
                    if len(valid_points) == 0:
                        print(f"âš ï¸ ç”»ç¬”æ ‡æ³¨ {i}: æ²¡æœ‰æœ‰æ•ˆçš„åæ ‡ç‚¹ï¼Œè·³è¿‡æ¸²æŸ“")
                        continue
                    
                    points = valid_points  # ä½¿ç”¨éªŒè¯è¿‡çš„ç‚¹
                    
                    # è·å–ç”»ç¬”å‚æ•°
                    brush_size = layer.get('brushSize', 20)
                    brush_feather = layer.get('brushFeather', 5)
                    
                    # ç»˜åˆ¶ç”»ç¬”è·¯å¾„
                    if brush_feather > 0:
                        # å¸¦ç¾½åŒ–çš„ç”»ç¬”è·¯å¾„
                        from PIL import ImageFilter
                        
                        # åˆ›å»ºä¸´æ—¶å›¾åƒç”¨äºç»˜åˆ¶è·¯å¾„
                        temp_img = Image.new('RGBA', (img_width, img_height), (0, 0, 0, 0))
                        temp_draw = ImageDraw.Draw(temp_img)
                        
                        # è½¬æ¢è·¯å¾„ç‚¹å¹¶ç»˜åˆ¶
                        scaled_points = []
                        for point in points:
                            scaled_x = int(point['x'] * scale_x)
                            scaled_y = int(point['y'] * scale_y)
                            scaled_points.append((scaled_x, scaled_y))
                        
                        if len(scaled_points) >= 2:
                            # ç»˜åˆ¶è·¯å¾„
                            stroke_width = int(brush_size * max(scale_x, scale_y))
                            stroke_alpha = int(opacity * 255 / 100)
                            stroke_color = (*color_rgb, stroke_alpha)
                            
                            print(f"ğŸ–Œï¸ ç”»ç¬”æ¸²æŸ“ {i}: ç¾½åŒ–è·¯å¾„ï¼Œwidth={stroke_width}, alpha={stroke_alpha}, color={stroke_color}")
                            
                            # ç»˜åˆ¶çº¿æ®µè¿æ¥å„ç‚¹
                            for j in range(len(scaled_points) - 1):
                                temp_draw.line([scaled_points[j], scaled_points[j + 1]], 
                                             fill=stroke_color, width=stroke_width)
                            
                            # åœ¨æ¯ä¸ªç‚¹ç»˜åˆ¶åœ†å½¢ä»¥å½¢æˆè¿ç»­è·¯å¾„
                            radius = stroke_width // 2
                            for point in scaled_points:
                                temp_draw.ellipse([
                                    point[0] - radius, point[1] - radius,
                                    point[0] + radius, point[1] + radius
                                ], fill=stroke_color)
                            
                            print(f"ğŸ–Œï¸ ç”»ç¬”æ¸²æŸ“ {i}: å®Œæˆç¾½åŒ–ç»˜åˆ¶ï¼Œå‡†å¤‡åˆæˆ")
                        
                        # åº”ç”¨ç¾½åŒ–æ•ˆæœ
                        feather_pixels = int(brush_feather * max(scale_x, scale_y))
                        if feather_pixels > 0:
                            temp_img = temp_img.filter(ImageFilter.GaussianBlur(feather_pixels))
                        
                        # å°†ç¾½åŒ–åçš„å›¾åƒåˆæˆåˆ°ä¸»å›¾åƒ
                        print(f"ğŸ–Œï¸ ç”»ç¬”åˆæˆ: ä¸»å›¾åƒå°ºå¯¸={pil_image.size}, ä¸´æ—¶å›¾åƒå°ºå¯¸={temp_img.size}")
                        # ä¿æŒRGBAæ¨¡å¼ä»¥ä¾¿åç»­æ ‡æ³¨ç»˜åˆ¶
                        pil_image = Image.alpha_composite(pil_image.convert('RGBA'), temp_img)
                        # é‡è¦ï¼šæ›´æ–°drawå¯¹è±¡åˆ°æ–°çš„åˆæˆå›¾åƒ
                        draw = ImageDraw.Draw(pil_image, 'RGBA')
                        print(f"ğŸ–Œï¸ ç”»ç¬”åˆæˆå®Œæˆ: {i}ï¼Œæ–°drawå¯¹è±¡={id(draw)}, æ–°å›¾åƒå¯¹è±¡={id(pil_image)}, å›¾åƒæ¨¡å¼={pil_image.mode}")
                    else:
                        # æ— ç¾½åŒ–çš„å®å¿ƒè·¯å¾„
                        scaled_points = []
                        for point in points:
                            scaled_x = int(point['x'] * scale_x)
                            scaled_y = int(point['y'] * scale_y)
                            scaled_points.append((scaled_x, scaled_y))
                        
                        if len(scaled_points) >= 2:
                            stroke_width = int(brush_size * max(scale_x, scale_y))
                            stroke_alpha = int(opacity * 255 / 100)
                            stroke_color = (*color_rgb, stroke_alpha)
                            
                            # ç»˜åˆ¶è·¯å¾„
                            for j in range(len(scaled_points) - 1):
                                draw.line([scaled_points[j], scaled_points[j + 1]], 
                                         fill=stroke_color, width=stroke_width)
                            
                            # åœ¨æ¯ä¸ªç‚¹ç»˜åˆ¶åœ†å½¢ä»¥å½¢æˆè¿ç»­è·¯å¾„
                            radius = stroke_width // 2
                            for point in scaled_points:
                                draw.ellipse([
                                    point[0] - radius, point[1] - radius,
                                    point[0] + radius, point[1] + radius
                                ], fill=stroke_color)
                    
                    print(f"ğŸ–Œï¸ ç”»ç¬”è·¯å¾„ {i}: {len(points)}ä¸ªç‚¹, å¤§å°={brush_size}, ç¾½åŒ–={brush_feather}, ä¸é€æ˜åº¦={opacity}%")
                    
                    # Draw annotation number outside the brush path (offset from first point)
                    if points:
                        annotation_number = layer.get('number', i + 1)
                        color_rgba = (*color_rgb, 255)
                        first_point = points[0]
                        # Calculate position outside the brush path (small offset from first point)
                        number_position = {
                            'x': first_point['x'] - 8,
                            'y': first_point['y'] - 8
                        }
                        draw_annotation_number(draw, number_position, annotation_number, color_rgba, scale_x, scale_y)
                    
                    rendered_count += 1
            
            numbers_status = "åŒ…å«ç¼–å·" if include_annotation_numbers else "ä¸åŒ…å«ç¼–å·"
            print(f"âœ… åç«¯æ ‡æ³¨æ¸²æŸ“å®Œæˆ: æ€»å…±{len(layers_data)}ä¸ªæ ‡æ³¨ï¼ŒæˆåŠŸæ¸²æŸ“{rendered_count}ä¸ª ({numbers_status})")
            
            # å¦‚æœå›¾åƒåœ¨RGBAæ¨¡å¼ï¼Œè½¬æ¢ä¸ºRGBæ¨¡å¼
            if pil_image.mode == 'RGBA':
                print(f"ğŸ”„ è½¬æ¢æœ€ç»ˆå›¾åƒä»RGBAåˆ°RGBæ¨¡å¼")
                pil_image = pil_image.convert('RGB')
            
            # Convert back to torch tensor
            output_array = np.array(pil_image)
            output_tensor = torch.from_numpy(output_array).float() / 255.0
            
            # Ensure correct dimensions
            if len(image.shape) == 4:
                output_tensor = output_tensor.unsqueeze(0)
            
            return output_tensor
            
        except Exception as e:
            print(f"Warning: Failed to render annotations on image: {e}")
            return image  # Return original image if rendering fails
    
    
    def _create_fallback_output(self, image: torch.Tensor, error_msg: str):
        """Create fallback output"""
        fallback_structured_prompt = "Edit the selected areas according to requirements"
        
        return (
            image,  # Image
            fallback_structured_prompt  # Structured prompt
        )

# Node registration
NODE_CLASS_MAPPINGS = {
    "VisualPromptEditor": VisualPromptEditor,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "VisualPromptEditor": "ğŸ¨ Visual Prompt Editor",
}