"""
SAM2æ™ºèƒ½æ ‡æ³¨èŠ‚ç‚¹
é›†æˆSAM2+FastSAMçš„ComfyUIèŠ‚ç‚¹
"""

import json
import numpy as np
import torch
from typing import Dict, List, Any
import os
import sys

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.append(parent_dir)

try:
    from sam2_annotation_service import get_sam2_service
    SAM2_SERVICE_AVAILABLE = True
except ImportError as e:
    print(f"SAM2æœåŠ¡å¯¼å…¥å¤±è´¥: {e}")
    SAM2_SERVICE_AVAILABLE = False

try:
    import comfy.model_management as model_management
    from nodes import MAX_RESOLUTION
    COMFY_AVAILABLE = True
except ImportError:
    COMFY_AVAILABLE = False
    MAX_RESOLUTION = 8192

class SAM2IntelligentAnnotationNode:
    """SAM2æ™ºèƒ½æ ‡æ³¨èŠ‚ç‚¹"""
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image": ("IMAGE",),
            },
            "optional": {
                "interaction_mode": (["auto", "fast", "precise"], {"default": "auto"}),
                "interaction_points": ("STRING", {
                    "multiline": True, 
                    "default": "[]", 
                    "tooltip": "JSONæ ¼å¼çš„äº¤äº’ç‚¹ï¼Œä¾‹å¦‚: [{\"type\":\"point\",\"point\":[320,240]}]"
                }),
                "confidence_threshold": ("FLOAT", {
                    "default": 0.4, 
                    "min": 0.1, 
                    "max": 1.0, 
                    "step": 0.1,
                    "tooltip": "FastSAMç½®ä¿¡åº¦é˜ˆå€¼"
                }),
                "enable_sam2": ("BOOLEAN", {
                    "default": False,
                    "tooltip": "å¯ç”¨SAM2ç²¾ç¡®æ¨¡å¼ï¼ˆéœ€è¦æ›´å¤šGPUå†…å­˜ï¼‰"
                })
            }
        }
    
    RETURN_TYPES = ("STRING", "STRING", "STRING")
    RETURN_NAMES = ("layers_json", "performance_stats", "debug_info")
    FUNCTION = "intelligent_annotate"
    CATEGORY = "kontext/sam2"
    DESCRIPTION = "ä½¿ç”¨SAM2+FastSAMè¿›è¡Œæ™ºèƒ½æ ‡æ³¨"
    
    def __init__(self):
        self.service = None
        self.last_interaction_mode = None
        
    def intelligent_annotate(self, image: torch.Tensor, interaction_mode: str = "auto", 
                           interaction_points: str = "[]", confidence_threshold: float = 0.4,
                           enable_sam2: bool = False):
        """æ‰§è¡Œæ™ºèƒ½æ ‡æ³¨"""
        
        try:
            # æ£€æŸ¥æœåŠ¡å¯ç”¨æ€§
            if not SAM2_SERVICE_AVAILABLE:
                return self._create_fallback_result("SAM2æœåŠ¡ä¸å¯ç”¨")
            
            # è·å–æœåŠ¡å®ä¾‹
            if self.service is None:
                self.service = get_sam2_service()
                print("ğŸ”§ SAM2æœåŠ¡å·²åˆå§‹åŒ–")
            
            # æ ¹æ®éœ€è¦åŠ è½½æ¨¡å‹
            if enable_sam2 and interaction_mode in ["precise", "auto"]:
                self.service.load_models(load_fastsam=True, load_sam2=True)
            else:
                self.service.load_models(load_fastsam=True, load_sam2=False)
            
            # è®¾ç½®å·¥ä½œæ¨¡å¼
            if interaction_mode != self.last_interaction_mode:
                self.service.set_mode(interaction_mode)
                self.last_interaction_mode = interaction_mode
            
            # è½¬æ¢å›¾åƒæ ¼å¼
            image_np = self._tensor_to_numpy(image)
            h, w = image_np.shape[:2]
            
            # è§£æäº¤äº’ç‚¹
            try:
                interactions = json.loads(interaction_points) if interaction_points.strip() else []
            except json.JSONDecodeError:
                print("âš ï¸ äº¤äº’ç‚¹JSONè§£æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤ä¸­å¿ƒç‚¹")
                interactions = []
            
            # å¦‚æœæ²¡æœ‰äº¤äº’ç‚¹ï¼Œç”Ÿæˆé»˜è®¤ç‚¹
            if not interactions:
                interactions = self._generate_default_interactions(w, h)
            
            # æ‰§è¡Œæ™ºèƒ½æ ‡æ³¨
            results = []
            debug_info = []
            
            for i, interaction in enumerate(interactions):
                print(f"ğŸ¯ å¤„ç†äº¤äº’ {i+1}/{len(interactions)}: {interaction}")
                
                # è®¾ç½®ç½®ä¿¡åº¦é˜ˆå€¼
                if interaction_mode == "fast":
                    # ä¸ºFastSAMè®¾ç½®åŠ¨æ€å‚æ•°
                    if hasattr(self.service, 'fastsam_model'):
                        interaction["conf_threshold"] = confidence_threshold
                
                # æ‰§è¡Œåˆ†å‰²
                result = self.service.smart_segment(image_np, interaction, interaction_mode)
                
                if result["success"]:
                    # è½¬æ¢ä¸ºæ ‡å‡†å±‚æ•°æ®æ ¼å¼
                    layer_data = self._convert_to_layer_format(result, i)
                    results.append(layer_data)
                    
                    debug_info.append({
                        "interaction_id": i,
                        "method": result["method"],
                        "confidence": result["confidence"],
                        "process_time_ms": result["process_time"] * 1000,
                        "success": True
                    })
                else:
                    debug_info.append({
                        "interaction_id": i,
                        "error": result.get("error", "æœªçŸ¥é”™è¯¯"),
                        "success": False
                    })
            
            # ç”Ÿæˆè¾“å‡º
            layers_json = json.dumps(results, ensure_ascii=False, indent=2)
            
            # æ€§èƒ½ç»Ÿè®¡
            perf_stats = self.service.get_performance_stats()
            perf_json = json.dumps(perf_stats, ensure_ascii=False, indent=2)
            
            # è°ƒè¯•ä¿¡æ¯
            debug_json = json.dumps({
                "total_interactions": len(interactions),
                "successful_results": len(results),
                "interaction_details": debug_info,
                "image_info": {
                    "width": w,
                    "height": h,
                    "channels": image_np.shape[2] if len(image_np.shape) > 2 else 1
                },
                "mode_info": {
                    "interaction_mode": interaction_mode,
                    "enable_sam2": enable_sam2,
                    "confidence_threshold": confidence_threshold
                }
            }, ensure_ascii=False, indent=2)
            
            print(f"âœ… SAM2æ™ºèƒ½æ ‡æ³¨å®Œæˆ: {len(results)}ä¸ªç»“æœ")
            return (layers_json, perf_json, debug_json)
            
        except Exception as e:
            error_msg = f"SAM2æ™ºèƒ½æ ‡æ³¨å¤±è´¥: {str(e)}"
            print(f"âŒ {error_msg}")
            return self._create_fallback_result(error_msg)
    
    def _tensor_to_numpy(self, tensor: torch.Tensor) -> np.ndarray:
        """å°†tensorè½¬æ¢ä¸ºnumpyæ•°ç»„"""
        if len(tensor.shape) == 4:
            # æ‰¹æ¬¡ç»´åº¦ï¼Œå–ç¬¬ä¸€ä¸ª
            tensor = tensor[0]
        
        # è½¬æ¢ä¸ºnumpy
        if tensor.device.type == 'cuda':
            tensor = tensor.cpu()
        
        numpy_array = tensor.numpy()
        
        # ç¡®ä¿å€¼èŒƒå›´åœ¨[0, 255]
        if numpy_array.max() <= 1.0:
            numpy_array = (numpy_array * 255).astype(np.uint8)
        else:
            numpy_array = numpy_array.astype(np.uint8)
        
        return numpy_array
    
    def _generate_default_interactions(self, width: int, height: int) -> List[Dict[str, Any]]:
        """ç”Ÿæˆé»˜è®¤äº¤äº’ç‚¹"""
        # ç”Ÿæˆç½‘æ ¼é‡‡æ ·ç‚¹
        interactions = []
        
        # ä¸­å¿ƒç‚¹
        interactions.append({
            "type": "point",
            "point": [width // 2, height // 2]
        })
        
        # å››ä¸ªè±¡é™çš„ç‚¹
        for x_ratio, y_ratio in [(0.25, 0.25), (0.75, 0.25), (0.25, 0.75), (0.75, 0.75)]:
            interactions.append({
                "type": "point", 
                "point": [int(width * x_ratio), int(height * y_ratio)]
            })
        
        return interactions
    
    def _convert_to_layer_format(self, result: Dict[str, Any], index: int) -> Dict[str, Any]:
        """å°†SAM2ç»“æœè½¬æ¢ä¸ºæ ‡å‡†å±‚æ ¼å¼"""
        mask_data = result["mask"]
        method = result["method"]
        confidence = result["confidence"]
        
        # ç”Ÿæˆå”¯ä¸€ID
        layer_id = f"sam2_annotation_{int(torch.rand(1).item() * 1000000)}_{method.lower()}"
        
        # åŸºç¡€å±‚æ•°æ®
        layer = {
            "id": layer_id,
            "type": "detection",
            "name": f"{method}_object_{index + 1}",
            "confidence": confidence,
            "class_name": mask_data.get("class_name", "object"),
            "method": method,
            "visible": True,
            "color": self._get_color_by_confidence(confidence),
            "number": index + 1
        }
        
        # æ·»åŠ å‡ ä½•ä¿¡æ¯
        if "geometry" in mask_data:
            layer["geometry"] = mask_data["geometry"]
        
        # æ·»åŠ ä¸­å¿ƒç‚¹
        if "center" in mask_data:
            layer["center"] = mask_data["center"]
        
        # æ·»åŠ è½®å»“ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
        if "contours" in mask_data:
            layer["contours"] = mask_data["contours"]
        
        # æ·»åŠ maskæ•°æ®ï¼ˆå¦‚æœæœ‰ä¸”ä¸å¤ªå¤§ï¼‰
        if "mask" in mask_data and mask_data["mask"] is not None:
            layer["mask"] = mask_data["mask"]
        
        return layer
    
    def _get_color_by_confidence(self, confidence: float) -> str:
        """æ ¹æ®ç½®ä¿¡åº¦é€‰æ‹©é¢œè‰²"""
        if confidence >= 0.8:
            return "#00ff00"  # ç»¿è‰² - é«˜ç½®ä¿¡åº¦
        elif confidence >= 0.6:
            return "#ffff00"  # é»„è‰² - ä¸­ç­‰ç½®ä¿¡åº¦
        elif confidence >= 0.4:
            return "#ff8800"  # æ©™è‰² - è¾ƒä½ç½®ä¿¡åº¦
        else:
            return "#ff0000"  # çº¢è‰² - ä½ç½®ä¿¡åº¦
    
    def _create_fallback_result(self, error_msg: str):
        """åˆ›å»ºå›é€€ç»“æœ"""
        fallback_layers = [{
            "id": "fallback_annotation",
            "type": "error",
            "name": "Fallback Annotation",
            "confidence": 0.0,
            "class_name": "error",
            "method": "Fallback",
            "visible": True,
            "color": "#ff0000",
            "geometry": {
                "type": "rectangle",
                "coordinates": [10, 10, 100, 100]
            },
            "error": error_msg
        }]
        
        error_stats = {
            "error": error_msg,
            "models_loaded": {"fastsam": False, "sam2": False},
            "device": "cpu"
        }
        
        error_debug = {
            "error": error_msg,
            "fallback_used": True
        }
        
        return (
            json.dumps(fallback_layers, ensure_ascii=False),
            json.dumps(error_stats, ensure_ascii=False),
            json.dumps(error_debug, ensure_ascii=False)
        )

# ComfyUIèŠ‚ç‚¹æ³¨å†Œ
NODE_CLASS_MAPPINGS = {
    "SAM2IntelligentAnnotation": SAM2IntelligentAnnotationNode,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "SAM2IntelligentAnnotation": "ğŸ¤– SAM2 Intelligent Annotation",
}

if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    print("ğŸ§ª SAM2æ™ºèƒ½æ ‡æ³¨èŠ‚ç‚¹æµ‹è¯•")
    node = SAM2IntelligentAnnotationNode()
    print("âœ… èŠ‚ç‚¹åˆ›å»ºæˆåŠŸ")