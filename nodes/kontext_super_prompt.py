"""
Kontext Super Prompt Node
Kontextè¶…çº§æç¤ºè¯ç”ŸæˆèŠ‚ç‚¹ - å¤ç°Visual Prompt Editorå®Œæ•´åŠŸèƒ½

æ¥æ”¶ğŸ¨ LRPG Canvasçš„å›¾å±‚ä¿¡æ¯ï¼Œæä¾›å…¨é¢ç¼–è¾‘åŠŸèƒ½ï¼š
- å±€éƒ¨ç¼–è¾‘ï¼šé’ˆå¯¹é€‰å®šå›¾å±‚çš„ç²¾ç¡®ç¼–è¾‘
- å…¨å±€ç¼–è¾‘ï¼šæ•´ä½“å›¾åƒå¤„ç†æ“ä½œ  
- æ–‡å­—ç¼–è¾‘ï¼šæ–‡æœ¬å†…å®¹ç¼–è¾‘å’Œæ“ä½œ
- ä¸“ä¸šæ“ä½œï¼šé«˜çº§ä¸“ä¸šç¼–è¾‘å·¥å…·
- è‡ªåŠ¨ç”Ÿæˆä¿®é¥°çº¦æŸæ€§æç¤ºè¯
"""

import json
import base64
import time
import random
from typing import Dict, List, Any, Tuple, Optional
from datetime import datetime

# Optional dependencies
try:
    import torch
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False
    torch = None

try:
    import numpy as np
    NUMPY_AVAILABLE = True
except ImportError:
    NUMPY_AVAILABLE = False
    np = None

try:
    from server import PromptServer
    COMFY_AVAILABLE = True
except ImportError:
    COMFY_AVAILABLE = False

CATEGORY_TYPE = "ğŸ¨ LRPG Canvas"

class KontextSuperPrompt:
    """
    Kontextè¶…çº§æç¤ºè¯ç”Ÿæˆå™¨èŠ‚ç‚¹
    å¤ç°Visual Prompt Editorçš„å®Œæ•´ç¼–è¾‘åŠŸèƒ½
    """
    
    # åŸºç¡€é”™è¯¯å¤„ç†çš„æç¤ºè¯æ˜ å°„ - åªä¿ç•™æœ€å¸¸ç”¨çš„æ˜ å°„
    BASIC_PROMPT_MAPPING = {
        # åŸºç¡€çº¦æŸæ€§æç¤ºè¯
        'natural blending': 'è‡ªç„¶èåˆ',
        'improved detail': 'ç»†èŠ‚æ”¹å–„', 
        'professional quality': 'ä¸“ä¸šå“è´¨',
        'seamless integration': 'æ— ç¼é›†æˆ',
        
        # åŸºç¡€ä¿®é¥°æ€§æç¤ºè¯
        'enhanced quality': 'å¢å¼ºè´¨é‡',
        'improved visual impact': 'æå‡è§†è§‰æ•ˆæœ',
        'professional finish': 'ä¸“ä¸šå®Œæˆåº¦',
        'artistic excellence': 'è‰ºæœ¯å“è¶Š'
    }
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "layer_info": ("LAYER_INFO",),
                "image": ("IMAGE",),
            },
            "hidden": {
                "unique_id": "UNIQUE_ID",
                "edit_mode": (["å±€éƒ¨ç¼–è¾‘", "å…¨å±€ç¼–è¾‘", "æ–‡å­—ç¼–è¾‘", "ä¸“ä¸šæ“ä½œ"], {"default": "å±€éƒ¨ç¼–è¾‘"}),
                "operation_type": ("STRING", {"default": "", "multiline": False}),
                "description": ("STRING", {"default": "", "multiline": True}),
                "constraint_prompts": ("STRING", {"default": "", "multiline": True}),
                "decorative_prompts": ("STRING", {"default": "", "multiline": True}),
                "selected_layers": ("STRING", {"default": "", "multiline": True}),
                "auto_generate": ("BOOLEAN", {"default": True}),
                "generated_prompt": ("STRING", {"default": "", "multiline": True}),
            },
        }
    
    RETURN_TYPES = ("IMAGE", "STRING")
    RETURN_NAMES = ("edited_image", "generated_prompt")
    FUNCTION = "process_super_prompt"
    CATEGORY = CATEGORY_TYPE
    OUTPUT_NODE = False
    
    @classmethod
    def IS_CHANGED(cls, **kwargs):
        # å¼ºåˆ¶æ¯æ¬¡éƒ½é‡æ–°æ‰§è¡Œ
        return float(time.time())
    
    def process_super_prompt(self, layer_info, image, unique_id="", edit_mode="å±€éƒ¨ç¼–è¾‘", 
                           operation_type="", description="", constraint_prompts="", 
                           decorative_prompts="", selected_layers="", auto_generate=True, 
                           generated_prompt=""):
        """
        å¤„ç†Kontextè¶…çº§æç¤ºè¯ç”Ÿæˆ
        """
        try:
            print(f"[Kontext Super Prompt] å¼€å§‹å¤„ç†è¶…çº§æç¤ºè¯ç”Ÿæˆï¼ŒèŠ‚ç‚¹ID: {unique_id}")
            print(f"[Kontext Super Prompt] ç¼–è¾‘æ¨¡å¼: {edit_mode}")
            print(f"[Kontext Super Prompt] æ“ä½œç±»å‹: '{operation_type}'")
            print(f"[Kontext Super Prompt] æè¿°: '{description}'")
            print(f"[Kontext Super Prompt] çº¦æŸæç¤ºè¯: '{constraint_prompts}'")
            print(f"[Kontext Super Prompt] ä¿®é¥°æç¤ºè¯: '{decorative_prompts}'")
            print(f"[Kontext Super Prompt] è‡ªåŠ¨ç”Ÿæˆ: {auto_generate}")
            print(f"[Kontext Super Prompt] å‰ç«¯ä¼ æ¥çš„ç”Ÿæˆæç¤ºè¯: '{generated_prompt}'")
            print(f"[Kontext Super Prompt] å‰ç«¯ä¼ æ¥çš„ç”Ÿæˆæç¤ºè¯é•¿åº¦: {len(generated_prompt)}")
            
            # ä¼˜å…ˆä½¿ç”¨å‰ç«¯ä¼ æ¥çš„generated_promptï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨åç«¯ç”Ÿæˆ
            if generated_prompt and generated_prompt.strip():
                print("[Kontext Super Prompt] ä½¿ç”¨å‰ç«¯ç”Ÿæˆçš„æç¤ºè¯")
                final_generated_prompt = generated_prompt.strip()
            else:
                print("[Kontext Super Prompt] å‰ç«¯æœªæä¾›æç¤ºè¯ï¼Œä½¿ç”¨åç«¯ç”Ÿæˆ")
                # è§£æå›¾å±‚ä¿¡æ¯
                parsed_layer_info = self.parse_layer_info(layer_info)
                
                # è§£æé€‰ä¸­çš„å›¾å±‚
                selected_layer_ids = self.parse_selected_layers(selected_layers)
                
                # è§£æçº¦æŸæ€§å’Œä¿®é¥°æ€§æç¤ºè¯
                constraint_list = self.parse_prompt_list(constraint_prompts)
                decorative_list = self.parse_prompt_list(decorative_prompts)
                
                # ç”ŸæˆåŸºç¡€fallbackæç¤ºè¯
                positive_prompt, negative_prompt, full_description = self.generate_basic_fallback_prompts(
                    edit_mode=edit_mode,
                    operation_type=operation_type,
                    description=description,
                    constraint_prompts=constraint_list,
                    decorative_prompts=decorative_list
                )
                
                # åˆå¹¶æ‰€æœ‰æç¤ºè¯ä¿¡æ¯ä¸ºä¸€ä¸ªå®Œæ•´çš„ç”Ÿæˆæç¤ºè¯
                final_generated_prompt = f"{positive_prompt}\n\nNegative: {negative_prompt}\n\n{full_description}"
            
            # æ„å»ºç¼–è¾‘æ•°æ®ï¼ˆç”¨äºè°ƒè¯•å’Œæ‰©å±•ï¼‰
            edit_data = {
                'node_id': unique_id,
                'edit_mode': edit_mode,
                'operation_type': operation_type,
                'description': description,
                'generated_prompt_source': 'frontend' if generated_prompt and generated_prompt.strip() else 'backend',
                'timestamp': time.time()
            }
            
            print(f"[Kontext Super Prompt] æœ€ç»ˆç”Ÿæˆæç¤ºè¯æ¥æº: {edit_data['generated_prompt_source']}")
            return (image, final_generated_prompt)
            
        except Exception as e:
            print(f"[Kontext Super Prompt] å¤„ç†é”™è¯¯: {str(e)}")
            import traceback
            traceback.print_exc()
            
            # è¿”å›é»˜è®¤å€¼
            default_edit_data = {
                'node_id': unique_id,
                'edit_mode': edit_mode,
                'error': str(e),
                'timestamp': time.time()
            }
            return (image, "å¤„ç†å‡ºé”™ï¼š" + str(e))
    
    def parse_layer_info(self, layer_info):
        """è§£æå›¾å±‚ä¿¡æ¯"""
        if isinstance(layer_info, dict):
            return layer_info
        return {}
    
    def parse_selected_layers(self, selected_layers_str):
        """è§£æé€‰ä¸­çš„å›¾å±‚"""
        if not selected_layers_str:
            return []
        try:
            return json.loads(selected_layers_str)
        except:
            return []
    
    def parse_prompt_list(self, prompt_str):
        """è§£ææç¤ºè¯åˆ—è¡¨"""
        if not prompt_str:
            return []
        
        # æ”¯æŒå¤šç§åˆ†éš”ç¬¦
        prompts = []
        for line in prompt_str.split('\n'):
            line = line.strip()
            if line:
                # æ”¯æŒé€—å·åˆ†éš”
                if ',' in line:
                    prompts.extend([p.strip() for p in line.split(',') if p.strip()])
                else:
                    prompts.append(line)
        return prompts
    
    def translate_basic_prompts(self, prompts):
        """å°†åŸºç¡€è‹±æ–‡æç¤ºè¯è½¬æ¢ä¸ºä¸­æ–‡æ˜¾ç¤º"""
        translated = []
        for prompt in prompts:
            if prompt in self.BASIC_PROMPT_MAPPING:
                translated.append(self.BASIC_PROMPT_MAPPING[prompt])
            else:
                translated.append(prompt)  # ä¿æŒåŸæ–‡ï¼Œå¦‚æœæ²¡æœ‰æ˜ å°„
        return translated
    
    def generate_fallback_prompt(self, edit_mode, operation_type, description):
        """ç”ŸæˆåŸºç¡€fallbackæç¤ºè¯ - ä»…åœ¨å‰ç«¯æœªæä¾›æ—¶ä½¿ç”¨"""
        # åŸºç¡€æç¤ºè¯æ¨¡æ¿
        basic_templates = {
            'change_color': f'change color to {description or "specified color"}',
            'blur_background': f'blur background while keeping {description or "subject"} sharp',
            'enhance_quality': f'enhance quality of {description or "image"}',
        }
        
        # åŸºç¡€çº¦æŸå’Œä¿®é¥°è¯
        basic_constraints = ['natural blending', 'seamless integration']
        basic_decoratives = ['improved detail', 'enhanced quality']
        
        # æ„å»ºåŸºç¡€æç¤ºè¯
        if operation_type and operation_type in basic_templates:
            base_prompt = basic_templates[operation_type]
        else:
            base_prompt = f"{edit_mode}: {description or 'apply editing'}"
        
        return base_prompt, basic_constraints, basic_decoratives
    
    def generate_basic_fallback_prompts(self, edit_mode, operation_type, description, 
                                       constraint_prompts, decorative_prompts):
        """ç”ŸæˆåŸºç¡€fallbackæç¤ºè¯ - ä»…åœ¨å‰ç«¯å®Œå…¨å¤±æ•ˆæ—¶ä½¿ç”¨"""
        # ä½¿ç”¨ç²¾ç®€çš„fallbackç”Ÿæˆå™¨
        base_prompt, basic_constraints, basic_decoratives = self.generate_fallback_prompt(
            edit_mode, operation_type, description
        )
        
        # ç»„åˆæç¤ºè¯
        all_constraints = constraint_prompts + basic_constraints
        all_decoratives = decorative_prompts + basic_decoratives
        
        # æ„å»ºæ­£å‘æç¤ºè¯
        positive_parts = [base_prompt]
        if all_constraints:
            positive_parts.extend(all_constraints[:3])  # é™åˆ¶æ•°é‡
        if all_decoratives:
            positive_parts.extend(all_decoratives[:2])   # é™åˆ¶æ•°é‡
        
        positive_prompt = ", ".join(positive_parts)
        
        # åŸºç¡€è´Ÿå‘æç¤ºè¯
        negative_prompt = "artifacts, distortions, unnatural appearance, poor quality, inconsistencies, blurry, low quality, artifacts, distorted, unnatural, poor composition, bad anatomy, incorrect proportions"
        
        # æ„å»ºå®Œæ•´æè¿°
        full_description_parts = [
            f"ç¼–è¾‘æ¨¡å¼ï¼š{edit_mode}",
            f"æ“ä½œç±»å‹ï¼š{operation_type or 'æœªæŒ‡å®š'}",
            f"æè¿°ï¼š{description or 'æœªæä¾›'}",
        ]
        
        if all_constraints:
            constraint_display = self.translate_basic_prompts(all_constraints[:3])
            full_description_parts.append(f"çº¦æŸæ€§æç¤ºè¯ï¼š{', '.join(constraint_display)}")
        
        if all_decoratives:
            decorative_display = self.translate_basic_prompts(all_decoratives[:2])
            full_description_parts.append(f"ä¿®é¥°æ€§æç¤ºè¯ï¼š{', '.join(decorative_display)}")
        
        full_description = " | ".join(full_description_parts)
        
        return positive_prompt, negative_prompt, full_description


# æ³¨å†ŒèŠ‚ç‚¹
NODE_CLASS_MAPPINGS = {
    "KontextSuperPrompt": KontextSuperPrompt,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "KontextSuperPrompt": "ğŸ¯ Kontext Super Prompt",
}

print("[Kontext Super Prompt] ğŸ¯ Kontextè¶…çº§æç¤ºè¯èŠ‚ç‚¹å·²æ³¨å†Œ")