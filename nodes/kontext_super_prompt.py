"""
Kontext Super Prompt Node
Kontextè¶…çº§æç¤ºè¯ç”ŸæˆèŠ‚ç‚¹ - å¤ç°Visual Prompt Editorå®Œæ•´åŠŸèƒ½

æ¥æ”¶ğŸ¨ LRPG Canvasçš„å›¾å±‚ä¿¡æ¯ï¼Œæä¾›å…¨é¢ç¼–è¾‘åŠŸèƒ½ï¼š
- å±€éƒ¨ç¼–è¾‘ï¼šé’ˆå¯¹é€‰å®šå›¾å±‚çš„ç²¾ç¡®ç¼–è¾‘
- å…¨å±€ç¼–è¾‘ï¼šæ•´ä½“å›¾åƒå¤„ç†æ“ä½œ  
- æ–‡å­—ç¼–è¾‘ï¼šæ–‡æœ¬å†…å®¹ç¼–è¾‘å’Œæ“ä½œ
- ä¸“ä¸šæ“ä½œï¼šé«˜çº§ä¸“ä¸šç¼–è¾‘å·¥å…·
- è‡ªåŠ¨ç”Ÿæˆä¿®é¥°çº¦æŸæ€§æç¤ºè¯
"""

import json
import base64
import time
import random
import os
import sys
from typing import Dict, List, Any, Tuple, Optional
from datetime import datetime

# æ·»åŠ èŠ‚ç‚¹ç›®å½•åˆ°ç³»ç»Ÿè·¯å¾„ä»¥å¯¼å…¥å…¶ä»–èŠ‚ç‚¹
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

# å¯¼å…¥å¢å¼ºçº¦æŸç³»ç»Ÿ
try:
    from .intelligent_constraint_generator import intelligent_constraint_generator
    ENHANCED_SYSTEM_AVAILABLE = True
    print("[Kontext Super Prompt] å¢å¼ºçº¦æŸç³»ç»Ÿå·²åŠ è½½")
except ImportError as e:
    ENHANCED_SYSTEM_AVAILABLE = False
    intelligent_constraint_generator = None
    print(f"[Kontext Super Prompt] å¢å¼ºçº¦æŸç³»ç»ŸåŠ è½½å¤±è´¥: {e}")

# é…ç½®ç®¡ç†å™¨å·²ç§»é™¤ï¼ŒAPIå¯†é’¥éœ€è¦æ¯æ¬¡æ‰‹åŠ¨è¾“å…¥
CONFIG_AVAILABLE = False

# æ–¹æ¡ˆAä¸“ä¸šå¼•å¯¼è¯åº“
GUIDANCE_LIBRARY_A = {
    "editing_intents": {
        "color_adjustment": [
            "precise color grading and tonal balance adjustment",
            "selective color modification with natural transitions",
            "hue, saturation and luminance fine-tuning",
            "color harmony optimization and palette refinement",
            "advanced color correction with preserved details"
        ],
        "object_removal": [
            "seamless object erasure with intelligent content-aware fill",
            "advanced inpainting with texture and pattern reconstruction",
            "clean removal with contextual background regeneration",
            "professional retouching with invisible object extraction",
            "content-aware deletion with natural scene completion"
        ],
        "object_replacement": [
            "intelligent object substitution with matched lighting and perspective",
            "seamless element swapping with proper shadow and reflection",
            "context-aware replacement maintaining scene coherence",
            "professional object exchange with realistic integration",
            "smart substitution with automatic color and scale matching"
        ],
        "object_addition": [
            "realistic object insertion with proper depth and occlusion",
            "natural element placement with accurate shadows and lighting",
            "contextual object addition with scene-aware compositing",
            "professional element integration with believable interactions",
            "intelligent object placement with automatic perspective matching"
        ],
        "background_change": [
            "professional background replacement with edge refinement",
            "environmental substitution with matched lighting conditions",
            "seamless backdrop swapping with hair and transparency handling",
            "studio-quality background modification with depth preservation",
            "intelligent scene replacement with automatic color grading"
        ],
        "face_swap": [
            "advanced facial replacement with expression preservation",
            "seamless face swapping with skin tone matching",
            "professional identity transfer with natural blending",
            "intelligent facial substitution with feature alignment",
            "realistic face exchange with age and lighting adaptation"
        ],
        "quality_enhancement": [
            "professional upscaling with detail enhancement and noise reduction",
            "AI-powered quality improvement with texture preservation",
            "advanced sharpening and clarity optimization",
            "intelligent detail recovery with artifact removal",
            "studio-grade enhancement with dynamic range expansion"
        ],
        "image_restoration": [
            "professional damage repair and artifact removal",
            "historical photo restoration with detail reconstruction",
            "advanced scratch and tear healing with texture synthesis",
            "intelligent restoration with color and contrast recovery",
            "museum-quality preservation with authentic detail retention"
        ],
        "style_transfer": [
            "artistic style application with content preservation",
            "professional aesthetic transformation with selective stylization",
            "intelligent style mapping with detail retention",
            "creative interpretation with balanced artistic expression",
            "advanced neural style transfer with customizable intensity"
        ],
        "text_editing": [
            "professional typography modification and text replacement",
            "intelligent text editing with font matching",
            "seamless text overlay with proper perspective and distortion",
            "advanced text manipulation with style preservation",
            "clean text removal and insertion with background recovery"
        ],
        "lighting_adjustment": [
            "professional lighting enhancement with natural shadows",
            "studio lighting simulation with directional control",
            "ambient light modification with mood preservation",
            "advanced exposure correction with highlight and shadow recovery",
            "cinematic lighting effects with realistic light propagation"
        ],
        "perspective_correction": [
            "professional lens distortion and perspective correction",
            "architectural straightening with proportion preservation",
            "advanced geometric transformation with content awareness",
            "keystone correction with automatic crop optimization",
            "wide-angle distortion removal with natural field of view"
        ],
        "blur_sharpen": [
            "selective focus adjustment with depth-aware processing",
            "professional bokeh simulation with realistic blur circles",
            "intelligent sharpening with edge preservation",
            "motion blur addition or removal with directional control",
            "tilt-shift effect with miniature scene simulation"
        ],
        "local_deformation": [
            "precise mesh-based warping with smooth transitions",
            "intelligent liquify with automatic proportion adjustment",
            "professional shape modification with natural deformation",
            "content-aware scaling with important feature preservation",
            "advanced morphing with realistic tissue behavior"
        ],
        "composition_adjustment": [
            "professional reframing with rule of thirds optimization",
            "intelligent cropping with subject-aware composition",
            "dynamic layout adjustment with visual balance enhancement",
            "golden ratio composition with automatic guide alignment",
            "cinematic aspect ratio conversion with content preservation"
        ],
        "general_editing": [
            "comprehensive image optimization with intelligent enhancement",
            "multi-aspect improvement with balanced adjustments",
            "professional post-processing with workflow automation",
            "adaptive editing with content-aware optimization",
            "flexible enhancement pipeline with customizable parameters"
        ]
    },
    "processing_styles": {
        "ecommerce_product": [
            "clean e-commerce presentation with pure white background and studio lighting",
            "professional product showcase with shadow detail and color accuracy",
            "commercial quality with floating product and reflection effects",
            "marketplace-ready presentation with standardized lighting setup",
            "retail-optimized display with crisp edges and neutral backdrop"
        ],
        "social_media": [
            "Instagram-worthy aesthetic with vibrant colors and high engagement appeal",
            "viral-ready content with thumb-stopping visual impact",
            "influencer-style presentation with trendy filters and effects",
            "platform-optimized format with mobile-first composition",
            "shareable content with emotional resonance and visual storytelling"
        ],
        "marketing_campaign": [
            "compelling campaign visual with strong brand message integration",
            "conversion-focused design with clear call-to-action placement",
            "professional advertising quality with psychological impact",
            "multi-channel campaign asset with consistent brand identity",
            "high-impact promotional material with memorable visual hook"
        ],
        "portrait_professional": [
            "executive headshot quality with confident professional presence",
            "LinkedIn-optimized portrait with approachable business aesthetic",
            "corporate photography standard with formal lighting setup",
            "professional profile image with personality and credibility",
            "studio portrait quality with flattering light and composition"
        ],
        "lifestyle": [
            "authentic lifestyle capture with natural, candid moments",
            "aspirational living aesthetic with warm, inviting atmosphere",
            "editorial lifestyle quality with storytelling elements",
            "wellness-focused imagery with organic, mindful presentation",
            "contemporary lifestyle documentation with relatable scenarios"
        ],
        "food_photography": [
            "appetizing food presentation with steam and freshness indicators",
            "culinary art photography with ingredient highlighting",
            "restaurant menu quality with professional food styling",
            "cookbook-worthy capture with recipe visualization",
            "gourmet presentation with texture emphasis and garnish details"
        ],
        "real_estate": [
            "MLS-ready property showcase with wide-angle room capture",
            "architectural photography standard with vertical line correction",
            "luxury real estate presentation with HDR processing",
            "virtual tour quality with consistent exposure across rooms",
            "property listing optimization with bright, spacious feel"
        ],
        "fashion_retail": [
            "editorial fashion quality with dynamic pose and movement",
            "lookbook presentation with outfit detail emphasis",
            "runway-inspired capture with dramatic lighting",
            "e-commerce fashion standard with consistent model positioning",
            "luxury brand aesthetic with premium texture showcase"
        ],
        "automotive": [
            "showroom quality presentation with paint reflection detail",
            "automotive advertising standard with dynamic angle selection",
            "dealership display quality with feature highlighting",
            "car enthusiast photography with performance emphasis",
            "luxury vehicle showcase with premium detailing focus"
        ],
        "beauty_cosmetics": [
            "beauty campaign quality with flawless skin retouching",
            "cosmetic product showcase with texture and color accuracy",
            "makeup artistry documentation with before/after clarity",
            "skincare photography with healthy glow emphasis",
            "beauty editorial standard with artistic color grading"
        ],
        "corporate_branding": [
            "brand guideline compliant with consistent visual identity",
            "corporate communication standard with professional polish",
            "annual report quality with data visualization clarity",
            "company culture showcase with authentic employee moments",
            "B2B presentation standard with trust-building imagery"
        ],
        "event_photography": [
            "event documentation with decisive moment capture",
            "conference photography standard with speaker and audience coverage",
            "wedding photography quality with emotional storytelling",
            "concert capture with stage lighting and crowd energy",
            "corporate event coverage with networking moment emphasis"
        ],
        "product_catalog": [
            "catalog-ready presentation with consistent angle and lighting",
            "technical documentation quality with detail visibility",
            "e-commerce grid compatibility with standardized framing",
            "print catalog standard with color accuracy and sharpness",
            "inventory photography with SKU identification clarity"
        ],
        "artistic_creation": [
            "gallery-worthy artistic interpretation with conceptual depth",
            "fine art photography standard with emotional expression",
            "creative vision with experimental technique application",
            "artistic portfolio quality with unique visual signature",
            "contemporary art aesthetic with boundary-pushing composition"
        ],
        "documentary": [
            "photojournalistic integrity with unaltered reality capture",
            "documentary storytelling with contextual environment",
            "street photography aesthetic with decisive moment timing",
            "reportage quality with narrative sequence potential",
            "archival documentation standard with historical accuracy"
        ],
        "auto_smart": [
            "AI-optimized enhancement with intelligent scene detection",
            "automatic quality improvement with balanced adjustments",
            "smart processing with content-aware optimization",
            "one-click enhancement with professional results",
            "adaptive editing with machine learning refinement"
        ]
    }
}

def get_intent_guidance(intent_key):
    """è·å–ç¼–è¾‘æ„å›¾å¼•å¯¼è¯ï¼ˆæ–¹æ¡ˆAï¼‰"""
    options = GUIDANCE_LIBRARY_A["editing_intents"].get(intent_key, GUIDANCE_LIBRARY_A["editing_intents"]["general_editing"])
    return random.choice(options)

def get_style_guidance(style_key):
    """è·å–å¤„ç†é£æ ¼å¼•å¯¼è¯ï¼ˆæ–¹æ¡ˆAï¼‰"""
    options = GUIDANCE_LIBRARY_A["processing_styles"].get(style_key, GUIDANCE_LIBRARY_A["processing_styles"]["auto_smart"])
    return random.choice(options)

# Optional dependencies
try:
    import torch
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False
    torch = None

try:
    import numpy as np
    NUMPY_AVAILABLE = True
except ImportError:
    NUMPY_AVAILABLE = False
    np = None

try:
    from server import PromptServer
    COMFY_AVAILABLE = True
except ImportError:
    COMFY_AVAILABLE = False

CATEGORY_TYPE = "ğŸ¨ Super Canvas"

class KontextSuperPrompt:
    """
    Kontextè¶…çº§æç¤ºè¯ç”Ÿæˆå™¨èŠ‚ç‚¹
    å¤ç°Visual Prompt Editorçš„å®Œæ•´ç¼–è¾‘åŠŸèƒ½
    """
    
    # å¢å¼ºçº¦æŸç³»ç»Ÿ - åŸºäº1026æ•°æ®é›†åˆ†æçš„ä¸‰å±‚çº¦æŸæ¶æ„
    ENHANCED_CONSTRAINT_SYSTEM = {
        # ç¬¬ä¸€å±‚ï¼šæ“ä½œç‰¹å¼‚æ€§çº¦æŸæ˜ å°„
        'operation_constraints': {
            'add': ['seamless visual integration', 'perspective geometry alignment', 'natural edge transitions'],
            'remove': ['content-aware background reconstruction', 'invisible trace elimination', 'natural background extension'],
            'color': ['color space management precision', 'natural color transitions', 'material authenticity preservation'],
            'shape': ['morphological structure preservation', 'proportional scaling accuracy', 'surface continuity maintenance'],
            'text': ['typographic hierarchy support', 'readability optimization', 'professional typography standards'],
            'background': ['lighting condition matching', 'atmospheric perspective alignment', 'seamless compositing quality']
        },
        
        # ç¬¬äºŒå±‚ï¼šè®¤çŸ¥è´Ÿè·é€‚é…çº¦æŸ
        'cognitive_constraints': {
            'low_complexity': ['precise technical execution', 'quality standard compliance', 'immediate visual feedback'],
            'medium_complexity': ['professional polish integration', 'contextual appropriateness', 'commercial viability assurance'],
            'high_complexity': ['conceptual innovation achievement', 'artistic expression authenticity', 'emotional resonance cultivation']
        },
        
        # ç¬¬ä¸‰å±‚ï¼šè¯­ä¹‰ä¿®é¥°è¯å¼ºåº¦åˆ†çº§
        'semantic_modifiers': {
            'level_1_technical': ['precisely executed', 'technically accurate', 'systematically controlled', 'quality assured'],
            'level_2_professional': ['commercially viable', 'professionally polished', 'contextually optimized', 'aesthetically balanced'],
            'level_3_creative': ['conceptually revolutionary', 'artistically transcendent', 'culturally resonant', 'visually transformative']
        }
    }
    
    @classmethod
    def INPUT_TYPES(cls):
        # ä»é…ç½®ç®¡ç†å™¨åŠ è½½é»˜è®¤è®¾ç½®
        api_settings = {}
        ollama_settings = {}
        ui_settings = {}
        
        if CONFIG_AVAILABLE:
            try:
                api_settings = get_api_settings()
                ollama_settings = config_manager.get_ollama_settings()
                ui_settings = config_manager.get_ui_settings()
            except Exception as e:
                pass
        
        return {
            "required": {
                "layer_info": ("LAYER_INFO",),
                "image": ("IMAGE",),
            },
            "optional": {
            },
            "hidden": {
                "unique_id": "UNIQUE_ID",
                "tab_mode": (["manual", "api", "ollama"], {"default": ui_settings.get("last_tab", "manual")}),
                "edit_mode": (["å±€éƒ¨ç¼–è¾‘", "å…¨å±€ç¼–è¾‘", "æ–‡å­—ç¼–è¾‘", "ä¸“ä¸šæ“ä½œ"], {"default": "å±€éƒ¨ç¼–è¾‘"}),
                "operation_type": ("STRING", {"default": "", "multiline": False}),
                "constraint_prompts": ("STRING", {"default": "", "multiline": True}),
                "decorative_prompts": ("STRING", {"default": "", "multiline": True}),
                "selected_layers": ("STRING", {"default": "", "multiline": True}),
                "auto_generate": ("BOOLEAN", {"default": True}),
                
                # å±€éƒ¨ç¼–è¾‘é€‰é¡¹å¡ - æŒä¹…åŒ–æ•°æ®
                "local_description": ("STRING", {"default": "", "multiline": True}),
                "local_generated_prompt": ("STRING", {"default": "", "multiline": True}),
                "local_operation_type": ("STRING", {"default": "add_object"}),
                "local_selected_constraints": ("STRING", {"default": "", "multiline": True}),
                "local_selected_decoratives": ("STRING", {"default": "", "multiline": True}),
                
                # å…¨å±€ç¼–è¾‘é€‰é¡¹å¡ - æŒä¹…åŒ–æ•°æ®
                "global_description": ("STRING", {"default": "", "multiline": True}),
                "global_generated_prompt": ("STRING", {"default": "", "multiline": True}),
                "global_operation_type": ("STRING", {"default": "global_color_grade"}),
                "global_selected_constraints": ("STRING", {"default": "", "multiline": True}),
                "global_selected_decoratives": ("STRING", {"default": "", "multiline": True}),
                
                # æ–‡å­—ç¼–è¾‘é€‰é¡¹å¡ - æŒä¹…åŒ–æ•°æ®
                "text_description": ("STRING", {"default": "", "multiline": True}),
                "text_generated_prompt": ("STRING", {"default": "", "multiline": True}),
                "text_operation_type": ("STRING", {"default": "text_add"}),
                "text_selected_constraints": ("STRING", {"default": "", "multiline": True}),
                "text_selected_decoratives": ("STRING", {"default": "", "multiline": True}),
                
                # ä¸“ä¸šæ“ä½œé€‰é¡¹å¡ - æŒä¹…åŒ–æ•°æ®
                "professional_description": ("STRING", {"default": "", "multiline": True}),
                "professional_generated_prompt": ("STRING", {"default": "", "multiline": True}),
                "professional_operation_type": ("STRING", {"default": "geometric_warp"}),
                "professional_selected_constraints": ("STRING", {"default": "", "multiline": True}),
                "professional_selected_decoratives": ("STRING", {"default": "", "multiline": True}),
                
                # APIé€‰é¡¹å¡ - æŒä¹…åŒ–æ•°æ®
                "api_description": ("STRING", {"default": "", "multiline": True}),
                "api_generated_prompt": ("STRING", {"default": "", "multiline": True}),
                "api_provider": ("STRING", {"default": api_settings.get("last_provider", "siliconflow")}),
                "api_key": ("STRING", {"default": "", "placeholder": "APIå¯†é’¥å°†è‡ªåŠ¨ä¿å­˜å’ŒåŠ è½½"}),
                "api_model": ("STRING", {"default": api_settings.get("last_model", "deepseek-ai/DeepSeek-V3")}),
                "api_editing_intent": ("STRING", {"default": api_settings.get("last_editing_intent", "general_editing")}),
                "api_processing_style": ("STRING", {"default": api_settings.get("last_processing_style", "auto_smart")}),
                "api_seed": ("INT", {"default": 0}),
                "api_custom_guidance": ("STRING", {"default": "", "multiline": True}),
                
                # Ollamaé€‰é¡¹å¡ - æŒä¹…åŒ–æ•°æ®
                "ollama_description": ("STRING", {"default": "", "multiline": True}),
                "ollama_generated_prompt": ("STRING", {"default": "", "multiline": True}),
                "ollama_url": ("STRING", {"default": ollama_settings.get("last_url", "http://127.0.0.1:11434")}),
                "ollama_model": ("STRING", {"default": ollama_settings.get("last_model", "")}),
                "ollama_temperature": ("FLOAT", {"default": ollama_settings.get("last_temperature", 0.7)}),
                "ollama_editing_intent": ("STRING", {"default": ollama_settings.get("last_editing_intent", "general_editing")}),
                "ollama_processing_style": ("STRING", {"default": ollama_settings.get("last_processing_style", "auto_smart")}),
                "ollama_seed": ("INT", {"default": 42}),
                "ollama_custom_guidance": ("STRING", {"default": "", "multiline": True}),
                "ollama_enable_visual": ("BOOLEAN", {"default": ollama_settings.get("enable_visual", False)}),
                "ollama_auto_unload": ("BOOLEAN", {"default": ollama_settings.get("auto_unload", False)}),
                
                # å…¼å®¹æ—§ç‰ˆæœ¬ - ä¿ç•™åŸå§‹å­—æ®µ
                "description": ("STRING", {"default": "", "multiline": True}),
                "generated_prompt": ("STRING", {"default": "", "multiline": True}),
            },
        }
    
    RETURN_TYPES = ("IMAGE", "STRING")
    RETURN_NAMES = ("edited_image", "generated_prompt")
    FUNCTION = "process_super_prompt"
    CATEGORY = CATEGORY_TYPE
    OUTPUT_NODE = False
    
    def __init__(self):
        """åˆå§‹åŒ–èŠ‚ç‚¹å¹¶è‡ªåŠ¨å¡«å……ä¿å­˜çš„è®¾ç½®"""
        super().__init__()
        
        # å¦‚æœé…ç½®ç®¡ç†å™¨å¯ç”¨ï¼Œè‡ªåŠ¨å¡«å……ä¿å­˜çš„APIå¯†é’¥
        if CONFIG_AVAILABLE:
            try:
                self._auto_fill_saved_settings()
            except Exception as e:
                pass
    
    def _auto_fill_saved_settings(self):
        """è‡ªåŠ¨å¡«å……ä¿å­˜çš„è®¾ç½®"""
        if not hasattr(self, 'widgets') or not self.widgets:
            return
            
        # è·å–ä¿å­˜çš„è®¾ç½®
        api_settings = get_api_settings()
        ollama_settings = config_manager.get_ollama_settings()
        
        # è‡ªåŠ¨å¡«å……APIå¯†é’¥
        api_provider_widget = next((w for w in self.widgets if hasattr(w, 'name') and w.name == "api_provider"), None)
        api_key_widget = next((w for w in self.widgets if hasattr(w, 'name') and w.name == "api_key"), None)
        
        if api_provider_widget and api_key_widget:
            provider = api_provider_widget.value
            saved_key = get_api_key(provider)
            if saved_key and (not api_key_widget.value or api_key_widget.value.strip() == ""):
                api_key_widget.value = saved_key
    
    @classmethod
    def IS_CHANGED(cls, **kwargs):
        # æ™ºèƒ½å˜åŒ–æ£€æµ‹ï¼šåªåœ¨å…³é”®å‚æ•°æ”¹å˜æ—¶è§¦å‘é‡æ–°æ‰§è¡Œ
        # è¿™æ ·æ—¢ä¿æŒwidgetçŠ¶æ€ï¼Œåˆæ”¯æŒéšæœºæ€§å’Œé…ç½®æ›´æ–°
        
        # æå–å…³é”®å‚æ•°ç”¨äºå˜åŒ–æ£€æµ‹
        api_seed = kwargs.get("api_seed", 0)
        ollama_seed = kwargs.get("ollama_seed", 42)
        tab_mode = kwargs.get("tab_mode", "manual")
        api_provider = kwargs.get("api_provider", "siliconflow")
        api_model = kwargs.get("api_model", "")
        ollama_model = kwargs.get("ollama_model", "")
        
        # æ„å»ºå˜åŒ–æ£€æµ‹å­—ç¬¦ä¸²ï¼ˆä¸åŒ…å«æ—¶é—´æˆ³ï¼‰
        change_factors = [
            f"api_seed:{api_seed}",
            f"ollama_seed:{ollama_seed}",
            f"tab_mode:{tab_mode}",
            f"api_provider:{api_provider}",
            f"api_model:{api_model}",
            f"ollama_model:{ollama_model}",
        ]
        
        change_string = "|".join(change_factors)
        return change_string
    
    def process_super_prompt(self, layer_info, image, 
                           # Optionalå‚æ•° - æ¯ä¸ªé€‰é¡¹å¡çš„ç‹¬ç«‹æ•°æ®
                           # å±€éƒ¨ç¼–è¾‘
                           local_description="", local_generated_prompt="", local_operation_type="add_object",
                           local_selected_constraints="", local_selected_decoratives="",
                           # å…¨å±€ç¼–è¾‘
                           global_description="", global_generated_prompt="", global_operation_type="global_color_grade",
                           global_selected_constraints="", global_selected_decoratives="",
                           # æ–‡å­—ç¼–è¾‘
                           text_description="", text_generated_prompt="", text_operation_type="text_add",
                           text_selected_constraints="", text_selected_decoratives="",
                           # ä¸“ä¸šæ“ä½œ
                           professional_description="", professional_generated_prompt="", professional_operation_type="geometric_warp",
                           professional_selected_constraints="", professional_selected_decoratives="",
                           # APIé€‰é¡¹å¡
                           api_description="", api_generated_prompt="",
                           api_provider="siliconflow", api_key="", api_model="deepseek-ai/DeepSeek-V3",
                           # Ollamaé€‰é¡¹å¡
                           ollama_description="", ollama_generated_prompt="",
                           ollama_url="http://127.0.0.1:11434", ollama_model="",
                           # å…¼å®¹æ—§ç‰ˆæœ¬
                           description="", generated_prompt="",
                           # Hiddenå‚æ•°
                           tab_mode="manual", unique_id="", edit_mode="å±€éƒ¨ç¼–è¾‘", 
                           operation_type="", constraint_prompts="", 
                           decorative_prompts="", selected_layers="", auto_generate=True, 
                           # APIé€‰é¡¹å¡å‚æ•°
                           api_editing_intent="general_editing", api_processing_style="auto_smart",
                           api_seed=0, api_custom_guidance="",
                           # Ollamaé€‰é¡¹å¡å‚æ•°  
                           ollama_temperature=0.7, ollama_editing_intent="general_editing", 
                           ollama_processing_style="auto_smart", ollama_seed=42, 
                           ollama_custom_guidance="", ollama_enable_visual=False,
                           ollama_auto_unload=False):
        """
        å¤„ç†Kontextè¶…çº§æç¤ºè¯ç”Ÿæˆ
        """
        try:
            # ä¿å­˜ç”¨æˆ·è®¾ç½®åˆ°é…ç½®ç®¡ç†å™¨
            if CONFIG_AVAILABLE:
                try:
                    # ä¿å­˜UIè®¾ç½®ï¼ˆå½“å‰é€‰é¡¹å¡ï¼‰
                    config_manager.save_ui_settings(tab_mode)
                    
                    # å¦‚æœæ˜¯APIæ¨¡å¼ï¼Œä¿å­˜APIè®¾ç½®å’Œå¯†é’¥
                    if tab_mode == "api":
                        if api_key and api_key.strip():
                            save_api_key(api_provider, api_key.strip())
                        
                        save_api_settings(api_provider, api_model, api_editing_intent, api_processing_style)
                        
                        # å¦‚æœæ²¡æœ‰æä¾›APIå¯†é’¥ï¼Œå°è¯•ä»é…ç½®åŠ è½½
                        if not api_key or not api_key.strip():
                            saved_key = get_api_key(api_provider)
                            if saved_key:
                                api_key = saved_key
                    
                    # å¦‚æœæ˜¯Ollamaæ¨¡å¼ï¼Œä¿å­˜Ollamaè®¾ç½®
                    elif tab_mode == "ollama":
                        config_manager.save_ollama_settings(
                            ollama_url, ollama_model, ollama_temperature,
                            ollama_editing_intent, ollama_processing_style,
                            ollama_enable_visual, ollama_auto_unload
                        )
                        
                except Exception as e:
                    pass
            
            # æ ¹æ®é€‰é¡¹å¡æ¨¡å¼å¤„ç†
            if tab_mode == "api":
                # APIæ¨¡å¼ï¼šä¼˜å…ˆä½¿ç”¨api_generated_promptï¼Œç„¶åæ˜¯generated_promptï¼Œæœ€åæ˜¯å®æ—¶ç”Ÿæˆ
                if api_generated_prompt and api_generated_prompt.strip():
                    # æ¸…ç†api_generated_promptï¼Œå»é™¤è°ƒè¯•ä¿¡æ¯
                    print(f"[DEBUG] APIæ¨¡å¼ - æ”¶åˆ°api_generated_prompt")
                    print(f"[DEBUG] å†…å®¹å‰100å­—ç¬¦: {api_generated_prompt[:100]}...")
                    final_generated_prompt = self._extract_clean_prompt_from_api_output(api_generated_prompt.strip())
                    print(f"[DEBUG] æå–åçš„ç»“æœ: {final_generated_prompt}")
                elif generated_prompt and generated_prompt.strip():
                    # generated_promptä¹Ÿå¯èƒ½åŒ…å«è°ƒè¯•ä¿¡æ¯ï¼Œéœ€è¦æ¸…ç†
                    print(f"[DEBUG] APIæ¨¡å¼ - ä½¿ç”¨generated_prompt")
                    print(f"[DEBUG] å†…å®¹å‰100å­—ç¬¦: {generated_prompt[:100]}...")
                    final_generated_prompt = self._extract_clean_prompt_from_api_output(generated_prompt.strip())
                    print(f"[DEBUG] æ¸…ç†å: {final_generated_prompt}")
                elif api_key:
                    final_generated_prompt = self.process_api_mode(
                        layer_info, description, api_provider, api_key, api_model,
                        api_editing_intent, api_processing_style, api_seed, 
                        api_custom_guidance, image
                    )
                else:
                    final_generated_prompt = ""
            elif tab_mode == "ollama":
                # Ollamaæ¨¡å¼ï¼šä¼˜å…ˆä½¿ç”¨ollama_generated_promptï¼Œç„¶åæ˜¯generated_promptï¼Œæœ€åæ˜¯å®æ—¶ç”Ÿæˆ
                if ollama_generated_prompt and ollama_generated_prompt.strip():
                    # æ¸…ç†ollama_generated_promptï¼Œå»é™¤è°ƒè¯•ä¿¡æ¯
                    final_generated_prompt = self._extract_clean_prompt_from_ollama_output(ollama_generated_prompt.strip())
                elif generated_prompt and generated_prompt.strip():
                    # generated_promptä¹Ÿå¯èƒ½åŒ…å«è°ƒè¯•ä¿¡æ¯ï¼Œéœ€è¦æ¸…ç†
                    final_generated_prompt = self._extract_clean_prompt_from_ollama_output(generated_prompt.strip())
                elif ollama_model:
                    final_generated_prompt = self.process_ollama_mode(
                        layer_info, description, ollama_url, ollama_model, ollama_temperature,
                        ollama_editing_intent, ollama_processing_style, ollama_seed,
                        ollama_custom_guidance, ollama_enable_visual, ollama_auto_unload, image
                    )
                else:
                    final_generated_prompt = ""
            elif generated_prompt and generated_prompt.strip():
                # éAPI/Ollamaæ¨¡å¼ï¼Œä½†generated_promptå¯èƒ½ä»åŒ…å«è°ƒè¯•ä¿¡æ¯
                print(f"[DEBUG] ä½¿ç”¨generated_prompt (éAPI/Ollamaæ¨¡å¼)")
                print(f"[DEBUG] å†…å®¹å‰100å­—ç¬¦: {generated_prompt[:100]}...")
                # å°è¯•æ¸…ç†ï¼Œå¦‚æœåŒ…å«è°ƒè¯•ä¿¡æ¯
                if 'âœ…' in generated_prompt or 'ç”Ÿæˆçš„æç¤ºè¯' in generated_prompt:
                    final_generated_prompt = self._extract_clean_prompt_from_api_output(generated_prompt.strip())
                    print(f"[DEBUG] æ¸…ç†å: {final_generated_prompt}")
                else:
                    final_generated_prompt = generated_prompt.strip()
            else:
                # è§£æå›¾å±‚ä¿¡æ¯
                parsed_layer_info = self.parse_layer_info(layer_info)
                
                # è§£æé€‰ä¸­çš„å›¾å±‚
                selected_layer_ids = self.parse_selected_layers(selected_layers)
                
                # è§£æçº¦æŸæ€§å’Œä¿®é¥°æ€§æç¤ºè¯
                constraint_list = self.parse_prompt_list(constraint_prompts)
                decorative_list = self.parse_prompt_list(decorative_prompts)
                
                # ç”ŸæˆåŸºç¡€fallbackæç¤ºè¯
                positive_prompt, negative_prompt, full_description = self.generate_basic_fallback_prompts(
                    edit_mode=edit_mode,
                    operation_type=operation_type,
                    description=description,
                    constraint_prompts=constraint_list,
                    decorative_prompts=decorative_list
                )
                
                # åˆå¹¶æ‰€æœ‰æç¤ºè¯ä¿¡æ¯ä¸ºä¸€ä¸ªå®Œæ•´çš„ç”Ÿæˆæç¤ºè¯
                final_generated_prompt = f"{positive_prompt}\n\nNegative: {negative_prompt}\n\n{full_description}"
            
            # æ„å»ºç¼–è¾‘æ•°æ®ï¼ˆç”¨äºè°ƒè¯•å’Œæ‰©å±•ï¼‰
            edit_data = {
                'node_id': unique_id,
                'edit_mode': edit_mode,
                'operation_type': operation_type,
                'description': description,
                'generated_prompt_source': 'frontend' if generated_prompt and generated_prompt.strip() else 'backend',
                'timestamp': time.time()
            }
            
            return (image, final_generated_prompt)
            
        except Exception as e:
            import traceback
            traceback.print_exc()
            
            # è¿”å›é»˜è®¤å€¼
            default_edit_data = {
                'node_id': unique_id,
                'edit_mode': edit_mode,
                'error': str(e),
                'timestamp': time.time()
            }
            return (image, "å¤„ç†å‡ºé”™ï¼š" + str(e))
    
    def parse_layer_info(self, layer_info):
        """è§£æå›¾å±‚ä¿¡æ¯"""
        if isinstance(layer_info, dict):
            return layer_info
        return {}
    
    def parse_selected_layers(self, selected_layers_str):
        """è§£æé€‰ä¸­çš„å›¾å±‚"""
        if not selected_layers_str:
            return []
        try:
            return json.loads(selected_layers_str)
        except:
            return []
    
    def parse_prompt_list(self, prompt_str):
        """è§£ææç¤ºè¯åˆ—è¡¨"""
        if not prompt_str:
            return []
        
        # æ”¯æŒå¤šç§åˆ†éš”ç¬¦
        prompts = []
        for line in prompt_str.split('\n'):
            line = line.strip()
            if line:
                # æ”¯æŒé€—å·åˆ†éš”
                if ',' in line:
                    prompts.extend([p.strip() for p in line.split(',') if p.strip()])
                else:
                    prompts.append(line)
        return prompts
    
    def translate_basic_prompts(self, prompts):
        """å°†åŸºç¡€è‹±æ–‡æç¤ºè¯è½¬æ¢ä¸ºä¸­æ–‡æ˜¾ç¤º"""
        translated = []
        for prompt in prompts:
            if prompt in self.BASIC_PROMPT_MAPPING:
                translated.append(self.BASIC_PROMPT_MAPPING[prompt])
            else:
                translated.append(prompt)  # ä¿æŒåŸæ–‡ï¼Œå¦‚æœæ²¡æœ‰æ˜ å°„
        return translated
    
    def _analyze_operation_type(self, description, editing_intent):
        """åˆ†æç¼–è¾‘æ“ä½œç±»å‹ï¼Œç”¨äºæ™ºèƒ½çº¦æŸç”Ÿæˆ"""
        description_lower = (description or "").lower()
        intent_lower = (editing_intent or "").lower()
        
        # åŸºäºæè¿°å…³é”®è¯åˆ†ææ“ä½œç±»å‹
        if any(keyword in description_lower for keyword in ['add', 'insert', 'place', 'put', 'æ·»åŠ ', 'æ”¾ç½®']):
            return 'add'
        elif any(keyword in description_lower for keyword in ['remove', 'delete', 'erase', 'clear', 'åˆ é™¤', 'ç§»é™¤']):
            return 'remove'  
        elif any(keyword in description_lower for keyword in ['color', 'colour', 'paint', 'tint', 'shade', 'é¢œè‰²', 'ç€è‰²']):
            return 'color'
        elif any(keyword in description_lower for keyword in ['shape', 'form', 'outline', 'contour', 'å½¢çŠ¶', 'è½®å»“']):
            return 'shape'
        elif any(keyword in description_lower for keyword in ['text', 'word', 'letter', 'font', 'æ–‡å­—', 'æ–‡æœ¬']):
            return 'text'
        elif any(keyword in description_lower for keyword in ['background', 'backdrop', 'bg', 'èƒŒæ™¯']):
            return 'background'
        else:
            # åŸºäºç¼–è¾‘æ„å›¾æ¨æ–­
            if 'creative' in intent_lower or 'artistic' in intent_lower:
                return 'creative'
            elif 'professional' in intent_lower or 'business' in intent_lower:
                return 'professional'
            else:
                return 'general'

    def generate_fallback_prompt(self, edit_mode, operation_type, description):
        """ç”ŸæˆåŸºç¡€fallbackæç¤ºè¯ - ä»…åœ¨å‰ç«¯æœªæä¾›æ—¶ä½¿ç”¨"""
        # åŸºç¡€æç¤ºè¯æ¨¡æ¿
        basic_templates = {
            'change_color': f'change color to {description or "specified color"}',
            'blur_background': f'blur background while keeping {description or "subject"} sharp',
            'enhance_quality': f'enhance quality of {description or "image"}',
        }
        
        # åŸºç¡€çº¦æŸå’Œä¿®é¥°è¯
        basic_constraints = ['natural blending', 'seamless integration']
        basic_decoratives = ['improved detail', 'enhanced quality']
        
        # æ„å»ºåŸºç¡€æç¤ºè¯
        if operation_type and operation_type in basic_templates:
            base_prompt = basic_templates[operation_type]
        else:
            base_prompt = f"{edit_mode}: {description or 'apply editing'}"
        
        return base_prompt, basic_constraints, basic_decoratives
    
    def generate_basic_fallback_prompts(self, edit_mode, operation_type, description, 
                                       constraint_prompts, decorative_prompts):
        """ç”ŸæˆåŸºç¡€fallbackæç¤ºè¯ - ä»…åœ¨å‰ç«¯å®Œå…¨å¤±æ•ˆæ—¶ä½¿ç”¨"""
        # ä½¿ç”¨ç²¾ç®€çš„fallbackç”Ÿæˆå™¨
        base_prompt, basic_constraints, basic_decoratives = self.generate_fallback_prompt(
            edit_mode, operation_type, description
        )
        
        # ç»„åˆæç¤ºè¯
        all_constraints = constraint_prompts + basic_constraints
        all_decoratives = decorative_prompts + basic_decoratives
        
        # æ„å»ºæ­£å‘æç¤ºè¯
        positive_parts = [base_prompt]
        if all_constraints:
            positive_parts.extend(all_constraints[:3])  # é™åˆ¶æ•°é‡
        if all_decoratives:
            positive_parts.extend(all_decoratives[:2])   # é™åˆ¶æ•°é‡
        
        positive_prompt = ", ".join(positive_parts)
        
        # åŸºç¡€è´Ÿå‘æç¤ºè¯
        negative_prompt = "artifacts, distortions, unnatural appearance, poor quality, inconsistencies, blurry, low quality, artifacts, distorted, unnatural, poor composition, bad anatomy, incorrect proportions"
        
        # æ„å»ºå®Œæ•´æè¿°
        full_description_parts = [
            f"ç¼–è¾‘æ¨¡å¼ï¼š{edit_mode}",
            f"æ“ä½œç±»å‹ï¼š{operation_type or 'æœªæŒ‡å®š'}",
            f"æè¿°ï¼š{description or 'æœªæä¾›'}",
        ]
        
        if all_constraints:
            constraint_display = self.translate_basic_prompts(all_constraints[:3])
            full_description_parts.append(f"çº¦æŸæ€§æç¤ºè¯ï¼š{', '.join(constraint_display)}")
        
        if all_decoratives:
            decorative_display = self.translate_basic_prompts(all_decoratives[:2])
            full_description_parts.append(f"ä¿®é¥°æ€§æç¤ºè¯ï¼š{', '.join(decorative_display)}")
        
        full_description = " | ".join(full_description_parts)
        
        return positive_prompt, negative_prompt, full_description
    
    def process_api_mode(self, layer_info, description, api_provider, api_key, api_model,
                        editing_intent, processing_style, seed, custom_guidance, image):
        """å¤„ç†APIæ¨¡å¼çš„æç¤ºè¯ç”Ÿæˆ"""
        try:
            import requests
            import re
            import hashlib
            
            if not api_key:
                return f"APIå¯†é’¥ä¸ºç©º: {description or 'æ— æè¿°'}"
            
            # APIæä¾›å•†é…ç½®
            api_configs = {
                'siliconflow': {
                    'base_url': 'https://api.siliconflow.cn/v1/chat/completions',
                    'default_model': 'deepseek-ai/DeepSeek-V3'
                },
                'zhipu': {
                    'base_url': 'https://open.bigmodel.cn/api/paas/v4/chat/completions',
                    'default_model': 'glm-4.5'
                },
                'deepseek': {
                    'base_url': 'https://api.deepseek.com/v1/chat/completions',
                    'default_model': 'deepseek-chat'
                }
            }
            
            # è·å–APIé…ç½®
            api_config = api_configs.get(api_provider, api_configs['siliconflow'])
            model = api_model or api_config['default_model']
            
            # ä½¿ç”¨æ™ºèƒ½çº¦æŸç”Ÿæˆå™¨ç”Ÿæˆä¼˜åŒ–æç¤ºè¯
            constraint_generator = IntelligentConstraintGenerator()
            
            # åˆ†æç¼–è¾‘æ“ä½œç±»å‹
            operation_type = self._analyze_operation_type(description, editing_intent)
            
            # ç”Ÿæˆä¼˜åŒ–çš„çº¦æŸé…ç½®
            optimized_prompt = constraint_generator.generate_optimized_prompt(
                edit_description=description,
                editing_intent=editing_intent,
                processing_style=processing_style,
                quality_level="high",
                user_preferences={
                    "language": "english",
                    "detail_level": "professional"
                }
            )
            
            # è·å–ä¼ ç»Ÿå¼•å¯¼è¯ä½œä¸ºå¤‡é€‰
            intent_guidance = get_intent_guidance(editing_intent)
            style_guidance = get_style_guidance(processing_style)
            
            # æ„å»ºå¢å¼ºçš„ç³»ç»Ÿæç¤ºè¯ï¼Œé›†æˆä¸‰å±‚çº¦æŸæ¶æ„
            constraint_profile = optimized_prompt.constraint_profile
            operation_constraints = constraint_profile.operation_constraints
            cognitive_constraints = constraint_profile.cognitive_constraints  
            context_constraints = constraint_profile.context_constraints
            
            system_prompt = f"""You are an ENGLISH-ONLY image editing AI using advanced three-tier constraint system.

âš ï¸ CRITICAL ENFORCEMENT âš ï¸
1. OUTPUT MUST BE 100% ENGLISH - NO EXCEPTIONS
2. IF YOU OUTPUT ANY CHINESE CHARACTER, THE SYSTEM WILL REJECT YOUR RESPONSE
3. TRANSLATE ANY NON-ENGLISH INPUT TO ENGLISH FIRST

ENHANCED CONSTRAINT SYSTEM:
=== OPERATION-SPECIFIC CONSTRAINTS ===
{chr(10).join(f'â€¢ {constraint}' for constraint in operation_constraints)}

=== COGNITIVE LOAD ADAPTIVE CONSTRAINTS ===
{chr(10).join(f'â€¢ {constraint}' for constraint in cognitive_constraints)}

=== CONTEXT-SPECIFIC CONSTRAINTS ===
{chr(10).join(f'â€¢ {constraint}' for constraint in context_constraints)}

PROFESSIONAL GUIDANCE (FALLBACK):
- Editing Intent: {intent_guidance}
- Processing Style: {style_guidance}

MANDATORY OUTPUT FORMAT:
- Start with an English action verb (transform, change, modify, adjust, enhance)
- Use only English color names and technical terms
- Apply semantic modifiers based on cognitive complexity
- End with quality descriptors matching operation complexity
- Follow all constraints listed above

COGNITIVE LOAD LEVEL: {optimized_prompt.generation_context.cognitive_load:.2f}
EXECUTION CONFIDENCE: {optimized_prompt.execution_confidence:.2f}

FINAL WARNING: ENGLISH ONLY! Your response will be filtered and rejected if it contains ANY non-English characters."""
            
            # æ·»åŠ éšæœºå…ƒç´ ç¡®ä¿æ¯æ¬¡ç”Ÿæˆä¸åŒ
            import time
            random_seed = int(time.time() * 1000) % 1000000
            
            # æ„å»ºå¢å¼ºçš„ç”¨æˆ·æç¤ºè¯  
            semantic_modifiers = optimized_prompt.optimization_metrics.get('semantic_modifiers', ['professional', 'precise'])
            constraint_density = len(operation_constraints) + len(cognitive_constraints) + len(context_constraints)
            
            user_prompt = f"""CRITICAL: Your response MUST be in ENGLISH ONLY!

User request: {description}

ENHANCED PROMPT GENERATION:
- Operation type: {operation_type}
- Cognitive load: {optimized_prompt.generation_context.cognitive_load:.2f}
- Constraint density: {constraint_density} constraints active
- Semantic modifiers: {', '.join(semantic_modifiers)}

APPLY ALL SYSTEM CONSTRAINTS:
1. Follow all three-tier constraints listed in system prompt
2. Output detailed English prompt (80-150 words based on complexity)
3. Use proper English grammar and technical vocabulary
4. NO Chinese characters allowed (ç³»ç»Ÿå°†æ‹’ç»ä»»ä½•ä¸­æ–‡)
5. Start with appropriate action verb for {operation_type} operation
6. Apply semantic modifiers: {', '.join(semantic_modifiers)}
7. Match quality descriptors to cognitive load level
8. Incorporate operation-specific technical requirements

FALLBACK GUIDANCE:
- Intent guidance: {intent_guidance}
- Style guidance: {style_guidance}

{f'Additional guidance: {custom_guidance}' if custom_guidance else ''}

Variation seed: {random_seed}
Confidence target: {optimized_prompt.execution_confidence:.2f}

REMEMBER: ENGLISH ONLY! Apply all constraints from system prompt!"""
            
            # å‘é€APIè¯·æ±‚
            headers = {
                'Content-Type': 'application/json',
                'Authorization': f'Bearer {api_key}'
            }
            
            data = {
                'model': model,
                'messages': [
                    {'role': 'system', 'content': system_prompt},
                    {'role': 'user', 'content': user_prompt}
                ],
                'temperature': 0.7 + (random_seed % 20) / 100,  # 0.7-0.89çš„éšæœºæ¸©åº¦
                'max_tokens': 350,  # æé«˜tokené™åˆ¶ä»¥æ”¯æŒæ›´è¯¦ç»†çš„è¾“å‡º
                'top_p': 0.9,
                'presence_penalty': 0.1,  # é¿å…é‡å¤
                'frequency_penalty': 0.1,  # å¢åŠ å¤šæ ·æ€§
                'language': 'en'  # å¼ºåˆ¶è‹±æ–‡è¾“å‡ºï¼ˆæŸäº›APIæ”¯æŒï¼‰
            }
            
            response = requests.post(api_config['base_url'], headers=headers, json=data, timeout=30)
            response.raise_for_status()
            
            result = response.json()
            api_response = result['choices'][0]['message']['content']
            
            # è°ƒè¯•ï¼šæ˜¾ç¤ºåŸå§‹å“åº”
            
            # æ¸…ç†å“åº”ï¼Œæå–çº¯å‡€æç¤ºè¯
            cleaned_response = self._clean_api_response(api_response)
            
            # äºŒæ¬¡éªŒè¯ï¼šç¡®ä¿æ²¡æœ‰ä¸­æ–‡
            if cleaned_response and any('\u4e00' <= char <= '\u9fff' for char in cleaned_response):
                # æ ¹æ®æè¿°ç”Ÿæˆå¤‡ç”¨è‹±æ–‡
                if 'color' in description.lower() or 'é¢œè‰²' in description:
                    return "Transform the selected area to the specified color with natural blending"
                elif 'remove' in description.lower() or 'åˆ é™¤' in description or 'ç§»é™¤' in description:
                    return "Remove the selected object seamlessly from the image"
                elif 'add' in description.lower() or 'æ·»åŠ ' in description:
                    return "Add the requested element to the selected area naturally"
                elif 'style' in description.lower() or 'é£æ ¼' in description:
                    return "Apply the specified style transformation to the marked region"
                else:
                    return "Edit the selected area according to the specified requirements"
            
            return cleaned_response if cleaned_response else "Apply professional editing to the marked area"
                
        except Exception as e:
            return f"APIå¤„ç†é”™è¯¯: {description or 'æ— æè¿°'}"
    
    def process_ollama_mode(self, layer_info, description, ollama_url, ollama_model, 
                           temperature, editing_intent, processing_style, seed,
                           custom_guidance, enable_visual, auto_unload, image):
        """å¤„ç†Ollamaæ¨¡å¼çš„æç¤ºè¯ç”Ÿæˆ - é›†æˆå¢å¼ºçº¦æŸç³»ç»Ÿ"""
        try:
            import requests
            
            # ä½¿ç”¨æ™ºèƒ½çº¦æŸç”Ÿæˆå™¨
            constraint_generator = IntelligentConstraintGenerator()
            operation_type = self._analyze_operation_type(description, editing_intent)
            
            # ç”Ÿæˆä¼˜åŒ–çš„çº¦æŸé…ç½®
            optimized_prompt = constraint_generator.generate_optimized_prompt(
                edit_description=description,
                editing_intent=editing_intent,
                processing_style=processing_style,
                quality_level="high",
                user_preferences={
                    "language": "english",
                    "detail_level": "professional"
                }
            )
            
            # è·å–å¢å¼ºçº¦æŸ
            constraint_profile = optimized_prompt.constraint_profile
            operation_constraints = constraint_profile.operation_constraints
            cognitive_constraints = constraint_profile.cognitive_constraints
            
            # æ„å»ºå¢å¼ºçš„ç³»ç»Ÿæç¤ºè¯
            system_prompt = f"""You are an ENGLISH-ONLY image editing assistant using enhanced constraint system.

CRITICAL RULES:
1. Output in ENGLISH ONLY
2. Never use Chinese characters or any other language
3. Apply all operation-specific constraints listed below
4. Use proper English color names and technical terms

OPERATION-SPECIFIC CONSTRAINTS:
{chr(10).join(f'â€¢ {constraint}' for constraint in operation_constraints)}

COGNITIVE ADAPTIVE CONSTRAINTS:
{chr(10).join(f'â€¢ {constraint}' for constraint in cognitive_constraints)}

OPERATION TYPE: {operation_type}
COGNITIVE LOAD: {optimized_prompt.generation_context.cognitive_load:.2f}
CONFIDENCE TARGET: {optimized_prompt.execution_confidence:.2f}

FORMAT: Apply semantic modifiers: {', '.join(optimized_prompt.optimization_metrics.get('semantic_modifiers', ['professional']))}

REMEMBER: ENGLISH ONLY OUTPUT with enhanced constraints!"""
            
            # æ„å»ºå¢å¼ºçš„ç”¨æˆ·æç¤ºè¯ï¼ˆOllamaæ¨¡å¼ï¼‰
            semantic_modifiers = optimized_prompt.optimization_metrics.get('semantic_modifiers', ['professional', 'precise'])
            constraint_density = len(operation_constraints) + len(cognitive_constraints)
            
            user_prompt = f"""Generate ENGLISH editing instruction for: {description}

ENHANCED PARAMETERS:
- Operation type: {operation_type}
- Semantic modifiers: {', '.join(semantic_modifiers)}
- Constraint density: {constraint_density} constraints active
- Target cognitive load: {optimized_prompt.generation_context.cognitive_load:.2f}

APPLY ALL SYSTEM CONSTRAINTS and generate precise English instruction (50-100 words).

{f'Additional guidance: {custom_guidance}' if custom_guidance else ''}

OUTPUT IN ENGLISH ONLY with enhanced constraint application!"""
            
            # è°ƒç”¨Ollama API
            response = requests.post(
                f"{ollama_url}/api/generate",
                json={
                    "model": ollama_model,
                    "prompt": user_prompt,
                    "system": system_prompt,
                    "temperature": temperature,
                    "seed": seed,
                    "stream": False,
                    "options": {
                        "num_predict": 200,  # é™åˆ¶è¾“å‡ºé•¿åº¦
                        "stop": ["\n\n", "###", "---"],  # åœæ­¢æ ‡è®°
                    }
                },
                timeout=30
            )
            
            if response.status_code == 200:
                result = response.json()
                generated_text = result.get('response', '')
                
                # æ¸…ç†å’ŒéªŒè¯è¾“å‡º
                cleaned_text = self._clean_api_response(generated_text)
                
                # æ£€æŸ¥æ˜¯å¦åŒ…å«ä¸­æ–‡å­—ç¬¦
                if any('\u4e00' <= char <= '\u9fff' for char in cleaned_text):
                    # å¦‚æœåŒ…å«ä¸­æ–‡ï¼Œè¿”å›é»˜è®¤è‹±æ–‡
                    return f"Transform marked area as requested: {description}"
                
                return cleaned_text if cleaned_text else f"Transform marked area: {description}"
            else:
                return f"Ollama request failed: {description}"
                
        except Exception as e:
            # è¿”å›è‹±æ–‡fallback
            return f"Apply editing to marked area: {description}"
    
    def _clean_api_response(self, response):
        """æ¸…ç†APIå“åº”ï¼Œç¡®ä¿åªè¾“å‡ºè‹±æ–‡æç¤ºè¯"""
        import re
        
        if not response:
            return "Edit the selected area as requested"
        
        # æ£€æµ‹ä¸­æ–‡å­—ç¬¦
        chinese_pattern = re.compile('[\u4e00-\u9fff]+')
        has_chinese = bool(chinese_pattern.search(response))
        
        # å¦‚æœåŒ…å«ä¸­æ–‡ï¼Œè¿›è¡Œå¼ºåŠ›å¤„ç†
        if has_chinese:
            
            # å°è¯•æå–æ‰€æœ‰è‹±æ–‡å¥å­
            english_sentences = re.findall(r'[A-Z][a-zA-Z\s,\.\-;:]+[\.]', response)
            if english_sentences:
                # æ‰¾åˆ°æœ€é•¿çš„è‹±æ–‡å¥å­
                longest = max(english_sentences, key=len)
                if len(longest) > 30:
                    return longest.strip()
            
            # å°è¯•æå–ä»»ä½•è‹±æ–‡ç‰‡æ®µ
            english_parts = re.findall(r'[a-zA-Z][a-zA-Z\s,\.\-]+', response)
            if english_parts:
                # è¿‡æ»¤å¤ªçŸ­çš„ç‰‡æ®µ
                valid_parts = [p for p in english_parts if len(p) > 10]
                if valid_parts:
                    # åˆå¹¶æœ‰æ•ˆçš„è‹±æ–‡éƒ¨åˆ†
                    english_text = ' '.join(valid_parts)
                    if len(english_text) > 20:
                        return english_text.strip()
            
            # å¦‚æœæ— æ³•æå–æœ‰æ•ˆè‹±æ–‡ï¼Œè¿”å›é€šç”¨è‹±æ–‡æŒ‡ä»¤
            return "Apply the requested editing to the marked area with professional quality"
        
        # å¦‚æœå“åº”åŒ…å«å¤šä¸ªPromptç¼–å·ï¼Œåªæå–ç¬¬ä¸€ä¸ª
        if '### Prompt' in response or 'Prompt 1:' in response:
            
            # å°è¯•æå–ç¬¬ä¸€ä¸ªå¼•å·å†…çš„æç¤ºè¯
            first_quoted_match = re.search(r'"([^"]{30,})"', response)
            if first_quoted_match:
                return first_quoted_match.group(1).strip()
            
            # å°è¯•æå–ç¬¬ä¸€ä¸ªæç¤ºè¯æ®µè½
            first_prompt_match = re.search(r'(?:Prompt \d+:.*?)"([^"]+)"', response, re.DOTALL)
            if first_prompt_match:
                return first_prompt_match.group(1).strip()
        
        # å°è¯•æå–å¼•å·ä¸­çš„æç¤ºè¯
        quoted_match = re.search(r'"([^"]{30,})"', response)
        if quoted_match:
            return quoted_match.group(1).strip()
        
        # æ¸…ç†æ ‡é¢˜å’Œå‰ç¼€
        patterns_to_remove = [
            r'^###.*$',            # ç§»é™¤Markdownæ ‡é¢˜
            r'^Prompt \d+:.*$',    # ç§»é™¤"Prompt 1:"ç­‰
            r'^---.*$',            # ç§»é™¤åˆ†éš”çº¿
            r'^.*?prompt:\s*',     # ç§»é™¤promptå‰ç¼€
        ]
        
        cleaned = response.strip()
        
        # å°è¯•æå–ä»£ç å—ä¸­çš„æç¤ºè¯
        code_block_match = re.search(r'```[^`]*?\n(.*?)\n```', response, re.DOTALL)
        if code_block_match and len(code_block_match.group(1).strip()) > 20:
            return code_block_match.group(1).strip()
        
        # åº”ç”¨æ¸…ç†æ¨¡å¼
        for pattern in patterns_to_remove:
            cleaned = re.sub(pattern, '', cleaned, flags=re.MULTILINE | re.IGNORECASE)
        
        # æ¸…ç†å¤šä½™ç©ºè¡Œ
        cleaned = re.sub(r'\n{2,}', '\n', cleaned).strip()
        
        # å¦‚æœæ²¡æœ‰åšä»»ä½•å¤„ç†æˆ–ç»“æœå¤ªçŸ­ï¼Œè¿”å›åŸå§‹å†…å®¹
        if not cleaned or len(cleaned) < 10:
            return response.strip()
        
        return cleaned.strip()
    
    def _extract_clean_prompt_from_api_output(self, api_output):
        """ä»APIè¾“å‡ºä¸­æå–çº¯å‡€çš„æç¤ºè¯"""
        
        # è°ƒè¯•è¾“å‡º
        print(f"[DEBUG] å¼€å§‹æå–ï¼Œè¾“å…¥é•¿åº¦: {len(api_output)}")
        
        # æ–¹æ³•1: æŸ¥æ‰¾"ç”Ÿæˆçš„æç¤ºè¯:"å¹¶æå–ä¹‹åçš„æ‰€æœ‰å†…å®¹
        markers = ['ç”Ÿæˆçš„æç¤ºè¯:', 'ç”Ÿæˆçš„æç¤ºè¯ï¼š']
        for marker in markers:
            if marker in api_output:
                # æ‰¾åˆ°æ ‡è®°çš„ä½ç½®
                idx = api_output.index(marker)
                # æå–æ ‡è®°åçš„æ‰€æœ‰å†…å®¹
                after_marker = api_output[idx + len(marker):].strip()
                
                # å¦‚æœæœ‰å†…å®¹ï¼Œå¤„ç†å¹¶è¿”å›
                if after_marker:
                    # æŒ‰è¡Œåˆ†å‰²ï¼Œå–ç¬¬ä¸€ä¸ªéç©ºè¡Œï¼ˆé€šå¸¸å°±æ˜¯æç¤ºè¯ï¼‰
                    lines = after_marker.split('\n')
                    for line in lines:
                        line = line.strip()
                        if line and not line.startswith('âœ…'):
                            # å»é™¤å¯èƒ½çš„å¼•å·
                            clean = line.strip('"').strip("'").strip()
                            print(f"[DEBUG] æå–æˆåŠŸ: {clean}")
                            return clean
        
        # æ–¹æ³•2: æå–æœ€åä¸€ä¸ªæœ‰æ„ä¹‰çš„è¡Œ
        lines = api_output.strip().split('\n')
        for line in reversed(lines):
            line = line.strip()
            # è·³è¿‡è°ƒè¯•ä¿¡æ¯è¡Œ
            if (line and 
                not line.startswith('âœ…') and 
                not line.startswith('æ¨¡å‹:') and 
                not line.startswith('è¾“å…¥:') and
                len(line) > 20):  # ç¡®ä¿æ˜¯å®é™…çš„æç¤ºè¯ï¼Œä¸æ˜¯çŸ­æ ‡ç­¾
                clean = line.strip('"').strip("'").strip()
                print(f"[DEBUG] é€šè¿‡æœ€åä¸€è¡Œæå–: {clean}")
                return clean
        
        # å¦‚æœéƒ½å¤±è´¥äº†ï¼Œè¿”å›åŸå§‹å†…å®¹
        print(f"[DEBUG] æå–å¤±è´¥ï¼Œè¿”å›åŸå§‹å†…å®¹")
        return api_output.strip()
    
    def _extract_clean_prompt_from_ollama_output(self, ollama_output):
        """ä»Ollamaè¾“å‡ºä¸­æå–çº¯å‡€çš„æç¤ºè¯"""
        import re
        
        # ä¸_extract_clean_prompt_from_api_outputç±»ä¼¼çš„é€»è¾‘
        if 'ç”Ÿæˆçš„æç¤ºè¯:' in ollama_output or 'ç”Ÿæˆçš„æç¤ºè¯\uff1a' in ollama_output:
            pattern = r'ç”Ÿæˆçš„æç¤ºè¯[:ï¼š]\s*\n?(.+?)$'
            match = re.search(pattern, ollama_output, re.DOTALL)
            if match:
                clean_prompt = match.group(1).strip()
                clean_prompt = clean_prompt.strip('"').strip("'").strip()
                return clean_prompt
        
        if 'generated prompt:' in ollama_output.lower() or 'prompt:' in ollama_output.lower():
            pattern = r'(?:generated prompt:|prompt:)\s*(.+?)(?:\n\n|$)'
            match = re.search(pattern, ollama_output, re.IGNORECASE | re.DOTALL)
            if match:
                clean_prompt = match.group(1).strip()
                clean_prompt = clean_prompt.strip('"').strip("'").strip()
                return clean_prompt
        
        # æå–æœ€åä¸€è¡Œæœ‰æ•ˆå†…å®¹
        lines = ollama_output.strip().split('\n')
        for line in reversed(lines):
            line = line.strip()
            if line and not line.startswith('âœ…') and not line.startswith('æ¨¡å‹:') and not line.startswith('è¾“å…¥:'):
                return line.strip('"').strip("'").strip()
        
        return ollama_output.strip()


# æ³¨å†ŒèŠ‚ç‚¹
NODE_CLASS_MAPPINGS = {
    "KontextSuperPrompt": KontextSuperPrompt,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "KontextSuperPrompt": "âœ¨ Super Prompt",
}

